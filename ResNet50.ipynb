{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet50.ipynb","provenance":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyOMoX6nsEBeYN6U+TLypHvd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"05c3KuM8tyLD"},"source":["# Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3421,"status":"ok","timestamp":1653847333386,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"hIZ944mUt0jK","outputId":"83e9c58a-5fc1-4633-fdb5-3300c23fbbb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}],"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"markdown","metadata":{"id":"F9WlWsGEbZkB"},"source":["'ghp_z(HayhkIaeF11Invg1KGWKjWYvfi150358zH'"]},{"cell_type":"markdown","metadata":{"id":"_lAsO__BbrQT"},"source":["ghp_z(HayhkIaeF11Invg1KGWKjWYvfi150358zH"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1764,"status":"ok","timestamp":1653847335141,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"SwpL1t6et9Ny","outputId":"cc791931-5bf0-4e8c-c74c-1c2dac4c516f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Z1Skv3IorEAx","executionInfo":{"status":"ok","timestamp":1653847335141,"user_tz":-180,"elapsed":9,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}}},"outputs":[],"source":["# UNDERFITTING - occurs when the model cannot obtain a low enough loss on the training set => model fails to learn the underlying patters in the training data\n","\n","# OVERFITTING - where network models the training data too well + fails to generalize to the validation data\n","\n","# goal is to reduce training loss + ensure gap between training & testing loss is small\n","\n","# control fitting by adjusting CAPACITY of the network\n","    # increase it by adding layers + neurons => reach \"optimal\" of network\n","    # decrease it by removing layers & neurons + using regularization methods\n","\n","# training & validation loss/accuracy start to diverge from each other => noticeable gap => GOAL is to limit the gap => preserve the generalizability of the model\n","    # if gap isnt limited => \"OVERFITTING ZONE\" => training loss will either stagnate/continue to drop + validation loss stagnates & increases (heavy indicator of overfitting)\n","\n","# combat overfitting? reduce complexity (less layers & neurons) + applying regularization methods (weight decay, dropout, data augmentation)\n","\n","# import the necessary packages\n","from keras.callbacks import BaseLogger # used to create a class that logs the losses & acccuracy to the disk\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import json\n","import os\n","\n","class TrainingMonitor(BaseLogger):\n","\n","    def __init__(self, figPath, jsonPath=None, startAt=0):\n","    \n","        # figPath = path to output plot thay can be used to visualize loss & accuracy over time\n","        # jsonPath = path used to serialize the loss & accuracy values as a JSON file (useful to see the training history to create custome plots)\n","        # startAt = staring epoch that training is resumed at using ctrl + c training\n","        \n","        \n","        # store the output path for the figure, the path to the JSON serialized file, and the starting epoch\n","        super(TrainingMonitor, self).__init__()\n","        self.figPath = figPath\n","        self.jsonPath = jsonPath\n","        self.startAt = startAt\n","        \n","    def on_train_begin(self, logs={}):\n","    \n","        # initialize the history dictionary (\"history\" of losses)\n","        self.H = {}\n","     \n","        # if the JSON history path exists, load the training history\n","        if self.jsonPath is not None:\n","            if os.path.exists(self.jsonPath):\n","                self.H = json.loads(open(self.jsonPath).read())\n","               \n","                # check to see if a starting epoch was supplied\n","                if self.startAt > 0:\n","                    # loop over the entries in the history log and trim any entries that are past the starting epoch\n","                    for k in self.H.keys():\n","                         self.H[k] = self.H[k][:self.startAt]\n","\n","    def on_epoch_end(self, epoch, logs={}): # is called when a training epoch completes\n","        # epoch = epoch #\n","        # logs = contains the training & validation loss + accuracy for current epoch\n","    \n","        # loop over the logs and update the loss, accuracy, etc. for the entire training process\n","        for (k, v) in logs.items():\n","            l = self.H.get(k, [])\n","            l.append(v)\n","            self.H[k] = l\n","            \n","            #after code is executed H has 4 keys (train_loss, train_accuracy, val_loss, val_accuracy) => a list is kept for each of the values => each list is updated after every epoch => plot an updated loss & accuracy curve as soon as the epoch completes\n","            \n","        # check to see if the training history should be serialized to file\n","        if self.jsonPath is not None:\n","            f = open(self.jsonPath, \"w\")\n","            f.write(json.dumps(self.H))\n","            f.close()\n","\n","        # ensure at least two epochs have passed before plotting (epoch starts at zero)\n","        if len(self.H[\"loss\"]) > 1:\n","            # plot the training loss and accuracy\n","            N = np.arange(0, len(self.H[\"loss\"]))\n","            plt.style.use(\"ggplot\")\n","            plt.figure()\n","            plt.plot(N, self.H[\"loss\"], label=\"train_loss\")\n","            plt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\n","            plt.plot(N, self.H[\"accuracy\"], label=\"train_accuracy\")\n","            plt.plot(N, self.H[\"val_accuracy\"], label=\"val_accuracy\")\n","            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(len(self.H[\"loss\"])))\n","            plt.xlabel(\"Epoch Number\")\n","            plt.ylabel(\"Loss/Accuracy\")\n","            plt.legend()\n","            \n","            # save the figure\n","            plt.savefig(self.figPath)\n","            plt.close()"]},{"cell_type":"markdown","metadata":{"id":"WecQtrx0Aeec"},"source":["# Antrenare pe modelul ResNet50"]},{"cell_type":"markdown","metadata":{"id":"sW9GvXfhAeee"},"source":["Se va schimba modelul EmotionVGG creat mai sus cu modelul ResNet50 pentru a testa pe un model preantrenat.\n","\n","In plus, se va face fine-tuning cu un strat de 512 de neuroni. Spre deosebire de 3.4, se va modifica modelul cu cel ResNet50.\n","\n","Rezultatele se salveaza in outputs/output33."]},{"cell_type":"markdown","metadata":{"id":"ycbTv3A5Aeef"},"source":["\n","\n","---\n","\n","ANTRENARE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13275,"status":"ok","timestamp":1653497073344,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"CRhJFT-pAeeg","outputId":"673498a2-e01a-441f-8a96-763fa059975c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 4246 images belonging to 6 classes.\n","Found 529 images belonging to 6 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 0s 0us/step\n","94781440/94765736 [==============================] - 0s 0us/step\n"]}],"source":["# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","\n","# import the necessary packages\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from keras.models import load_model\n","import keras.backend as K\n","import argparse\n","import os\n","import tensorflow\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import ResNet50\n","\n","output = '/content/drive/MyDrive/GitHub/licenta/outputs/output33'\n","checkpoint = '/content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1'\n","model = None\n","start_epoch = 0\n","\n","train_datagen = ImageDataGenerator( rotation_range = 10, rescale = 1 / 255.0, zoom_range = 0.1, horizontal_flip = True, fill_mode = \"nearest\")\n","val_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/GitHub/licenta/dataset_fer/train', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')\n","val_generator = val_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/val', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')\n","\n","\n","# FOLOSIRE VGG16\n","\n","## Loading VGG16 model\n","\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n","base_model.trainable = False ## Not trainable weights\n","\n","## Add last layers\n","\n","flatten_layer = layers.Flatten()\n","dense_layer_1 = layers.Dense(512, activation='relu')\n","dropout_layer = layers.Dropout(0.5)\n","prediction_layer = layers.Dense(6, activation='softmax')\n","\n","\n","model = models.Sequential([base_model, flatten_layer, dense_layer_1, dropout_layer, prediction_layer])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1653497078855,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"VPsdpw1EAeeh","outputId":"20c75e02-f8c2-4b47-819b-9a19f2303cb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] base model status... \n","\n","0 input_1 False\n","1 conv1_pad False\n","2 conv1_conv False\n","3 conv1_bn False\n","4 conv1_relu False\n","5 pool1_pad False\n","6 pool1_pool False\n","7 conv2_block1_1_conv False\n","8 conv2_block1_1_bn False\n","9 conv2_block1_1_relu False\n","10 conv2_block1_2_conv False\n","11 conv2_block1_2_bn False\n","12 conv2_block1_2_relu False\n","13 conv2_block1_0_conv False\n","14 conv2_block1_3_conv False\n","15 conv2_block1_0_bn False\n","16 conv2_block1_3_bn False\n","17 conv2_block1_add False\n","18 conv2_block1_out False\n","19 conv2_block2_1_conv False\n","20 conv2_block2_1_bn False\n","21 conv2_block2_1_relu False\n","22 conv2_block2_2_conv False\n","23 conv2_block2_2_bn False\n","24 conv2_block2_2_relu False\n","25 conv2_block2_3_conv False\n","26 conv2_block2_3_bn False\n","27 conv2_block2_add False\n","28 conv2_block2_out False\n","29 conv2_block3_1_conv False\n","30 conv2_block3_1_bn False\n","31 conv2_block3_1_relu False\n","32 conv2_block3_2_conv False\n","33 conv2_block3_2_bn False\n","34 conv2_block3_2_relu False\n","35 conv2_block3_3_conv False\n","36 conv2_block3_3_bn False\n","37 conv2_block3_add False\n","38 conv2_block3_out False\n","39 conv3_block1_1_conv False\n","40 conv3_block1_1_bn False\n","41 conv3_block1_1_relu False\n","42 conv3_block1_2_conv False\n","43 conv3_block1_2_bn False\n","44 conv3_block1_2_relu False\n","45 conv3_block1_0_conv False\n","46 conv3_block1_3_conv False\n","47 conv3_block1_0_bn False\n","48 conv3_block1_3_bn False\n","49 conv3_block1_add False\n","50 conv3_block1_out False\n","51 conv3_block2_1_conv False\n","52 conv3_block2_1_bn False\n","53 conv3_block2_1_relu False\n","54 conv3_block2_2_conv False\n","55 conv3_block2_2_bn False\n","56 conv3_block2_2_relu False\n","57 conv3_block2_3_conv False\n","58 conv3_block2_3_bn False\n","59 conv3_block2_add False\n","60 conv3_block2_out False\n","61 conv3_block3_1_conv False\n","62 conv3_block3_1_bn False\n","63 conv3_block3_1_relu False\n","64 conv3_block3_2_conv False\n","65 conv3_block3_2_bn False\n","66 conv3_block3_2_relu False\n","67 conv3_block3_3_conv False\n","68 conv3_block3_3_bn False\n","69 conv3_block3_add False\n","70 conv3_block3_out False\n","71 conv3_block4_1_conv False\n","72 conv3_block4_1_bn False\n","73 conv3_block4_1_relu False\n","74 conv3_block4_2_conv False\n","75 conv3_block4_2_bn False\n","76 conv3_block4_2_relu False\n","77 conv3_block4_3_conv False\n","78 conv3_block4_3_bn False\n","79 conv3_block4_add False\n","80 conv3_block4_out False\n","81 conv4_block1_1_conv False\n","82 conv4_block1_1_bn False\n","83 conv4_block1_1_relu False\n","84 conv4_block1_2_conv False\n","85 conv4_block1_2_bn False\n","86 conv4_block1_2_relu False\n","87 conv4_block1_0_conv False\n","88 conv4_block1_3_conv False\n","89 conv4_block1_0_bn False\n","90 conv4_block1_3_bn False\n","91 conv4_block1_add False\n","92 conv4_block1_out False\n","93 conv4_block2_1_conv False\n","94 conv4_block2_1_bn False\n","95 conv4_block2_1_relu False\n","96 conv4_block2_2_conv False\n","97 conv4_block2_2_bn False\n","98 conv4_block2_2_relu False\n","99 conv4_block2_3_conv False\n","100 conv4_block2_3_bn False\n","101 conv4_block2_add False\n","102 conv4_block2_out False\n","103 conv4_block3_1_conv False\n","104 conv4_block3_1_bn False\n","105 conv4_block3_1_relu False\n","106 conv4_block3_2_conv False\n","107 conv4_block3_2_bn False\n","108 conv4_block3_2_relu False\n","109 conv4_block3_3_conv False\n","110 conv4_block3_3_bn False\n","111 conv4_block3_add False\n","112 conv4_block3_out False\n","113 conv4_block4_1_conv False\n","114 conv4_block4_1_bn False\n","115 conv4_block4_1_relu False\n","116 conv4_block4_2_conv False\n","117 conv4_block4_2_bn False\n","118 conv4_block4_2_relu False\n","119 conv4_block4_3_conv False\n","120 conv4_block4_3_bn False\n","121 conv4_block4_add False\n","122 conv4_block4_out False\n","123 conv4_block5_1_conv False\n","124 conv4_block5_1_bn False\n","125 conv4_block5_1_relu False\n","126 conv4_block5_2_conv False\n","127 conv4_block5_2_bn False\n","128 conv4_block5_2_relu False\n","129 conv4_block5_3_conv False\n","130 conv4_block5_3_bn False\n","131 conv4_block5_add False\n","132 conv4_block5_out False\n","133 conv4_block6_1_conv False\n","134 conv4_block6_1_bn False\n","135 conv4_block6_1_relu False\n","136 conv4_block6_2_conv False\n","137 conv4_block6_2_bn False\n","138 conv4_block6_2_relu False\n","139 conv4_block6_3_conv False\n","140 conv4_block6_3_bn False\n","141 conv4_block6_add False\n","142 conv4_block6_out False\n","143 conv5_block1_1_conv False\n","144 conv5_block1_1_bn False\n","145 conv5_block1_1_relu False\n","146 conv5_block1_2_conv False\n","147 conv5_block1_2_bn False\n","148 conv5_block1_2_relu False\n","149 conv5_block1_0_conv False\n","150 conv5_block1_3_conv False\n","151 conv5_block1_0_bn False\n","152 conv5_block1_3_bn False\n","153 conv5_block1_add False\n","154 conv5_block1_out False\n","155 conv5_block2_1_conv False\n","156 conv5_block2_1_bn False\n","157 conv5_block2_1_relu False\n","158 conv5_block2_2_conv False\n","159 conv5_block2_2_bn False\n","160 conv5_block2_2_relu False\n","161 conv5_block2_3_conv False\n","162 conv5_block2_3_bn False\n","163 conv5_block2_add False\n","164 conv5_block2_out False\n","165 conv5_block3_1_conv False\n","166 conv5_block3_1_bn False\n","167 conv5_block3_1_relu False\n","168 conv5_block3_2_conv False\n","169 conv5_block3_2_bn False\n","170 conv5_block3_2_relu False\n","171 conv5_block3_3_conv False\n","172 conv5_block3_3_bn False\n","173 conv5_block3_add False\n","174 conv5_block3_out False\n","\n","\n","[INFO] entire model status...\n","\n","0 resnet50 False\n","1 flatten True\n","2 dense True\n","3 dropout True\n","4 dense_1 True\n"]}],"source":["print(\"[INFO] base model status... \\n\")\n","for i, layer in enumerate(base_model.layers):\n","  print(i, layer.name, layer.trainable)\n","\n","print(\"\\n\\n[INFO] entire model status...\\n\")\n","for i, layer in enumerate(model.layers):\n","  print(i, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1341034,"status":"ok","timestamp":1653499405751,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"2PkN4GvnAeeh","outputId":"d6f23e2b-f22c-4117-8639-ae16ddf43e5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] compiling model...\n","Epoch 1/20\n","16/33 [=============>................] - ETA: 32s - loss: 1.7746 - accuracy: 0.2147"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.7573 - accuracy: 0.2363INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1/assets\n","33/33 [==============================] - 102s 3s/step - loss: 1.7573 - accuracy: 0.2363 - val_loss: 1.7029 - val_accuracy: 0.3281\n","Epoch 2/20\n","32/33 [============================>.] - ETA: 1s - loss: 1.7340 - accuracy: 0.2471"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.7338 - accuracy: 0.2484INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1/assets\n","33/33 [==============================] - 86s 3s/step - loss: 1.7338 - accuracy: 0.2484 - val_loss: 1.6894 - val_accuracy: 0.3301\n","Epoch 3/20\n","12/33 [=========>....................] - ETA: 42s - loss: 1.7133 - accuracy: 0.2819"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 64s 2s/step - loss: 1.7065 - accuracy: 0.2834 - val_loss: 1.6633 - val_accuracy: 0.2969\n","Epoch 4/20\n","19/33 [================>.............] - ETA: 24s - loss: 1.6950 - accuracy: 0.2854"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.6968 - accuracy: 0.2773INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.6968 - accuracy: 0.2773 - val_loss: 1.6496 - val_accuracy: 0.3340\n","Epoch 5/20\n"," 2/33 [>.............................] - ETA: 49s - loss: 1.6915 - accuracy: 0.2891 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.6823 - accuracy: 0.2981INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1/assets\n","33/33 [==============================] - 79s 2s/step - loss: 1.6823 - accuracy: 0.2981 - val_loss: 1.6278 - val_accuracy: 0.3359\n","Epoch 6/20\n"," 3/33 [=>............................] - ETA: 47s - loss: 1.6977 - accuracy: 0.2917"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 58s 2s/step - loss: 1.6694 - accuracy: 0.2980 - val_loss: 1.6028 - val_accuracy: 0.3301\n","Epoch 7/20\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6545 - accuracy: 0.3116 - val_loss: 1.6012 - val_accuracy: 0.3340\n","Epoch 8/20\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.6492 - accuracy: 0.3137INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1/assets\n","33/33 [==============================] - 77s 2s/step - loss: 1.6492 - accuracy: 0.3137 - val_loss: 1.5881 - val_accuracy: 0.3457\n","Epoch 9/20\n"," 4/33 [==>...........................] - ETA: 47s - loss: 1.6846 - accuracy: 0.2949"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 58s 2s/step - loss: 1.6444 - accuracy: 0.3099 - val_loss: 1.5824 - val_accuracy: 0.3164\n","Epoch 10/20\n","13/33 [==========>...................] - ETA: 33s - loss: 1.6226 - accuracy: 0.3215"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6251 - accuracy: 0.3218 - val_loss: 1.5817 - val_accuracy: 0.3359\n","Epoch 11/20\n"," 1/33 [..............................] - ETA: 1:05 - loss: 1.6619 - accuracy: 0.3828"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6163 - accuracy: 0.3220 - val_loss: 1.5461 - val_accuracy: 0.3398\n","Epoch 12/20\n","24/33 [====================>.........] - ETA: 14s - loss: 1.6101 - accuracy: 0.3230"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.6111 - accuracy: 0.3249INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.6111 - accuracy: 0.3249 - val_loss: 1.5485 - val_accuracy: 0.3594\n","Epoch 13/20\n","28/33 [========================>.....] - ETA: 8s - loss: 1.6076 - accuracy: 0.3292"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6133 - accuracy: 0.3269 - val_loss: 1.5379 - val_accuracy: 0.3477\n","Epoch 14/20\n"," 5/33 [===>..........................] - ETA: 46s - loss: 1.6361 - accuracy: 0.3000"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5992 - accuracy: 0.3196INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1/assets\n","33/33 [==============================] - 75s 2s/step - loss: 1.5992 - accuracy: 0.3196 - val_loss: 1.5258 - val_accuracy: 0.3730\n","Epoch 15/20\n"," 4/33 [==>...........................] - ETA: 34s - loss: 1.6149 - accuracy: 0.3251"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5890 - accuracy: 0.3329 - val_loss: 1.5258 - val_accuracy: 0.3555\n","Epoch 16/20\n","19/33 [================>.............] - ETA: 21s - loss: 1.5934 - accuracy: 0.3452"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5981 - accuracy: 0.3344 - val_loss: 1.5188 - val_accuracy: 0.3438\n","Epoch 17/20\n","21/33 [==================>...........] - ETA: 18s - loss: 1.5855 - accuracy: 0.3311"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.5822 - accuracy: 0.3320 - val_loss: 1.4969 - val_accuracy: 0.3613\n","Epoch 18/20\n","14/33 [===========>..................] - ETA: 30s - loss: 1.5839 - accuracy: 0.3281"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5854 - accuracy: 0.3358INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1/assets\n","33/33 [==============================] - 75s 2s/step - loss: 1.5854 - accuracy: 0.3358 - val_loss: 1.5004 - val_accuracy: 0.3750\n","Epoch 19/20\n","21/33 [==================>...........] - ETA: 19s - loss: 1.5710 - accuracy: 0.3517"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5605 - accuracy: 0.3543 - val_loss: 1.5044 - val_accuracy: 0.3711\n","Epoch 20/20\n"," 5/33 [===>..........................] - ETA: 44s - loss: 1.5801 - accuracy: 0.3297"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.5713 - accuracy: 0.3363 - val_loss: 1.4907 - val_accuracy: 0.3750\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f1c30496ed0>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["## Compile and fit model\n","\n","print(\"[INFO] compiling model...\")\n","opt = Adam(learning_rate = 1e-4)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# construct the set of callbacks\n","figPath = os.path.sep.join([output,\"facial_emotion_recognition33_1.png\"])\n","jsonPath = os.path.sep.join([output,\"facial_emotion_recognitio33_1.json\"])\n","model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n","callbacks = [model_checkpoint_callback, TrainingMonitor(figPath, jsonPath=jsonPath, startAt=start_epoch)]\n","\n","model.fit(train_generator, steps_per_epoch = 4246 // 128, epochs = 20, validation_data = val_generator, validation_steps = 529 // 128, max_queue_size = 128 * 2, callbacks = callbacks, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"7er_whjWAeeh"},"source":["\n","\n","---\n","\n","TESTARE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":134781,"status":"ok","timestamp":1653500161470,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"UyOn3K8PAeei","outputId":"1ea876f1-d91c-4861-f202-cce3a60dce0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 540 images belonging to 6 classes.\n","[INFO] loading /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1...\n","4/4 [==============================] - 84s 27s/step - loss: 1.5456 - accuracy: 0.3496\n","              precision    recall  f1-score   support\n","\n","           0       0.17      0.49      0.25        96\n","           1       0.16      0.15      0.15        81\n","           2       0.25      0.18      0.21        99\n","           3       0.09      0.06      0.07        94\n","           4       0.09      0.01      0.02        88\n","           5       0.17      0.09      0.11        82\n","\n","    accuracy                           0.17       540\n","   macro avg       0.16      0.16      0.14       540\n","weighted avg       0.16      0.17      0.14       540\n","\n","\n","\n","[INFO] accuracy: 34.96\n"]}],"source":["# import the necessary packages\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import load_model\n","import argparse\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelBinarizer\n","import numpy as np\n","\n","model = '/content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint1'\n","\n","test_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","test_generator = test_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/test', target_size = (224, 224), batch_size = 128, class_mode = \"categorical\")\n","\n","# load the model from disk\n","print(\"[INFO] loading {}...\".format(model))\n","model = load_model(model)\n","\n","\n","# evaluate the network\n","(loss, acc) = model.evaluate(test_generator, steps = 540 // 128, max_queue_size = 128 * 2)\n","\n","# get the ground truth of your data. \n","test_labels  =test_generator.classes \n","\n","# predict the probability distribution of the data\n","predictions = model.predict(test_generator)\n","\n","# get the class with highest probability for each sample\n","y_pred = np.argmax(predictions, axis=-1)\n","\n","# get the classification report\n","print(classification_report(test_labels, y_pred))\n","\n","print(\"\\n\\n[INFO] accuracy: {:.2f}\".format(acc * 100))"]},{"cell_type":"markdown","metadata":{"id":"iuisTYFXAeei"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","ANTRENARE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1653500216728,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"_MPSuIwYAeei","outputId":"0eb6a9f5-dd5b-4937-cc4f-76a71484d083"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] base model status... \n","\n","0 input_1 False\n","1 conv1_pad False\n","2 conv1_conv False\n","3 conv1_bn False\n","4 conv1_relu False\n","5 pool1_pad False\n","6 pool1_pool False\n","7 conv2_block1_1_conv False\n","8 conv2_block1_1_bn False\n","9 conv2_block1_1_relu False\n","10 conv2_block1_2_conv False\n","11 conv2_block1_2_bn False\n","12 conv2_block1_2_relu False\n","13 conv2_block1_0_conv False\n","14 conv2_block1_3_conv False\n","15 conv2_block1_0_bn False\n","16 conv2_block1_3_bn False\n","17 conv2_block1_add False\n","18 conv2_block1_out False\n","19 conv2_block2_1_conv False\n","20 conv2_block2_1_bn False\n","21 conv2_block2_1_relu False\n","22 conv2_block2_2_conv False\n","23 conv2_block2_2_bn False\n","24 conv2_block2_2_relu False\n","25 conv2_block2_3_conv False\n","26 conv2_block2_3_bn False\n","27 conv2_block2_add False\n","28 conv2_block2_out False\n","29 conv2_block3_1_conv False\n","30 conv2_block3_1_bn False\n","31 conv2_block3_1_relu False\n","32 conv2_block3_2_conv False\n","33 conv2_block3_2_bn False\n","34 conv2_block3_2_relu False\n","35 conv2_block3_3_conv False\n","36 conv2_block3_3_bn False\n","37 conv2_block3_add False\n","38 conv2_block3_out False\n","39 conv3_block1_1_conv False\n","40 conv3_block1_1_bn False\n","41 conv3_block1_1_relu False\n","42 conv3_block1_2_conv False\n","43 conv3_block1_2_bn False\n","44 conv3_block1_2_relu False\n","45 conv3_block1_0_conv False\n","46 conv3_block1_3_conv False\n","47 conv3_block1_0_bn False\n","48 conv3_block1_3_bn False\n","49 conv3_block1_add False\n","50 conv3_block1_out False\n","51 conv3_block2_1_conv False\n","52 conv3_block2_1_bn False\n","53 conv3_block2_1_relu False\n","54 conv3_block2_2_conv False\n","55 conv3_block2_2_bn False\n","56 conv3_block2_2_relu False\n","57 conv3_block2_3_conv False\n","58 conv3_block2_3_bn False\n","59 conv3_block2_add False\n","60 conv3_block2_out False\n","61 conv3_block3_1_conv False\n","62 conv3_block3_1_bn False\n","63 conv3_block3_1_relu False\n","64 conv3_block3_2_conv False\n","65 conv3_block3_2_bn False\n","66 conv3_block3_2_relu False\n","67 conv3_block3_3_conv False\n","68 conv3_block3_3_bn False\n","69 conv3_block3_add False\n","70 conv3_block3_out False\n","71 conv3_block4_1_conv False\n","72 conv3_block4_1_bn False\n","73 conv3_block4_1_relu False\n","74 conv3_block4_2_conv False\n","75 conv3_block4_2_bn False\n","76 conv3_block4_2_relu False\n","77 conv3_block4_3_conv False\n","78 conv3_block4_3_bn False\n","79 conv3_block4_add False\n","80 conv3_block4_out False\n","81 conv4_block1_1_conv False\n","82 conv4_block1_1_bn False\n","83 conv4_block1_1_relu False\n","84 conv4_block1_2_conv False\n","85 conv4_block1_2_bn False\n","86 conv4_block1_2_relu False\n","87 conv4_block1_0_conv False\n","88 conv4_block1_3_conv False\n","89 conv4_block1_0_bn False\n","90 conv4_block1_3_bn False\n","91 conv4_block1_add False\n","92 conv4_block1_out False\n","93 conv4_block2_1_conv False\n","94 conv4_block2_1_bn False\n","95 conv4_block2_1_relu False\n","96 conv4_block2_2_conv False\n","97 conv4_block2_2_bn False\n","98 conv4_block2_2_relu False\n","99 conv4_block2_3_conv False\n","100 conv4_block2_3_bn False\n","101 conv4_block2_add False\n","102 conv4_block2_out False\n","103 conv4_block3_1_conv False\n","104 conv4_block3_1_bn False\n","105 conv4_block3_1_relu False\n","106 conv4_block3_2_conv False\n","107 conv4_block3_2_bn False\n","108 conv4_block3_2_relu False\n","109 conv4_block3_3_conv False\n","110 conv4_block3_3_bn False\n","111 conv4_block3_add False\n","112 conv4_block3_out False\n","113 conv4_block4_1_conv False\n","114 conv4_block4_1_bn False\n","115 conv4_block4_1_relu False\n","116 conv4_block4_2_conv False\n","117 conv4_block4_2_bn False\n","118 conv4_block4_2_relu False\n","119 conv4_block4_3_conv False\n","120 conv4_block4_3_bn False\n","121 conv4_block4_add False\n","122 conv4_block4_out False\n","123 conv4_block5_1_conv False\n","124 conv4_block5_1_bn False\n","125 conv4_block5_1_relu False\n","126 conv4_block5_2_conv False\n","127 conv4_block5_2_bn False\n","128 conv4_block5_2_relu False\n","129 conv4_block5_3_conv False\n","130 conv4_block5_3_bn False\n","131 conv4_block5_add False\n","132 conv4_block5_out False\n","133 conv4_block6_1_conv False\n","134 conv4_block6_1_bn False\n","135 conv4_block6_1_relu False\n","136 conv4_block6_2_conv False\n","137 conv4_block6_2_bn False\n","138 conv4_block6_2_relu False\n","139 conv4_block6_3_conv False\n","140 conv4_block6_3_bn False\n","141 conv4_block6_add False\n","142 conv4_block6_out False\n","143 conv5_block1_1_conv False\n","144 conv5_block1_1_bn False\n","145 conv5_block1_1_relu False\n","146 conv5_block1_2_conv False\n","147 conv5_block1_2_bn False\n","148 conv5_block1_2_relu False\n","149 conv5_block1_0_conv False\n","150 conv5_block1_3_conv False\n","151 conv5_block1_0_bn False\n","152 conv5_block1_3_bn False\n","153 conv5_block1_add False\n","154 conv5_block1_out False\n","155 conv5_block2_1_conv False\n","156 conv5_block2_1_bn False\n","157 conv5_block2_1_relu False\n","158 conv5_block2_2_conv False\n","159 conv5_block2_2_bn False\n","160 conv5_block2_2_relu False\n","161 conv5_block2_3_conv False\n","162 conv5_block2_3_bn False\n","163 conv5_block2_add False\n","164 conv5_block2_out False\n","165 conv5_block3_1_conv False\n","166 conv5_block3_1_bn False\n","167 conv5_block3_1_relu False\n","168 conv5_block3_2_conv True\n","169 conv5_block3_2_bn True\n","170 conv5_block3_2_relu True\n","171 conv5_block3_3_conv True\n","172 conv5_block3_3_bn True\n","173 conv5_block3_add True\n","174 conv5_block3_out True\n","\n","\n","[INFO] entire model status...\n","\n","\n","0 resnet50 False\n","1 flatten True\n","2 dense True\n","3 dropout True\n","4 dense_1 True\n"]}],"source":["output = '/content/drive/MyDrive/GitHub/licenta/outputs/output33'\n","checkpoint = '/content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2'\n","start_epoch = 0\n","\n","for layer in base_model.layers[168:]:\n","  layer.trainable = True\n","\n","print(\"[INFO] base model status... \\n\")\n","for i, layer in enumerate(base_model.layers):\n","  print(i, layer.name, layer.trainable)\n","\n","print(\"\\n\\n[INFO] entire model status...\\n\\n\")\n","for i, layer in enumerate(model.layers):\n","  print(i, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5909495,"status":"ok","timestamp":1653506133566,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"jaOZj4scAeek","outputId":"14d88bf0-6a07-4cf4-bbe6-6dc5c82341a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] compiling model...\n","Epoch 1/100\n"," 5/33 [===>..........................] - ETA: 44s - loss: 1.6214 - accuracy: 0.3047"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5909 - accuracy: 0.3150INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.5909 - accuracy: 0.3150 - val_loss: 1.5199 - val_accuracy: 0.3652\n","Epoch 2/100\n","12/33 [=========>....................] - ETA: 33s - loss: 1.5673 - accuracy: 0.3287"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5676 - accuracy: 0.3329INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.5676 - accuracy: 0.3329 - val_loss: 1.4967 - val_accuracy: 0.3809\n","Epoch 3/100\n","31/33 [===========================>..] - ETA: 3s - loss: 1.5565 - accuracy: 0.3480"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 59s 2s/step - loss: 1.5623 - accuracy: 0.3441 - val_loss: 1.4876 - val_accuracy: 0.3672\n","Epoch 4/100\n","20/33 [=================>............] - ETA: 20s - loss: 1.5537 - accuracy: 0.3350"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 58s 2s/step - loss: 1.5662 - accuracy: 0.3388 - val_loss: 1.4971 - val_accuracy: 0.3789\n","Epoch 5/100\n","20/33 [=================>............] - ETA: 21s - loss: 1.5353 - accuracy: 0.3492"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5586 - accuracy: 0.3378 - val_loss: 1.5007 - val_accuracy: 0.3750\n","Epoch 6/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.5449 - accuracy: 0.3418"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 58s 2s/step - loss: 1.5512 - accuracy: 0.3423 - val_loss: 1.4853 - val_accuracy: 0.3750\n","Epoch 7/100\n"," 5/33 [===>..........................] - ETA: 45s - loss: 1.5793 - accuracy: 0.3219"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5482 - accuracy: 0.3499 - val_loss: 1.4753 - val_accuracy: 0.3750\n","Epoch 8/100\n","23/33 [===================>..........] - ETA: 16s - loss: 1.5413 - accuracy: 0.3495"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 59s 2s/step - loss: 1.5524 - accuracy: 0.3494 - val_loss: 1.4827 - val_accuracy: 0.3633\n","Epoch 9/100\n","10/33 [========>.....................] - ETA: 38s - loss: 1.5397 - accuracy: 0.3484"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5382 - accuracy: 0.3543INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.5382 - accuracy: 0.3543 - val_loss: 1.4674 - val_accuracy: 0.3828\n","Epoch 10/100\n","31/33 [===========================>..] - ETA: 3s - loss: 1.5397 - accuracy: 0.3441"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5403 - accuracy: 0.3448 - val_loss: 1.4817 - val_accuracy: 0.3770\n","Epoch 11/100\n","16/33 [=============>................] - ETA: 27s - loss: 1.5370 - accuracy: 0.3579"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.5323 - accuracy: 0.3524 - val_loss: 1.4617 - val_accuracy: 0.3750\n","Epoch 12/100\n"," 4/33 [==>...........................] - ETA: 48s - loss: 1.5024 - accuracy: 0.3867"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5329 - accuracy: 0.3434INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.5329 - accuracy: 0.3434 - val_loss: 1.4528 - val_accuracy: 0.3848\n","Epoch 13/100\n","23/33 [===================>..........] - ETA: 16s - loss: 1.5128 - accuracy: 0.3499"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 58s 2s/step - loss: 1.5118 - accuracy: 0.3480 - val_loss: 1.4543 - val_accuracy: 0.3711\n","Epoch 14/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.5216 - accuracy: 0.3495"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5201 - accuracy: 0.3497INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.5201 - accuracy: 0.3497 - val_loss: 1.4551 - val_accuracy: 0.3867\n","Epoch 15/100\n","24/33 [====================>.........] - ETA: 15s - loss: 1.5324 - accuracy: 0.3520"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5336 - accuracy: 0.3511 - val_loss: 1.4475 - val_accuracy: 0.3770\n","Epoch 16/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.5173 - accuracy: 0.3602"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5185 - accuracy: 0.3606 - val_loss: 1.4499 - val_accuracy: 0.3828\n","Epoch 17/100\n","15/33 [============>.................] - ETA: 29s - loss: 1.5157 - accuracy: 0.3547"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.5121 - accuracy: 0.3584 - val_loss: 1.4381 - val_accuracy: 0.3867\n","Epoch 18/100\n","14/33 [===========>..................] - ETA: 31s - loss: 1.5298 - accuracy: 0.3622"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5061 - accuracy: 0.3645 - val_loss: 1.4427 - val_accuracy: 0.3770\n","Epoch 19/100\n","26/33 [======================>.......] - ETA: 11s - loss: 1.5096 - accuracy: 0.3613"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5129 - accuracy: 0.3611 - val_loss: 1.4549 - val_accuracy: 0.3789\n","Epoch 20/100\n","31/33 [===========================>..] - ETA: 3s - loss: 1.5056 - accuracy: 0.3664"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5070 - accuracy: 0.3681 - val_loss: 1.4391 - val_accuracy: 0.3789\n","Epoch 21/100\n","11/33 [=========>....................] - ETA: 36s - loss: 1.5162 - accuracy: 0.3516"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.5100 - accuracy: 0.3579 - val_loss: 1.4359 - val_accuracy: 0.3809\n","Epoch 22/100\n","11/33 [=========>....................] - ETA: 34s - loss: 1.5106 - accuracy: 0.3564"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5225 - accuracy: 0.3485 - val_loss: 1.4473 - val_accuracy: 0.3672\n","Epoch 23/100\n","23/33 [===================>..........] - ETA: 15s - loss: 1.5121 - accuracy: 0.3531"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.5185 - accuracy: 0.3536 - val_loss: 1.4485 - val_accuracy: 0.3828\n","Epoch 24/100\n","22/33 [===================>..........] - ETA: 17s - loss: 1.4885 - accuracy: 0.3720"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4958 - accuracy: 0.3672 - val_loss: 1.4372 - val_accuracy: 0.3770\n","Epoch 25/100\n","16/33 [=============>................] - ETA: 26s - loss: 1.5125 - accuracy: 0.3460"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5058 - accuracy: 0.3511INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.5058 - accuracy: 0.3511 - val_loss: 1.4413 - val_accuracy: 0.3965\n","Epoch 26/100\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5083 - accuracy: 0.3626 - val_loss: 1.4299 - val_accuracy: 0.3887\n","Epoch 27/100\n","14/33 [===========>..................] - ETA: 29s - loss: 1.4944 - accuracy: 0.3387"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.4915 - accuracy: 0.3533INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 76s 2s/step - loss: 1.4915 - accuracy: 0.3533 - val_loss: 1.4390 - val_accuracy: 0.3984\n","Epoch 28/100\n"," 6/33 [====>.........................] - ETA: 43s - loss: 1.4773 - accuracy: 0.3555"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4973 - accuracy: 0.3613 - val_loss: 1.4236 - val_accuracy: 0.3887\n","Epoch 29/100\n","15/33 [============>.................] - ETA: 29s - loss: 1.4929 - accuracy: 0.3755"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4969 - accuracy: 0.3667 - val_loss: 1.4274 - val_accuracy: 0.3867\n","Epoch 30/100\n","21/33 [==================>...........] - ETA: 19s - loss: 1.4906 - accuracy: 0.3508"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4944 - accuracy: 0.3601 - val_loss: 1.4185 - val_accuracy: 0.3789\n","Epoch 31/100\n","10/33 [========>.....................] - ETA: 37s - loss: 1.4655 - accuracy: 0.3742"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4925 - accuracy: 0.3621 - val_loss: 1.4094 - val_accuracy: 0.3789\n","Epoch 32/100\n","32/33 [============================>.] - ETA: 1s - loss: 1.4828 - accuracy: 0.3752"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4823 - accuracy: 0.3749 - val_loss: 1.4394 - val_accuracy: 0.3691\n","Epoch 33/100\n"," 6/33 [====>.........................] - ETA: 44s - loss: 1.4633 - accuracy: 0.3672"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4863 - accuracy: 0.3694 - val_loss: 1.4385 - val_accuracy: 0.3828\n","Epoch 34/100\n","15/33 [============>.................] - ETA: 27s - loss: 1.4872 - accuracy: 0.3622"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.4808 - accuracy: 0.3594INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.4808 - accuracy: 0.3594 - val_loss: 1.4009 - val_accuracy: 0.4004\n","Epoch 35/100\n","23/33 [===================>..........] - ETA: 16s - loss: 1.4645 - accuracy: 0.3795"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4700 - accuracy: 0.3783 - val_loss: 1.4271 - val_accuracy: 0.3926\n","Epoch 36/100\n","29/33 [=========================>....] - ETA: 6s - loss: 1.4689 - accuracy: 0.3680"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4741 - accuracy: 0.3647 - val_loss: 1.4226 - val_accuracy: 0.3945\n","Epoch 37/100\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4761 - accuracy: 0.3638 - val_loss: 1.4120 - val_accuracy: 0.3906\n","Epoch 38/100\n","29/33 [=========================>....] - ETA: 6s - loss: 1.4853 - accuracy: 0.3712"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4838 - accuracy: 0.3684 - val_loss: 1.4208 - val_accuracy: 0.3809\n","Epoch 39/100\n","27/33 [=======================>......] - ETA: 9s - loss: 1.4892 - accuracy: 0.3522 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4911 - accuracy: 0.3577 - val_loss: 1.4153 - val_accuracy: 0.3809\n","Epoch 40/100\n","15/33 [============>.................] - ETA: 29s - loss: 1.4849 - accuracy: 0.3552"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4790 - accuracy: 0.3618 - val_loss: 1.4139 - val_accuracy: 0.3926\n","Epoch 41/100\n","20/33 [=================>............] - ETA: 20s - loss: 1.4807 - accuracy: 0.3692"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4701 - accuracy: 0.3754 - val_loss: 1.3965 - val_accuracy: 0.3809\n","Epoch 42/100\n","14/33 [===========>..................] - ETA: 31s - loss: 1.4846 - accuracy: 0.3460"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4684 - accuracy: 0.3611 - val_loss: 1.4034 - val_accuracy: 0.3926\n","Epoch 43/100\n","28/33 [========================>.....] - ETA: 8s - loss: 1.4879 - accuracy: 0.3683"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4843 - accuracy: 0.3707 - val_loss: 1.4185 - val_accuracy: 0.4004\n","Epoch 44/100\n","26/33 [======================>.......] - ETA: 11s - loss: 1.4768 - accuracy: 0.3752"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4738 - accuracy: 0.3759 - val_loss: 1.3939 - val_accuracy: 0.3887\n","Epoch 45/100\n","19/33 [================>.............] - ETA: 21s - loss: 1.4783 - accuracy: 0.3641"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4698 - accuracy: 0.3706 - val_loss: 1.3923 - val_accuracy: 0.3965\n","Epoch 46/100\n","32/33 [============================>.] - ETA: 1s - loss: 1.4706 - accuracy: 0.3747"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.4713 - accuracy: 0.3752INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 76s 2s/step - loss: 1.4713 - accuracy: 0.3752 - val_loss: 1.4026 - val_accuracy: 0.4043\n","Epoch 47/100\n","18/33 [===============>..............] - ETA: 25s - loss: 1.4733 - accuracy: 0.3507"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4683 - accuracy: 0.3582 - val_loss: 1.4076 - val_accuracy: 0.3906\n","Epoch 48/100\n","28/33 [========================>.....] - ETA: 7s - loss: 1.4672 - accuracy: 0.3824"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4647 - accuracy: 0.3803 - val_loss: 1.3956 - val_accuracy: 0.3750\n","Epoch 49/100\n","14/33 [===========>..................] - ETA: 31s - loss: 1.4708 - accuracy: 0.3471"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4652 - accuracy: 0.3740 - val_loss: 1.3921 - val_accuracy: 0.4004\n","Epoch 50/100\n","10/33 [========>.....................] - ETA: 37s - loss: 1.4779 - accuracy: 0.3602"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4772 - accuracy: 0.3604 - val_loss: 1.4140 - val_accuracy: 0.3867\n","Epoch 51/100\n"," 7/33 [=====>........................] - ETA: 41s - loss: 1.4723 - accuracy: 0.3850"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4527 - accuracy: 0.3856 - val_loss: 1.3883 - val_accuracy: 0.4004\n","Epoch 52/100\n"," 2/33 [>.............................] - ETA: 51s - loss: 1.4644 - accuracy: 0.4180 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4633 - accuracy: 0.3725 - val_loss: 1.4048 - val_accuracy: 0.3945\n","Epoch 53/100\n"," 2/33 [>.............................] - ETA: 48s - loss: 1.4786 - accuracy: 0.3945 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4520 - accuracy: 0.3757 - val_loss: 1.3971 - val_accuracy: 0.3984\n","Epoch 54/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.4618 - accuracy: 0.3771"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4601 - accuracy: 0.3715 - val_loss: 1.4221 - val_accuracy: 0.3887\n","Epoch 55/100\n"," 7/33 [=====>........................] - ETA: 42s - loss: 1.4740 - accuracy: 0.3616"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4587 - accuracy: 0.3803 - val_loss: 1.3927 - val_accuracy: 0.4023\n","Epoch 56/100\n","22/33 [===================>..........] - ETA: 17s - loss: 1.4507 - accuracy: 0.3778"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4547 - accuracy: 0.3781 - val_loss: 1.3828 - val_accuracy: 0.3906\n","Epoch 57/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.4540 - accuracy: 0.3712"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4558 - accuracy: 0.3713 - val_loss: 1.3831 - val_accuracy: 0.3848\n","Epoch 58/100\n","16/33 [=============>................] - ETA: 27s - loss: 1.4713 - accuracy: 0.3701"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4476 - accuracy: 0.3822 - val_loss: 1.3936 - val_accuracy: 0.3770\n","Epoch 59/100\n","13/33 [==========>...................] - ETA: 32s - loss: 1.4354 - accuracy: 0.3738"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.4452 - accuracy: 0.3737INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.4452 - accuracy: 0.3737 - val_loss: 1.3741 - val_accuracy: 0.4062\n","Epoch 60/100\n","28/33 [========================>.....] - ETA: 8s - loss: 1.4402 - accuracy: 0.3968"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4357 - accuracy: 0.3970 - val_loss: 1.3775 - val_accuracy: 0.4043\n","Epoch 61/100\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4455 - accuracy: 0.3783 - val_loss: 1.3946 - val_accuracy: 0.4062\n","Epoch 62/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.4437 - accuracy: 0.3768"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4398 - accuracy: 0.3800 - val_loss: 1.3884 - val_accuracy: 0.3809\n","Epoch 63/100\n"," 9/33 [=======>......................] - ETA: 39s - loss: 1.4498 - accuracy: 0.3516"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4629 - accuracy: 0.3558 - val_loss: 1.3842 - val_accuracy: 0.3789\n","Epoch 64/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.4635 - accuracy: 0.3604"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4535 - accuracy: 0.3718 - val_loss: 1.3794 - val_accuracy: 0.3984\n","Epoch 65/100\n","20/33 [=================>............] - ETA: 21s - loss: 1.4340 - accuracy: 0.3625"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4400 - accuracy: 0.3694 - val_loss: 1.3877 - val_accuracy: 0.3848\n","Epoch 66/100\n","21/33 [==================>...........] - ETA: 19s - loss: 1.4318 - accuracy: 0.3776"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4408 - accuracy: 0.3732 - val_loss: 1.3739 - val_accuracy: 0.4043\n","Epoch 67/100\n"," 1/33 [..............................] - ETA: 1:02 - loss: 1.4593 - accuracy: 0.3906"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4357 - accuracy: 0.3932 - val_loss: 1.3724 - val_accuracy: 0.3848\n","Epoch 68/100\n"," 6/33 [====>.........................] - ETA: 44s - loss: 1.4052 - accuracy: 0.4115"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4442 - accuracy: 0.3844 - val_loss: 1.4285 - val_accuracy: 0.3809\n","Epoch 69/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.4964 - accuracy: 0.3652"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4941 - accuracy: 0.3596 - val_loss: 1.3892 - val_accuracy: 0.4023\n","Epoch 70/100\n","20/33 [=================>............] - ETA: 21s - loss: 1.4554 - accuracy: 0.3715"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.4441 - accuracy: 0.3762INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2/assets\n","33/33 [==============================] - 77s 2s/step - loss: 1.4441 - accuracy: 0.3762 - val_loss: 1.3723 - val_accuracy: 0.4121\n","Epoch 71/100\n","14/33 [===========>..................] - ETA: 33s - loss: 1.4532 - accuracy: 0.3733"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4384 - accuracy: 0.3779 - val_loss: 1.3662 - val_accuracy: 0.4082\n","Epoch 72/100\n"," 3/33 [=>............................] - ETA: 47s - loss: 1.4151 - accuracy: 0.3542"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4346 - accuracy: 0.3898 - val_loss: 1.3625 - val_accuracy: 0.3789\n","Epoch 73/100\n","28/33 [========================>.....] - ETA: 8s - loss: 1.4358 - accuracy: 0.3732"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4369 - accuracy: 0.3713 - val_loss: 1.3647 - val_accuracy: 0.3848\n","Epoch 74/100\n","28/33 [========================>.....] - ETA: 7s - loss: 1.4300 - accuracy: 0.3703"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4305 - accuracy: 0.3757 - val_loss: 1.3615 - val_accuracy: 0.3945\n","Epoch 75/100\n","25/33 [=====================>........] - ETA: 12s - loss: 1.4299 - accuracy: 0.3824"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4331 - accuracy: 0.3866 - val_loss: 1.3750 - val_accuracy: 0.3828\n","Epoch 76/100\n","22/33 [===================>..........] - ETA: 17s - loss: 1.4315 - accuracy: 0.3989"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4363 - accuracy: 0.3868 - val_loss: 1.3710 - val_accuracy: 0.3848\n","Epoch 77/100\n","11/33 [=========>....................] - ETA: 36s - loss: 1.4189 - accuracy: 0.3686"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4236 - accuracy: 0.3800 - val_loss: 1.3603 - val_accuracy: 0.3906\n","Epoch 78/100\n","11/33 [=========>....................] - ETA: 36s - loss: 1.4229 - accuracy: 0.4027"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4311 - accuracy: 0.3813 - val_loss: 1.3663 - val_accuracy: 0.3984\n","Epoch 79/100\n","25/33 [=====================>........] - ETA: 12s - loss: 1.4337 - accuracy: 0.3878"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4310 - accuracy: 0.3946 - val_loss: 1.3552 - val_accuracy: 0.3926\n","Epoch 80/100\n","23/33 [===================>..........] - ETA: 15s - loss: 1.4178 - accuracy: 0.3830"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4281 - accuracy: 0.3764 - val_loss: 1.3676 - val_accuracy: 0.3984\n","Epoch 81/100\n","15/33 [============>.................] - ETA: 29s - loss: 1.4255 - accuracy: 0.3927"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4309 - accuracy: 0.3859 - val_loss: 1.3661 - val_accuracy: 0.3906\n","Epoch 82/100\n"," 1/33 [..............................] - ETA: 1:06 - loss: 1.4193 - accuracy: 0.3906"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4404 - accuracy: 0.3868 - val_loss: 1.3532 - val_accuracy: 0.3887\n","Epoch 83/100\n"," 2/33 [>.............................] - ETA: 53s - loss: 1.4668 - accuracy: 0.3281 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4169 - accuracy: 0.3956 - val_loss: 1.3486 - val_accuracy: 0.4043\n","Epoch 84/100\n","12/33 [=========>....................] - ETA: 31s - loss: 1.4169 - accuracy: 0.4028"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4230 - accuracy: 0.3885 - val_loss: 1.3644 - val_accuracy: 0.3926\n","Epoch 85/100\n"," 9/33 [=======>......................] - ETA: 38s - loss: 1.4293 - accuracy: 0.3837"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4290 - accuracy: 0.3861 - val_loss: 1.3592 - val_accuracy: 0.3887\n","Epoch 86/100\n","14/33 [===========>..................] - ETA: 30s - loss: 1.4113 - accuracy: 0.4023"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4120 - accuracy: 0.3996 - val_loss: 1.3536 - val_accuracy: 0.4043\n","Epoch 87/100\n","28/33 [========================>.....] - ETA: 8s - loss: 1.4110 - accuracy: 0.3943"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4145 - accuracy: 0.3936 - val_loss: 1.3988 - val_accuracy: 0.4102\n","Epoch 88/100\n","22/33 [===================>..........] - ETA: 17s - loss: 1.4327 - accuracy: 0.3743"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4339 - accuracy: 0.3737 - val_loss: 1.3787 - val_accuracy: 0.3848\n","Epoch 89/100\n"," 9/33 [=======>......................] - ETA: 35s - loss: 1.3835 - accuracy: 0.3929"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4227 - accuracy: 0.3791 - val_loss: 1.3564 - val_accuracy: 0.3848\n","Epoch 90/100\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4270 - accuracy: 0.3873 - val_loss: 1.3564 - val_accuracy: 0.3945\n","Epoch 91/100\n","13/33 [==========>...................] - ETA: 32s - loss: 1.4391 - accuracy: 0.3810"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4236 - accuracy: 0.3970 - val_loss: 1.3627 - val_accuracy: 0.3984\n","Epoch 92/100\n","27/33 [=======================>......] - ETA: 9s - loss: 1.4159 - accuracy: 0.3809 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4142 - accuracy: 0.3805 - val_loss: 1.3451 - val_accuracy: 0.3867\n","Epoch 93/100\n","21/33 [==================>...........] - ETA: 19s - loss: 1.4036 - accuracy: 0.4001"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4142 - accuracy: 0.3980 - val_loss: 1.3499 - val_accuracy: 0.4023\n","Epoch 94/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.4144 - accuracy: 0.3964"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4099 - accuracy: 0.3936 - val_loss: 1.3525 - val_accuracy: 0.3984\n","Epoch 95/100\n"," 1/33 [..............................] - ETA: 1:10 - loss: 1.4142 - accuracy: 0.3672"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4057 - accuracy: 0.3878 - val_loss: 1.3525 - val_accuracy: 0.4043\n","Epoch 96/100\n","13/33 [==========>...................] - ETA: 33s - loss: 1.4172 - accuracy: 0.3894"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4096 - accuracy: 0.3866 - val_loss: 1.3525 - val_accuracy: 0.3945\n","Epoch 97/100\n","16/33 [=============>................] - ETA: 26s - loss: 1.4218 - accuracy: 0.3924"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4279 - accuracy: 0.3866 - val_loss: 1.3441 - val_accuracy: 0.3945\n","Epoch 98/100\n","13/33 [==========>...................] - ETA: 30s - loss: 1.4226 - accuracy: 0.3697"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4132 - accuracy: 0.3905 - val_loss: 1.3366 - val_accuracy: 0.3848\n","Epoch 99/100\n","28/33 [========================>.....] - ETA: 7s - loss: 1.4130 - accuracy: 0.3945"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4072 - accuracy: 0.3936 - val_loss: 1.3303 - val_accuracy: 0.4062\n","Epoch 100/100\n","18/33 [===============>..............] - ETA: 24s - loss: 1.3934 - accuracy: 0.3963"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3980 - accuracy: 0.3936 - val_loss: 1.3536 - val_accuracy: 0.3887\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f19dd035ad0>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["## Compile and fit model\n","\n","print(\"[INFO] compiling model...\")\n","opt = Adam(learning_rate = 1e-4)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# construct the set of callbacks\n","figPath = os.path.sep.join([output,\"facial_emotion_recognition33_2.png\"])\n","jsonPath = os.path.sep.join([output,\"facial_emotion_recognition33_2.json\"])\n","model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n","callbacks = [model_checkpoint_callback, TrainingMonitor(figPath, jsonPath=jsonPath, startAt=start_epoch)]\n","\n","model.fit(train_generator, steps_per_epoch = 4246 // 128, epochs = 100, validation_data = val_generator, validation_steps = 529 // 128, max_queue_size = 128 * 2, callbacks = callbacks, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"iUUM5jt2Aeek"},"source":["\n","\n","---\n","\n","TESTARE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17468,"status":"ok","timestamp":1653506151019,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"9HFQcLaZAeel","outputId":"ccbca6e8-1db5-48e4-e383-df8da13fac36"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 540 images belonging to 6 classes.\n","[INFO] loading /content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2...\n","4/4 [==============================] - 3s 588ms/step - loss: 1.4314 - accuracy: 0.3770\n","              precision    recall  f1-score   support\n","\n","           0       0.19      0.47      0.27        96\n","           1       0.15      0.07      0.10        81\n","           2       0.11      0.09      0.10        99\n","           3       0.23      0.19      0.21        94\n","           4       0.05      0.02      0.03        88\n","           5       0.12      0.10      0.11        82\n","\n","    accuracy                           0.16       540\n","   macro avg       0.14      0.16      0.14       540\n","weighted avg       0.14      0.16      0.14       540\n","\n","\n","\n","[INFO] accuracy: 37.70\n"]}],"source":["model = '/content/drive/MyDrive/GitHub/licenta/outputs/output33/checkpoint2'\n","\n","test_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","test_generator = test_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/test', target_size = (224, 224), batch_size = 128, class_mode = \"categorical\")\n","\n","# load the model from disk\n","print(\"[INFO] loading {}...\".format(model))\n","model = load_model(model)\n","\n","\n","# evaluate the network\n","(loss, acc) = model.evaluate(test_generator, steps = 540 // 128, max_queue_size = 128 * 2)\n","\n","# get the ground truth of your data. \n","test_labels  =test_generator.classes \n","\n","# predict the probability distribution of the data\n","predictions = model.predict(test_generator)\n","\n","# get the class with highest probability for each sample\n","y_pred = np.argmax(predictions, axis=-1)\n","\n","# get the classification report\n","print(classification_report(test_labels, y_pred))\n","\n","print(\"\\n\\n[INFO] accuracy: {:.2f}\".format(acc * 100))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"executionInfo":{"elapsed":814,"status":"ok","timestamp":1653506151826,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"5HogQ1lLAeel","outputId":"fcfeba8e-f76b-4ae1-912f-c252e84cc178"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","%matplotlib inline\n","plt.close('all')\n","\n","# Get the confusion matrix\n","cf_matrix = confusion_matrix(test_labels, y_pred)\n","\n","ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')\n","\n","ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n","ax.set_xlabel('\\nPredicted Category')\n","ax.set_ylabel('Actual Category ')\n","\n","## Ticket labels - List must be in alphabetical order\n","ax.xaxis.set_ticklabels(['angry','fear', 'happy', 'neutral', 'sad', 'surprise'])\n","ax.yaxis.set_ticklabels(['angry','fear', 'happy', 'neutral', 'sad', 'surprise'])\n","\n","## Display the visualization of the Confusion Matrix.\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"im-dgCd8e2pr"},"source":["# Deblocare straturi"]},{"cell_type":"markdown","metadata":{"id":"mgOIO6nfe2pt"},"source":["Se va schimba modelul EmotionVGG creat mai sus cu modelul ResNet50 pentru a testa pe un model preantrenat.\n","\n","In plus, se va face fine-tuning cu un strat de 512 de neuroni. Spre deosebire de 3.4, se va modifica modelul cu cel ResNet50.\n","\n","Se vor debloca straturile de la 143.\n","\n","Rezultatele se salveaza in outputs/output34."]},{"cell_type":"markdown","metadata":{"id":"_eKfT1Iae2pt"},"source":["\n","\n","---\n","\n","ANTRENARE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2931,"status":"ok","timestamp":1653590198984,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"K0aSr-Mre2pt","outputId":"e98db532-b87f-472d-e1df-69c98a869de6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 4246 images belonging to 6 classes.\n","Found 529 images belonging to 6 classes.\n"]}],"source":["# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","\n","# import the necessary packages\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from keras.models import load_model\n","import keras.backend as K\n","import argparse\n","import os\n","import tensorflow\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import ResNet50\n","\n","output = '/content/drive/MyDrive/GitHub/licenta/outputs/output34'\n","checkpoint = '/content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1'\n","model = None\n","start_epoch = 0\n","\n","train_datagen = ImageDataGenerator( rotation_range = 10, rescale = 1 / 255.0, zoom_range = 0.1, horizontal_flip = True, fill_mode = \"nearest\")\n","val_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/GitHub/licenta/dataset_fer/train', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')\n","val_generator = val_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/val', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')\n","\n","\n","# FOLOSIRE VGG16\n","\n","## Loading VGG16 model\n","\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n","base_model.trainable = False ## Not trainable weights\n","\n","## Add last layers\n","\n","flatten_layer = layers.Flatten()\n","dense_layer_1 = layers.Dense(512, activation='relu')\n","dropout_layer = layers.Dropout(0.5)\n","prediction_layer = layers.Dense(6, activation='softmax')\n","\n","\n","model = models.Sequential([base_model, flatten_layer, dense_layer_1, dropout_layer, prediction_layer])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1653587465811,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"HLqSOPVZe2pu","outputId":"f7c616f4-b8fb-4d9a-9531-e4126955f34a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] base model status... \n","\n","0 input_1 False\n","1 conv1_pad False\n","2 conv1_conv False\n","3 conv1_bn False\n","4 conv1_relu False\n","5 pool1_pad False\n","6 pool1_pool False\n","7 conv2_block1_1_conv False\n","8 conv2_block1_1_bn False\n","9 conv2_block1_1_relu False\n","10 conv2_block1_2_conv False\n","11 conv2_block1_2_bn False\n","12 conv2_block1_2_relu False\n","13 conv2_block1_0_conv False\n","14 conv2_block1_3_conv False\n","15 conv2_block1_0_bn False\n","16 conv2_block1_3_bn False\n","17 conv2_block1_add False\n","18 conv2_block1_out False\n","19 conv2_block2_1_conv False\n","20 conv2_block2_1_bn False\n","21 conv2_block2_1_relu False\n","22 conv2_block2_2_conv False\n","23 conv2_block2_2_bn False\n","24 conv2_block2_2_relu False\n","25 conv2_block2_3_conv False\n","26 conv2_block2_3_bn False\n","27 conv2_block2_add False\n","28 conv2_block2_out False\n","29 conv2_block3_1_conv False\n","30 conv2_block3_1_bn False\n","31 conv2_block3_1_relu False\n","32 conv2_block3_2_conv False\n","33 conv2_block3_2_bn False\n","34 conv2_block3_2_relu False\n","35 conv2_block3_3_conv False\n","36 conv2_block3_3_bn False\n","37 conv2_block3_add False\n","38 conv2_block3_out False\n","39 conv3_block1_1_conv False\n","40 conv3_block1_1_bn False\n","41 conv3_block1_1_relu False\n","42 conv3_block1_2_conv False\n","43 conv3_block1_2_bn False\n","44 conv3_block1_2_relu False\n","45 conv3_block1_0_conv False\n","46 conv3_block1_3_conv False\n","47 conv3_block1_0_bn False\n","48 conv3_block1_3_bn False\n","49 conv3_block1_add False\n","50 conv3_block1_out False\n","51 conv3_block2_1_conv False\n","52 conv3_block2_1_bn False\n","53 conv3_block2_1_relu False\n","54 conv3_block2_2_conv False\n","55 conv3_block2_2_bn False\n","56 conv3_block2_2_relu False\n","57 conv3_block2_3_conv False\n","58 conv3_block2_3_bn False\n","59 conv3_block2_add False\n","60 conv3_block2_out False\n","61 conv3_block3_1_conv False\n","62 conv3_block3_1_bn False\n","63 conv3_block3_1_relu False\n","64 conv3_block3_2_conv False\n","65 conv3_block3_2_bn False\n","66 conv3_block3_2_relu False\n","67 conv3_block3_3_conv False\n","68 conv3_block3_3_bn False\n","69 conv3_block3_add False\n","70 conv3_block3_out False\n","71 conv3_block4_1_conv False\n","72 conv3_block4_1_bn False\n","73 conv3_block4_1_relu False\n","74 conv3_block4_2_conv False\n","75 conv3_block4_2_bn False\n","76 conv3_block4_2_relu False\n","77 conv3_block4_3_conv False\n","78 conv3_block4_3_bn False\n","79 conv3_block4_add False\n","80 conv3_block4_out False\n","81 conv4_block1_1_conv False\n","82 conv4_block1_1_bn False\n","83 conv4_block1_1_relu False\n","84 conv4_block1_2_conv False\n","85 conv4_block1_2_bn False\n","86 conv4_block1_2_relu False\n","87 conv4_block1_0_conv False\n","88 conv4_block1_3_conv False\n","89 conv4_block1_0_bn False\n","90 conv4_block1_3_bn False\n","91 conv4_block1_add False\n","92 conv4_block1_out False\n","93 conv4_block2_1_conv False\n","94 conv4_block2_1_bn False\n","95 conv4_block2_1_relu False\n","96 conv4_block2_2_conv False\n","97 conv4_block2_2_bn False\n","98 conv4_block2_2_relu False\n","99 conv4_block2_3_conv False\n","100 conv4_block2_3_bn False\n","101 conv4_block2_add False\n","102 conv4_block2_out False\n","103 conv4_block3_1_conv False\n","104 conv4_block3_1_bn False\n","105 conv4_block3_1_relu False\n","106 conv4_block3_2_conv False\n","107 conv4_block3_2_bn False\n","108 conv4_block3_2_relu False\n","109 conv4_block3_3_conv False\n","110 conv4_block3_3_bn False\n","111 conv4_block3_add False\n","112 conv4_block3_out False\n","113 conv4_block4_1_conv False\n","114 conv4_block4_1_bn False\n","115 conv4_block4_1_relu False\n","116 conv4_block4_2_conv False\n","117 conv4_block4_2_bn False\n","118 conv4_block4_2_relu False\n","119 conv4_block4_3_conv False\n","120 conv4_block4_3_bn False\n","121 conv4_block4_add False\n","122 conv4_block4_out False\n","123 conv4_block5_1_conv False\n","124 conv4_block5_1_bn False\n","125 conv4_block5_1_relu False\n","126 conv4_block5_2_conv False\n","127 conv4_block5_2_bn False\n","128 conv4_block5_2_relu False\n","129 conv4_block5_3_conv False\n","130 conv4_block5_3_bn False\n","131 conv4_block5_add False\n","132 conv4_block5_out False\n","133 conv4_block6_1_conv False\n","134 conv4_block6_1_bn False\n","135 conv4_block6_1_relu False\n","136 conv4_block6_2_conv False\n","137 conv4_block6_2_bn False\n","138 conv4_block6_2_relu False\n","139 conv4_block6_3_conv False\n","140 conv4_block6_3_bn False\n","141 conv4_block6_add False\n","142 conv4_block6_out False\n","143 conv5_block1_1_conv False\n","144 conv5_block1_1_bn False\n","145 conv5_block1_1_relu False\n","146 conv5_block1_2_conv False\n","147 conv5_block1_2_bn False\n","148 conv5_block1_2_relu False\n","149 conv5_block1_0_conv False\n","150 conv5_block1_3_conv False\n","151 conv5_block1_0_bn False\n","152 conv5_block1_3_bn False\n","153 conv5_block1_add False\n","154 conv5_block1_out False\n","155 conv5_block2_1_conv False\n","156 conv5_block2_1_bn False\n","157 conv5_block2_1_relu False\n","158 conv5_block2_2_conv False\n","159 conv5_block2_2_bn False\n","160 conv5_block2_2_relu False\n","161 conv5_block2_3_conv False\n","162 conv5_block2_3_bn False\n","163 conv5_block2_add False\n","164 conv5_block2_out False\n","165 conv5_block3_1_conv False\n","166 conv5_block3_1_bn False\n","167 conv5_block3_1_relu False\n","168 conv5_block3_2_conv False\n","169 conv5_block3_2_bn False\n","170 conv5_block3_2_relu False\n","171 conv5_block3_3_conv False\n","172 conv5_block3_3_bn False\n","173 conv5_block3_add False\n","174 conv5_block3_out False\n","\n","\n","[INFO] entire model status...\n","\n","0 resnet50 False\n","1 flatten True\n","2 dense True\n","3 dropout True\n","4 dense_1 True\n"]}],"source":["print(\"[INFO] base model status... \\n\")\n","for i, layer in enumerate(base_model.layers):\n","  print(i, layer.name, layer.trainable)\n","\n","print(\"\\n\\n[INFO] entire model status...\\n\")\n","for i, layer in enumerate(model.layers):\n","  print(i, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2396541,"status":"ok","timestamp":1653589876591,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"VYwffcN_e2pu","outputId":"7b47544e-df5b-46ec-8f33-26f16cee7fe8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] compiling model...\n","Epoch 1/20\n"," 2/33 [>.............................] - ETA: 8:58 - loss: 3.8812 - accuracy: 0.1797 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 2.4417 - accuracy: 0.2035 INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1/assets\n","33/33 [==============================] - 936s 28s/step - loss: 2.4417 - accuracy: 0.2035 - val_loss: 1.7203 - val_accuracy: 0.3027\n","Epoch 2/20\n","28/33 [========================>.....] - ETA: 9s - loss: 1.7192 - accuracy: 0.2795 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.7193 - accuracy: 0.2771INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1/assets\n","33/33 [==============================] - 93s 3s/step - loss: 1.7193 - accuracy: 0.2771 - val_loss: 1.6818 - val_accuracy: 0.3301\n","Epoch 3/20\n","23/33 [===================>..........] - ETA: 18s - loss: 1.7156 - accuracy: 0.2833"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 1.7110 - accuracy: 0.2909 - val_loss: 1.6704 - val_accuracy: 0.3203\n","Epoch 4/20\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 64s 2s/step - loss: 1.6907 - accuracy: 0.3043 - val_loss: 1.6474 - val_accuracy: 0.3242\n","Epoch 5/20\n"," 2/33 [>.............................] - ETA: 1:00 - loss: 1.6584 - accuracy: 0.2891"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.6729 - accuracy: 0.3101INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1/assets\n","33/33 [==============================] - 91s 3s/step - loss: 1.6729 - accuracy: 0.3101 - val_loss: 1.6303 - val_accuracy: 0.3477\n","Epoch 6/20\n","13/33 [==========>...................] - ETA: 40s - loss: 1.6719 - accuracy: 0.3095"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 1.6662 - accuracy: 0.3113 - val_loss: 1.5989 - val_accuracy: 0.3438\n","Epoch 7/20\n","15/33 [============>.................] - ETA: 31s - loss: 1.6542 - accuracy: 0.3236"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.6515 - accuracy: 0.3220INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1/assets\n","33/33 [==============================] - 91s 3s/step - loss: 1.6515 - accuracy: 0.3220 - val_loss: 1.6005 - val_accuracy: 0.3613\n","Epoch 8/20\n","10/33 [========>.....................] - ETA: 47s - loss: 1.6414 - accuracy: 0.3180"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 1.6433 - accuracy: 0.3205 - val_loss: 1.5882 - val_accuracy: 0.3281\n","Epoch 9/20\n","12/33 [=========>....................] - ETA: 39s - loss: 1.6329 - accuracy: 0.3301"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.6173 - accuracy: 0.3344 - val_loss: 1.5853 - val_accuracy: 0.3457\n","Epoch 10/20\n","12/33 [=========>....................] - ETA: 39s - loss: 1.6395 - accuracy: 0.3105"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.6251 - accuracy: 0.3181 - val_loss: 1.5660 - val_accuracy: 0.3535\n","Epoch 11/20\n"," 6/33 [====>.........................] - ETA: 51s - loss: 1.6095 - accuracy: 0.3307"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.6047 - accuracy: 0.3412 - val_loss: 1.5583 - val_accuracy: 0.3555\n","Epoch 12/20\n"," 7/33 [=====>........................] - ETA: 49s - loss: 1.6245 - accuracy: 0.3270"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 64s 2s/step - loss: 1.6053 - accuracy: 0.3383 - val_loss: 1.5491 - val_accuracy: 0.3574\n","Epoch 13/20\n"," 5/33 [===>..........................] - ETA: 53s - loss: 1.5652 - accuracy: 0.3625"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5921 - accuracy: 0.3400INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1/assets\n","33/33 [==============================] - 92s 3s/step - loss: 1.5921 - accuracy: 0.3400 - val_loss: 1.5470 - val_accuracy: 0.3672\n","Epoch 14/20\n","29/33 [=========================>....] - ETA: 7s - loss: 1.6157 - accuracy: 0.3300"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.6107 - accuracy: 0.3315INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1/assets\n","33/33 [==============================] - 93s 3s/step - loss: 1.6107 - accuracy: 0.3315 - val_loss: 1.5272 - val_accuracy: 0.3730\n","Epoch 15/20\n"," 2/33 [>.............................] - ETA: 1:00 - loss: 1.5527 - accuracy: 0.3516"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.5968 - accuracy: 0.3334 - val_loss: 1.5372 - val_accuracy: 0.3633\n","Epoch 16/20\n","14/33 [===========>..................] - ETA: 33s - loss: 1.5940 - accuracy: 0.3393"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5812 - accuracy: 0.3490INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1/assets\n","33/33 [==============================] - 92s 3s/step - loss: 1.5812 - accuracy: 0.3490 - val_loss: 1.5065 - val_accuracy: 0.3906\n","Epoch 17/20\n","26/33 [======================>.......] - ETA: 13s - loss: 1.5819 - accuracy: 0.3380"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.5768 - accuracy: 0.3385INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1/assets\n","33/33 [==============================] - 92s 3s/step - loss: 1.5768 - accuracy: 0.3385 - val_loss: 1.5146 - val_accuracy: 0.3945\n","Epoch 18/20\n","33/33 [==============================] - ETA: 0s - loss: 1.5714 - accuracy: 0.3487"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 66s 2s/step - loss: 1.5714 - accuracy: 0.3487 - val_loss: 1.5156 - val_accuracy: 0.3633\n","Epoch 19/20\n","26/33 [======================>.......] - ETA: 12s - loss: 1.5606 - accuracy: 0.3557"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 64s 2s/step - loss: 1.5633 - accuracy: 0.3538 - val_loss: 1.5086 - val_accuracy: 0.3770\n","Epoch 20/20\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 64s 2s/step - loss: 1.5571 - accuracy: 0.3526 - val_loss: 1.5006 - val_accuracy: 0.3828\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f836ddd3850>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["## Compile and fit model\n","\n","print(\"[INFO] compiling model...\")\n","opt = Adam(learning_rate = 1e-4)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# construct the set of callbacks\n","figPath = os.path.sep.join([output,\"facial_emotion_recognition34_1.png\"])\n","jsonPath = os.path.sep.join([output,\"facial_emotion_recognitio34_1.json\"])\n","model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n","callbacks = [model_checkpoint_callback, TrainingMonitor(figPath, jsonPath=jsonPath, startAt=start_epoch)]\n","\n","model.fit(train_generator, steps_per_epoch = 4246 // 128, epochs = 20, validation_data = val_generator, validation_steps = 529 // 128, max_queue_size = 128 * 2, callbacks = callbacks, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"Ria3Jl2ee2pu"},"source":["\n","\n","---\n","\n","TESTARE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140748,"status":"ok","timestamp":1653590017325,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"4JJk5o1We2pv","outputId":"fdb6a088-d727-4943-ad9f-a536bb6aaea5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 540 images belonging to 6 classes.\n","[INFO] loading /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1...\n","4/4 [==============================] - 87s 28s/step - loss: 1.5545 - accuracy: 0.3750\n","              precision    recall  f1-score   support\n","\n","           0       0.18      0.50      0.26        96\n","           1       0.18      0.14      0.15        81\n","           2       0.21      0.12      0.15        99\n","           3       0.23      0.22      0.23        94\n","           4       0.09      0.01      0.02        88\n","           5       0.16      0.10      0.12        82\n","\n","    accuracy                           0.19       540\n","   macro avg       0.17      0.18      0.16       540\n","weighted avg       0.18      0.19      0.16       540\n","\n","\n","\n","[INFO] accuracy: 37.50\n"]}],"source":["# import the necessary packages\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import load_model\n","import argparse\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelBinarizer\n","import numpy as np\n","\n","model = '/content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint1'\n","\n","test_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","test_generator = test_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/test', target_size = (224, 224), batch_size = 128, class_mode = \"categorical\")\n","\n","# load the model from disk\n","print(\"[INFO] loading {}...\".format(model))\n","model = load_model(model)\n","\n","\n","# evaluate the network\n","(loss, acc) = model.evaluate(test_generator, steps = 540 // 128, max_queue_size = 128 * 2)\n","\n","# get the ground truth of your data. \n","test_labels  =test_generator.classes \n","\n","# predict the probability distribution of the data\n","predictions = model.predict(test_generator)\n","\n","# get the class with highest probability for each sample\n","y_pred = np.argmax(predictions, axis=-1)\n","\n","# get the classification report\n","print(classification_report(test_labels, y_pred))\n","\n","print(\"\\n\\n[INFO] accuracy: {:.2f}\".format(acc * 100))"]},{"cell_type":"markdown","metadata":{"id":"AnxTJzpfe2pv"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","ANTRENARE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1653590212979,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"73am60vke2pv","outputId":"f6f464a8-33ed-4fd7-d378-382216a851e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] base model status... \n","\n","0 input_2 False\n","1 conv1_pad False\n","2 conv1_conv False\n","3 conv1_bn False\n","4 conv1_relu False\n","5 pool1_pad False\n","6 pool1_pool False\n","7 conv2_block1_1_conv False\n","8 conv2_block1_1_bn False\n","9 conv2_block1_1_relu False\n","10 conv2_block1_2_conv False\n","11 conv2_block1_2_bn False\n","12 conv2_block1_2_relu False\n","13 conv2_block1_0_conv False\n","14 conv2_block1_3_conv False\n","15 conv2_block1_0_bn False\n","16 conv2_block1_3_bn False\n","17 conv2_block1_add False\n","18 conv2_block1_out False\n","19 conv2_block2_1_conv False\n","20 conv2_block2_1_bn False\n","21 conv2_block2_1_relu False\n","22 conv2_block2_2_conv False\n","23 conv2_block2_2_bn False\n","24 conv2_block2_2_relu False\n","25 conv2_block2_3_conv False\n","26 conv2_block2_3_bn False\n","27 conv2_block2_add False\n","28 conv2_block2_out False\n","29 conv2_block3_1_conv False\n","30 conv2_block3_1_bn False\n","31 conv2_block3_1_relu False\n","32 conv2_block3_2_conv False\n","33 conv2_block3_2_bn False\n","34 conv2_block3_2_relu False\n","35 conv2_block3_3_conv False\n","36 conv2_block3_3_bn False\n","37 conv2_block3_add False\n","38 conv2_block3_out False\n","39 conv3_block1_1_conv False\n","40 conv3_block1_1_bn False\n","41 conv3_block1_1_relu False\n","42 conv3_block1_2_conv False\n","43 conv3_block1_2_bn False\n","44 conv3_block1_2_relu False\n","45 conv3_block1_0_conv False\n","46 conv3_block1_3_conv False\n","47 conv3_block1_0_bn False\n","48 conv3_block1_3_bn False\n","49 conv3_block1_add False\n","50 conv3_block1_out False\n","51 conv3_block2_1_conv False\n","52 conv3_block2_1_bn False\n","53 conv3_block2_1_relu False\n","54 conv3_block2_2_conv False\n","55 conv3_block2_2_bn False\n","56 conv3_block2_2_relu False\n","57 conv3_block2_3_conv False\n","58 conv3_block2_3_bn False\n","59 conv3_block2_add False\n","60 conv3_block2_out False\n","61 conv3_block3_1_conv False\n","62 conv3_block3_1_bn False\n","63 conv3_block3_1_relu False\n","64 conv3_block3_2_conv False\n","65 conv3_block3_2_bn False\n","66 conv3_block3_2_relu False\n","67 conv3_block3_3_conv False\n","68 conv3_block3_3_bn False\n","69 conv3_block3_add False\n","70 conv3_block3_out False\n","71 conv3_block4_1_conv False\n","72 conv3_block4_1_bn False\n","73 conv3_block4_1_relu False\n","74 conv3_block4_2_conv False\n","75 conv3_block4_2_bn False\n","76 conv3_block4_2_relu False\n","77 conv3_block4_3_conv False\n","78 conv3_block4_3_bn False\n","79 conv3_block4_add False\n","80 conv3_block4_out False\n","81 conv4_block1_1_conv False\n","82 conv4_block1_1_bn False\n","83 conv4_block1_1_relu False\n","84 conv4_block1_2_conv False\n","85 conv4_block1_2_bn False\n","86 conv4_block1_2_relu False\n","87 conv4_block1_0_conv False\n","88 conv4_block1_3_conv False\n","89 conv4_block1_0_bn False\n","90 conv4_block1_3_bn False\n","91 conv4_block1_add False\n","92 conv4_block1_out False\n","93 conv4_block2_1_conv False\n","94 conv4_block2_1_bn False\n","95 conv4_block2_1_relu False\n","96 conv4_block2_2_conv False\n","97 conv4_block2_2_bn False\n","98 conv4_block2_2_relu False\n","99 conv4_block2_3_conv False\n","100 conv4_block2_3_bn False\n","101 conv4_block2_add False\n","102 conv4_block2_out False\n","103 conv4_block3_1_conv False\n","104 conv4_block3_1_bn False\n","105 conv4_block3_1_relu False\n","106 conv4_block3_2_conv False\n","107 conv4_block3_2_bn False\n","108 conv4_block3_2_relu False\n","109 conv4_block3_3_conv False\n","110 conv4_block3_3_bn False\n","111 conv4_block3_add False\n","112 conv4_block3_out False\n","113 conv4_block4_1_conv False\n","114 conv4_block4_1_bn False\n","115 conv4_block4_1_relu False\n","116 conv4_block4_2_conv False\n","117 conv4_block4_2_bn False\n","118 conv4_block4_2_relu False\n","119 conv4_block4_3_conv False\n","120 conv4_block4_3_bn False\n","121 conv4_block4_add False\n","122 conv4_block4_out False\n","123 conv4_block5_1_conv False\n","124 conv4_block5_1_bn False\n","125 conv4_block5_1_relu False\n","126 conv4_block5_2_conv False\n","127 conv4_block5_2_bn False\n","128 conv4_block5_2_relu False\n","129 conv4_block5_3_conv False\n","130 conv4_block5_3_bn False\n","131 conv4_block5_add False\n","132 conv4_block5_out False\n","133 conv4_block6_1_conv False\n","134 conv4_block6_1_bn False\n","135 conv4_block6_1_relu False\n","136 conv4_block6_2_conv False\n","137 conv4_block6_2_bn False\n","138 conv4_block6_2_relu False\n","139 conv4_block6_3_conv False\n","140 conv4_block6_3_bn False\n","141 conv4_block6_add False\n","142 conv4_block6_out False\n","143 conv5_block1_1_conv True\n","144 conv5_block1_1_bn True\n","145 conv5_block1_1_relu True\n","146 conv5_block1_2_conv True\n","147 conv5_block1_2_bn True\n","148 conv5_block1_2_relu True\n","149 conv5_block1_0_conv True\n","150 conv5_block1_3_conv True\n","151 conv5_block1_0_bn True\n","152 conv5_block1_3_bn True\n","153 conv5_block1_add True\n","154 conv5_block1_out True\n","155 conv5_block2_1_conv True\n","156 conv5_block2_1_bn True\n","157 conv5_block2_1_relu True\n","158 conv5_block2_2_conv True\n","159 conv5_block2_2_bn True\n","160 conv5_block2_2_relu True\n","161 conv5_block2_3_conv True\n","162 conv5_block2_3_bn True\n","163 conv5_block2_add True\n","164 conv5_block2_out True\n","165 conv5_block3_1_conv True\n","166 conv5_block3_1_bn True\n","167 conv5_block3_1_relu True\n","168 conv5_block3_2_conv True\n","169 conv5_block3_2_bn True\n","170 conv5_block3_2_relu True\n","171 conv5_block3_3_conv True\n","172 conv5_block3_3_bn True\n","173 conv5_block3_add True\n","174 conv5_block3_out True\n","\n","\n","[INFO] entire model status...\n","\n","\n","0 resnet50 False\n","1 flatten_1 True\n","2 dense_2 True\n","3 dropout_1 True\n","4 dense_3 True\n"]}],"source":["output = '/content/drive/MyDrive/GitHub/licenta/outputs/output34'\n","checkpoint = '/content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2'\n","start_epoch = 0\n","\n","for layer in base_model.layers[143:]:\n","  layer.trainable = True\n","\n","print(\"[INFO] base model status... \\n\")\n","for i, layer in enumerate(base_model.layers):\n","  print(i, layer.name, layer.trainable)\n","\n","print(\"\\n\\n[INFO] entire model status...\\n\\n\")\n","for i, layer in enumerate(model.layers):\n","  print(i, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7175288,"status":"ok","timestamp":1653597424980,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"RfkDC85_e2pw","outputId":"6108af24-e7ae-4270-a4ca-4a6147eaa728"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] compiling model...\n","Epoch 1/100\n","26/33 [======================>.......] - ETA: 14s - loss: 2.1877 - accuracy: 0.2831"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 2.0646 - accuracy: 0.2948INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 106s 3s/step - loss: 2.0646 - accuracy: 0.2948 - val_loss: 1.9183 - val_accuracy: 0.1797\n","Epoch 2/100\n","31/33 [===========================>..] - ETA: 4s - loss: 1.5568 - accuracy: 0.3669"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 73s 2s/step - loss: 1.5572 - accuracy: 0.3655 - val_loss: 1.8949 - val_accuracy: 0.1699\n","Epoch 3/100\n"," 4/33 [==>...........................] - ETA: 59s - loss: 1.5202 - accuracy: 0.3652 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 72s 2s/step - loss: 1.5047 - accuracy: 0.3771 - val_loss: 1.9656 - val_accuracy: 0.1777\n","Epoch 4/100\n","32/33 [============================>.] - ETA: 1s - loss: 1.4586 - accuracy: 0.4118"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.4582 - accuracy: 0.4099INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 94s 3s/step - loss: 1.4582 - accuracy: 0.4099 - val_loss: 2.0056 - val_accuracy: 0.2090\n","Epoch 5/100\n","12/33 [=========>....................] - ETA: 43s - loss: 1.4230 - accuracy: 0.4264"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 68s 2s/step - loss: 1.4338 - accuracy: 0.4160 - val_loss: 2.0794 - val_accuracy: 0.2051\n","Epoch 6/100\n","20/33 [=================>............] - ETA: 25s - loss: 1.3951 - accuracy: 0.4305"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.4085 - accuracy: 0.4209INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 95s 3s/step - loss: 1.4085 - accuracy: 0.4209 - val_loss: 1.9606 - val_accuracy: 0.2188\n","Epoch 7/100\n","31/33 [===========================>..] - ETA: 3s - loss: 1.4029 - accuracy: 0.4205"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 1.4040 - accuracy: 0.4186 - val_loss: 2.1304 - val_accuracy: 0.2168\n","Epoch 8/100\n","16/33 [=============>................] - ETA: 32s - loss: 1.3457 - accuracy: 0.4409"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 64s 2s/step - loss: 1.3687 - accuracy: 0.4369 - val_loss: 1.9024 - val_accuracy: 0.2012\n","Epoch 9/100\n","15/33 [============>.................] - ETA: 31s - loss: 1.3553 - accuracy: 0.4399"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.3462 - accuracy: 0.4427INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 92s 3s/step - loss: 1.3462 - accuracy: 0.4427 - val_loss: 1.7721 - val_accuracy: 0.2754\n","Epoch 10/100\n","18/33 [===============>..............] - ETA: 29s - loss: 1.3352 - accuracy: 0.4345"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.3292 - accuracy: 0.4463 - val_loss: 1.7565 - val_accuracy: 0.2734\n","Epoch 11/100\n","28/33 [========================>.....] - ETA: 9s - loss: 1.3047 - accuracy: 0.4699 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.3052 - accuracy: 0.4687INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 90s 3s/step - loss: 1.3052 - accuracy: 0.4687 - val_loss: 1.5566 - val_accuracy: 0.2832\n","Epoch 12/100\n"," 8/33 [======>.......................] - ETA: 51s - loss: 1.2501 - accuracy: 0.5068"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.3102 - accuracy: 0.4706INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 93s 3s/step - loss: 1.3102 - accuracy: 0.4706 - val_loss: 1.5178 - val_accuracy: 0.3184\n","Epoch 13/100\n","20/33 [=================>............] - ETA: 25s - loss: 1.2825 - accuracy: 0.4695"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.2818 - accuracy: 0.4750INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 91s 3s/step - loss: 1.2818 - accuracy: 0.4750 - val_loss: 1.3686 - val_accuracy: 0.4160\n","Epoch 14/100\n","11/33 [=========>....................] - ETA: 43s - loss: 1.2803 - accuracy: 0.4673"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.2614 - accuracy: 0.4755INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 91s 3s/step - loss: 1.2614 - accuracy: 0.4755 - val_loss: 1.3131 - val_accuracy: 0.4766\n","Epoch 15/100\n","16/33 [=============>................] - ETA: 31s - loss: 1.2727 - accuracy: 0.4660"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.2668 - accuracy: 0.4752INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 93s 3s/step - loss: 1.2668 - accuracy: 0.4752 - val_loss: 1.2743 - val_accuracy: 0.4883\n","Epoch 16/100\n"," 6/33 [====>.........................] - ETA: 53s - loss: 1.2208 - accuracy: 0.4792"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.2341 - accuracy: 0.4891 - val_loss: 1.2297 - val_accuracy: 0.4824\n","Epoch 17/100\n"," 8/33 [======>.......................] - ETA: 46s - loss: 1.2231 - accuracy: 0.4990"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.2405 - accuracy: 0.4806INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 91s 3s/step - loss: 1.2405 - accuracy: 0.4806 - val_loss: 1.1603 - val_accuracy: 0.5156\n","Epoch 18/100\n","23/33 [===================>..........] - ETA: 18s - loss: 1.1994 - accuracy: 0.5053"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 63s 2s/step - loss: 1.2042 - accuracy: 0.5080 - val_loss: 1.1902 - val_accuracy: 0.4980\n","Epoch 19/100\n","23/33 [===================>..........] - ETA: 17s - loss: 1.1926 - accuracy: 0.5208"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.1909 - accuracy: 0.5151INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 90s 3s/step - loss: 1.1909 - accuracy: 0.5151 - val_loss: 1.1823 - val_accuracy: 0.5332\n","Epoch 20/100\n","21/33 [==================>...........] - ETA: 22s - loss: 1.1853 - accuracy: 0.5119"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 64s 2s/step - loss: 1.1923 - accuracy: 0.5041 - val_loss: 1.2107 - val_accuracy: 0.5293\n","Epoch 21/100\n"," 5/33 [===>..........................] - ETA: 52s - loss: 1.1849 - accuracy: 0.5188"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 63s 2s/step - loss: 1.1861 - accuracy: 0.5104 - val_loss: 1.1443 - val_accuracy: 0.5293\n","Epoch 22/100\n","20/33 [=================>............] - ETA: 24s - loss: 1.1295 - accuracy: 0.5391"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 63s 2s/step - loss: 1.1343 - accuracy: 0.5352 - val_loss: 1.1303 - val_accuracy: 0.5137\n","Epoch 23/100\n"," 6/33 [====>.........................] - ETA: 51s - loss: 1.1579 - accuracy: 0.5182"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 64s 2s/step - loss: 1.1523 - accuracy: 0.5279 - val_loss: 1.1102 - val_accuracy: 0.5156\n","Epoch 24/100\n","14/33 [===========>..................] - ETA: 33s - loss: 1.1527 - accuracy: 0.5178"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.1688 - accuracy: 0.5214INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 91s 3s/step - loss: 1.1688 - accuracy: 0.5214 - val_loss: 1.1282 - val_accuracy: 0.5352\n","Epoch 25/100\n","17/33 [==============>...............] - ETA: 30s - loss: 1.1586 - accuracy: 0.5386"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.1547 - accuracy: 0.5393INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 94s 3s/step - loss: 1.1547 - accuracy: 0.5393 - val_loss: 1.1471 - val_accuracy: 0.5410\n","Epoch 26/100\n","13/33 [==========>...................] - ETA: 37s - loss: 1.1641 - accuracy: 0.5295"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 1.1436 - accuracy: 0.5255 - val_loss: 1.1222 - val_accuracy: 0.5410\n","Epoch 27/100\n","15/33 [============>.................] - ETA: 33s - loss: 1.1239 - accuracy: 0.5453"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.1288 - accuracy: 0.5469INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 93s 3s/step - loss: 1.1288 - accuracy: 0.5469 - val_loss: 1.0951 - val_accuracy: 0.5605\n","Epoch 28/100\n","22/33 [===================>..........] - ETA: 20s - loss: 1.1366 - accuracy: 0.5443"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 1.1332 - accuracy: 0.5432 - val_loss: 1.1392 - val_accuracy: 0.5469\n","Epoch 29/100\n","14/33 [===========>..................] - ETA: 36s - loss: 1.0674 - accuracy: 0.5603"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0851 - accuracy: 0.5522 - val_loss: 1.1919 - val_accuracy: 0.5352\n","Epoch 30/100\n","31/33 [===========================>..] - ETA: 3s - loss: 1.1116 - accuracy: 0.5438"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.1086 - accuracy: 0.5486 - val_loss: 1.1129 - val_accuracy: 0.5488\n","Epoch 31/100\n","26/33 [======================>.......] - ETA: 12s - loss: 1.1086 - accuracy: 0.5500"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.1038 - accuracy: 0.5503INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 92s 3s/step - loss: 1.1038 - accuracy: 0.5503 - val_loss: 1.0914 - val_accuracy: 0.5645\n","Epoch 32/100\n","14/33 [===========>..................] - ETA: 35s - loss: 1.0503 - accuracy: 0.5795"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.0868 - accuracy: 0.5614INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 94s 3s/step - loss: 1.0868 - accuracy: 0.5614 - val_loss: 1.1042 - val_accuracy: 0.5781\n","Epoch 33/100\n","17/33 [==============>...............] - ETA: 31s - loss: 1.0943 - accuracy: 0.5666"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 1.0913 - accuracy: 0.5651 - val_loss: 1.1039 - val_accuracy: 0.5684\n","Epoch 34/100\n","12/33 [=========>....................] - ETA: 36s - loss: 1.1102 - accuracy: 0.5657"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0894 - accuracy: 0.5583 - val_loss: 1.1116 - val_accuracy: 0.5508\n","Epoch 35/100\n","11/33 [=========>....................] - ETA: 42s - loss: 1.1049 - accuracy: 0.5518"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 64s 2s/step - loss: 1.0736 - accuracy: 0.5658 - val_loss: 1.1472 - val_accuracy: 0.5547\n","Epoch 36/100\n","22/33 [===================>..........] - ETA: 20s - loss: 1.0646 - accuracy: 0.5539"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.0445 - accuracy: 0.5648INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 93s 3s/step - loss: 1.0445 - accuracy: 0.5648 - val_loss: 1.0594 - val_accuracy: 0.5918\n","Epoch 37/100\n","25/33 [=====================>........] - ETA: 15s - loss: 1.0200 - accuracy: 0.5878"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 1.0317 - accuracy: 0.5833 - val_loss: 1.0963 - val_accuracy: 0.5586\n","Epoch 38/100\n"," 3/33 [=>............................] - ETA: 57s - loss: 1.0770 - accuracy: 0.5495"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 1.0298 - accuracy: 0.5775INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 92s 3s/step - loss: 1.0298 - accuracy: 0.5775 - val_loss: 1.0632 - val_accuracy: 0.6133\n","Epoch 39/100\n","33/33 [==============================] - ETA: 0s - loss: 1.0330 - accuracy: 0.5879"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 66s 2s/step - loss: 1.0330 - accuracy: 0.5879 - val_loss: 1.1013 - val_accuracy: 0.5781\n","Epoch 40/100\n","32/33 [============================>.] - ETA: 1s - loss: 1.0584 - accuracy: 0.5687"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0585 - accuracy: 0.5690 - val_loss: 1.0906 - val_accuracy: 0.5586\n","Epoch 41/100\n"," 4/33 [==>...........................] - ETA: 54s - loss: 1.0736 - accuracy: 0.5293"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0396 - accuracy: 0.5789 - val_loss: 1.0994 - val_accuracy: 0.5840\n","Epoch 42/100\n","22/33 [===================>..........] - ETA: 20s - loss: 1.0421 - accuracy: 0.5845"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0652 - accuracy: 0.5753 - val_loss: 1.0978 - val_accuracy: 0.5547\n","Epoch 43/100\n"," 4/33 [==>...........................] - ETA: 55s - loss: 1.0726 - accuracy: 0.5898"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0479 - accuracy: 0.5814 - val_loss: 1.0504 - val_accuracy: 0.5605\n","Epoch 44/100\n","26/33 [======================>.......] - ETA: 12s - loss: 1.0655 - accuracy: 0.5664"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0633 - accuracy: 0.5663 - val_loss: 1.0773 - val_accuracy: 0.5605\n","Epoch 45/100\n","28/33 [========================>.....] - ETA: 9s - loss: 1.0299 - accuracy: 0.5857 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0268 - accuracy: 0.5886 - val_loss: 1.0765 - val_accuracy: 0.5742\n","Epoch 46/100\n","29/33 [=========================>....] - ETA: 7s - loss: 1.0346 - accuracy: 0.5799"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0340 - accuracy: 0.5782 - val_loss: 1.1005 - val_accuracy: 0.5430\n","Epoch 47/100\n","12/33 [=========>....................] - ETA: 40s - loss: 1.0668 - accuracy: 0.5729"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0360 - accuracy: 0.5821 - val_loss: 1.0817 - val_accuracy: 0.5820\n","Epoch 48/100\n","22/33 [===================>..........] - ETA: 20s - loss: 1.0340 - accuracy: 0.5878"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 1.0260 - accuracy: 0.5913 - val_loss: 1.0586 - val_accuracy: 0.5723\n","Epoch 49/100\n","10/33 [========>.....................] - ETA: 45s - loss: 1.0120 - accuracy: 0.5906"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 1.0071 - accuracy: 0.5964 - val_loss: 1.0514 - val_accuracy: 0.5742\n","Epoch 50/100\n","18/33 [===============>..............] - ETA: 29s - loss: 0.9962 - accuracy: 0.5968"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 68s 2s/step - loss: 0.9785 - accuracy: 0.6018 - val_loss: 1.0611 - val_accuracy: 0.5625\n","Epoch 51/100\n","21/33 [==================>...........] - ETA: 22s - loss: 0.9764 - accuracy: 0.6146"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.9767 - accuracy: 0.6093 - val_loss: 1.0648 - val_accuracy: 0.6035\n","Epoch 52/100\n","13/33 [==========>...................] - ETA: 38s - loss: 0.9602 - accuracy: 0.6088"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.9802 - accuracy: 0.6059 - val_loss: 1.0524 - val_accuracy: 0.5879\n","Epoch 53/100\n","27/33 [=======================>......] - ETA: 11s - loss: 0.9765 - accuracy: 0.6015"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.9757 - accuracy: 0.5988 - val_loss: 1.0341 - val_accuracy: 0.5977\n","Epoch 54/100\n","30/33 [==========================>...] - ETA: 5s - loss: 0.9668 - accuracy: 0.6152"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.9648 - accuracy: 0.6158 - val_loss: 1.0810 - val_accuracy: 0.5605\n","Epoch 55/100\n","21/33 [==================>...........] - ETA: 22s - loss: 1.0070 - accuracy: 0.5995"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.9858 - accuracy: 0.6044 - val_loss: 1.0360 - val_accuracy: 0.5938\n","Epoch 56/100\n","33/33 [==============================] - ETA: 0s - loss: 0.9636 - accuracy: 0.6153"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 67s 2s/step - loss: 0.9636 - accuracy: 0.6153 - val_loss: 1.0570 - val_accuracy: 0.5977\n","Epoch 57/100\n"," 5/33 [===>..........................] - ETA: 53s - loss: 1.0102 - accuracy: 0.5813"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.9659 - accuracy: 0.6139 - val_loss: 1.0730 - val_accuracy: 0.5957\n","Epoch 58/100\n","12/33 [=========>....................] - ETA: 39s - loss: 0.9200 - accuracy: 0.6237"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.9410 - accuracy: 0.6204 - val_loss: 1.0667 - val_accuracy: 0.5820\n","Epoch 59/100\n","25/33 [=====================>........] - ETA: 14s - loss: 0.9545 - accuracy: 0.6096"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.9648 - accuracy: 0.6076 - val_loss: 1.0196 - val_accuracy: 0.6074\n","Epoch 60/100\n","20/33 [=================>............] - ETA: 25s - loss: 0.9031 - accuracy: 0.6336"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.9107 - accuracy: 0.6331 - val_loss: 1.0717 - val_accuracy: 0.5996\n","Epoch 61/100\n","29/33 [=========================>....] - ETA: 7s - loss: 0.9413 - accuracy: 0.6298"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.9367 - accuracy: 0.6302 - val_loss: 1.0038 - val_accuracy: 0.5977\n","Epoch 62/100\n","13/33 [==========>...................] - ETA: 35s - loss: 0.9185 - accuracy: 0.6220"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.9197 - accuracy: 0.6229 - val_loss: 1.0431 - val_accuracy: 0.6074\n","Epoch 63/100\n","22/33 [===================>..........] - ETA: 21s - loss: 0.9253 - accuracy: 0.6303"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.9184 - accuracy: 0.6289 - val_loss: 1.0452 - val_accuracy: 0.5859\n","Epoch 64/100\n","33/33 [==============================] - ETA: 0s - loss: 0.9248 - accuracy: 0.6207"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 65s 2s/step - loss: 0.9248 - accuracy: 0.6207 - val_loss: 1.0970 - val_accuracy: 0.5957\n","Epoch 65/100\n","18/33 [===============>..............] - ETA: 27s - loss: 0.8916 - accuracy: 0.6442"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.8968 - accuracy: 0.6394 - val_loss: 1.0572 - val_accuracy: 0.6133\n","Epoch 66/100\n","13/33 [==========>...................] - ETA: 38s - loss: 0.9249 - accuracy: 0.6232"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.9196 - accuracy: 0.6268 - val_loss: 1.0536 - val_accuracy: 0.6016\n","Epoch 67/100\n"," 7/33 [=====>........................] - ETA: 42s - loss: 0.8947 - accuracy: 0.6544"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.9011 - accuracy: 0.6372 - val_loss: 1.0689 - val_accuracy: 0.5820\n","Epoch 68/100\n","18/33 [===============>..............] - ETA: 27s - loss: 0.9180 - accuracy: 0.6383"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.9259 - accuracy: 0.6280 - val_loss: 1.0497 - val_accuracy: 0.5781\n","Epoch 69/100\n","26/33 [======================>.......] - ETA: 13s - loss: 0.8931 - accuracy: 0.6356"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 0.9016 - accuracy: 0.6350INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 95s 3s/step - loss: 0.9016 - accuracy: 0.6350 - val_loss: 1.0130 - val_accuracy: 0.6172\n","Epoch 70/100\n"," 8/33 [======>.......................] - ETA: 51s - loss: 0.8940 - accuracy: 0.6396"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.8801 - accuracy: 0.6486 - val_loss: 1.0590 - val_accuracy: 0.6172\n","Epoch 71/100\n","32/33 [============================>.] - ETA: 1s - loss: 0.8624 - accuracy: 0.6489"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.8608 - accuracy: 0.6491 - val_loss: 1.0999 - val_accuracy: 0.6152\n","Epoch 72/100\n"," 5/33 [===>..........................] - ETA: 54s - loss: 0.8567 - accuracy: 0.6734"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8719 - accuracy: 0.6591 - val_loss: 1.0076 - val_accuracy: 0.6016\n","Epoch 73/100\n","28/33 [========================>.....] - ETA: 9s - loss: 0.8703 - accuracy: 0.6616 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 0.8660 - accuracy: 0.6637INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 94s 3s/step - loss: 0.8660 - accuracy: 0.6637 - val_loss: 1.0000 - val_accuracy: 0.6191\n","Epoch 74/100\n"," 4/33 [==>...........................] - ETA: 59s - loss: 0.7692 - accuracy: 0.6758 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.8574 - accuracy: 0.6540 - val_loss: 1.0342 - val_accuracy: 0.6055\n","Epoch 75/100\n","16/33 [=============>................] - ETA: 30s - loss: 0.8970 - accuracy: 0.6498"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - ETA: 0s - loss: 0.8763 - accuracy: 0.6544INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 93s 3s/step - loss: 0.8763 - accuracy: 0.6544 - val_loss: 1.0486 - val_accuracy: 0.6328\n","Epoch 76/100\n","20/33 [=================>............] - ETA: 25s - loss: 0.8695 - accuracy: 0.6551"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.8637 - accuracy: 0.6532 - val_loss: 1.0920 - val_accuracy: 0.6133\n","Epoch 77/100\n","21/33 [==================>...........] - ETA: 22s - loss: 0.8539 - accuracy: 0.6681"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8398 - accuracy: 0.6688 - val_loss: 1.0515 - val_accuracy: 0.6191\n","Epoch 78/100\n"," 3/33 [=>............................] - ETA: 55s - loss: 0.8034 - accuracy: 0.6771"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.8612 - accuracy: 0.6578 - val_loss: 1.0534 - val_accuracy: 0.6191\n","Epoch 79/100\n","27/33 [=======================>......] - ETA: 11s - loss: 0.8854 - accuracy: 0.6394"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8809 - accuracy: 0.6430 - val_loss: 1.0379 - val_accuracy: 0.6289\n","Epoch 80/100\n"," 8/33 [======>.......................] - ETA: 47s - loss: 0.8410 - accuracy: 0.6719"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8715 - accuracy: 0.6508 - val_loss: 1.0903 - val_accuracy: 0.5957\n","Epoch 81/100\n","12/33 [=========>....................] - ETA: 39s - loss: 0.8482 - accuracy: 0.6458"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.8396 - accuracy: 0.6591 - val_loss: 1.0765 - val_accuracy: 0.6055\n","Epoch 82/100\n","23/33 [===================>..........] - ETA: 18s - loss: 0.8190 - accuracy: 0.6698"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8165 - accuracy: 0.6748 - val_loss: 1.0590 - val_accuracy: 0.6016\n","Epoch 83/100\n","26/33 [======================>.......] - ETA: 12s - loss: 0.8465 - accuracy: 0.6570"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8402 - accuracy: 0.6608 - val_loss: 1.0422 - val_accuracy: 0.6094\n","Epoch 84/100\n","29/33 [=========================>....] - ETA: 7s - loss: 0.8340 - accuracy: 0.6791"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8387 - accuracy: 0.6782 - val_loss: 1.0450 - val_accuracy: 0.6113\n","Epoch 85/100\n","17/33 [==============>...............] - ETA: 28s - loss: 0.7994 - accuracy: 0.6696"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8178 - accuracy: 0.6666 - val_loss: 1.0720 - val_accuracy: 0.6152\n","Epoch 86/100\n"," 8/33 [======>.......................] - ETA: 48s - loss: 0.8277 - accuracy: 0.6543"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8152 - accuracy: 0.6727 - val_loss: 1.0194 - val_accuracy: 0.6270\n","Epoch 87/100\n"," 5/33 [===>..........................] - ETA: 53s - loss: 0.9022 - accuracy: 0.6648"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8724 - accuracy: 0.6423 - val_loss: 1.0785 - val_accuracy: 0.6191\n","Epoch 88/100\n","23/33 [===================>..........] - ETA: 18s - loss: 0.8298 - accuracy: 0.6681"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8349 - accuracy: 0.6666 - val_loss: 1.0405 - val_accuracy: 0.6016\n","Epoch 89/100\n"," 5/33 [===>..........................] - ETA: 42s - loss: 0.8802 - accuracy: 0.6479"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8245 - accuracy: 0.6663 - val_loss: 1.0477 - val_accuracy: 0.6211\n","Epoch 90/100\n","23/33 [===================>..........] - ETA: 18s - loss: 0.8201 - accuracy: 0.6790"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8358 - accuracy: 0.6736 - val_loss: 1.0418 - val_accuracy: 0.6211\n","Epoch 91/100\n","33/33 [==============================] - ETA: 0s - loss: 0.7949 - accuracy: 0.6829"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2/assets\n","33/33 [==============================] - 92s 3s/step - loss: 0.7949 - accuracy: 0.6829 - val_loss: 1.0506 - val_accuracy: 0.6348\n","Epoch 92/100\n"," 3/33 [=>............................] - ETA: 57s - loss: 0.8062 - accuracy: 0.7005"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.8215 - accuracy: 0.6693 - val_loss: 1.0764 - val_accuracy: 0.6035\n","Epoch 93/100\n","31/33 [===========================>..] - ETA: 3s - loss: 0.8152 - accuracy: 0.6851"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8171 - accuracy: 0.6819 - val_loss: 1.0490 - val_accuracy: 0.6348\n","Epoch 94/100\n","30/33 [==========================>...] - ETA: 5s - loss: 0.7923 - accuracy: 0.6826"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.7960 - accuracy: 0.6787 - val_loss: 1.0525 - val_accuracy: 0.6133\n","Epoch 95/100\n","28/33 [========================>.....] - ETA: 9s - loss: 0.7812 - accuracy: 0.6839 "]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.7823 - accuracy: 0.6877 - val_loss: 1.0525 - val_accuracy: 0.6152\n","Epoch 96/100\n"," 2/33 [>.............................] - ETA: 1:00 - loss: 0.6646 - accuracy: 0.7383"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 65s 2s/step - loss: 0.8007 - accuracy: 0.6918 - val_loss: 1.0698 - val_accuracy: 0.5898\n","Epoch 97/100\n","10/33 [========>.....................] - ETA: 44s - loss: 0.8009 - accuracy: 0.6828"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.7831 - accuracy: 0.6855 - val_loss: 1.0576 - val_accuracy: 0.6191\n","Epoch 98/100\n"," 2/33 [>.............................] - ETA: 1:04 - loss: 0.7207 - accuracy: 0.7344"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 67s 2s/step - loss: 0.7868 - accuracy: 0.6860 - val_loss: 1.0859 - val_accuracy: 0.6172\n","Epoch 99/100\n","23/33 [===================>..........] - ETA: 18s - loss: 0.7737 - accuracy: 0.6920"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.7829 - accuracy: 0.6904 - val_loss: 1.0324 - val_accuracy: 0.6230\n","Epoch 100/100\n","20/33 [=================>............] - ETA: 24s - loss: 0.7588 - accuracy: 0.6960"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 66s 2s/step - loss: 0.7446 - accuracy: 0.6945 - val_loss: 1.0864 - val_accuracy: 0.6055\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f836c43f810>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["## Compile and fit model\n","\n","print(\"[INFO] compiling model...\")\n","opt = Adam(learning_rate = 1e-4)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# construct the set of callbacks\n","figPath = os.path.sep.join([output,\"facial_emotion_recognition34_2.png\"])\n","jsonPath = os.path.sep.join([output,\"facial_emotion_recognition34_2.json\"])\n","model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n","callbacks = [model_checkpoint_callback, TrainingMonitor(figPath, jsonPath=jsonPath, startAt=start_epoch)]\n","\n","model.fit(train_generator, steps_per_epoch = 4246 // 128, epochs = 100, validation_data = val_generator, validation_steps = 529 // 128, max_queue_size = 128 * 2, callbacks = callbacks, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"BZuXulPOe2pw"},"source":["\n","\n","---\n","\n","TESTARE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21891,"status":"ok","timestamp":1653597446837,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"RK4Lz2ane2pw","outputId":"42d24115-05ca-4f36-8743-f3761907f28d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 540 images belonging to 6 classes.\n","[INFO] loading /content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2...\n","4/4 [==============================] - 4s 687ms/step - loss: 1.0311 - accuracy: 0.5996\n","              precision    recall  f1-score   support\n","\n","           0       0.21      0.31      0.25        96\n","           1       0.14      0.10      0.12        81\n","           2       0.25      0.23      0.24        99\n","           3       0.25      0.24      0.25        94\n","           4       0.18      0.15      0.16        88\n","           5       0.18      0.18      0.18        82\n","\n","    accuracy                           0.21       540\n","   macro avg       0.20      0.20      0.20       540\n","weighted avg       0.20      0.21      0.20       540\n","\n","\n","\n","[INFO] accuracy: 59.96\n"]}],"source":["model = '/content/drive/MyDrive/GitHub/licenta/outputs/output34/checkpoint2'\n","\n","test_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","test_generator = test_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/test', target_size = (224, 224), batch_size = 128, class_mode = \"categorical\")\n","\n","# load the model from disk\n","print(\"[INFO] loading {}...\".format(model))\n","model = load_model(model)\n","\n","\n","# evaluate the network\n","(loss, acc) = model.evaluate(test_generator, steps = 540 // 128, max_queue_size = 128 * 2)\n","\n","# get the ground truth of your data. \n","test_labels  =test_generator.classes \n","\n","# predict the probability distribution of the data\n","predictions = model.predict(test_generator)\n","\n","# get the class with highest probability for each sample\n","y_pred = np.argmax(predictions, axis=-1)\n","\n","# get the classification report\n","print(classification_report(test_labels, y_pred))\n","\n","print(\"\\n\\n[INFO] accuracy: {:.2f}\".format(acc * 100))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"executionInfo":{"elapsed":681,"status":"ok","timestamp":1653597447511,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"tT0bxBSve2pw","outputId":"71c50364-fe90-462b-9f64-56b0bd144126"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","%matplotlib inline\n","plt.close('all')\n","\n","# Get the confusion matrix\n","cf_matrix = confusion_matrix(test_labels, y_pred)\n","\n","ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')\n","\n","ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n","ax.set_xlabel('\\nPredicted Category')\n","ax.set_ylabel('Actual Category ')\n","\n","## Ticket labels - List must be in alphabetical order\n","ax.xaxis.set_ticklabels(['angry','fear', 'happy', 'neutral', 'sad', 'surprise'])\n","ax.yaxis.set_ticklabels(['angry','fear', 'happy', 'neutral', 'sad', 'surprise'])\n","\n","## Display the visualization of the Confusion Matrix.\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"GoRu40mnYNEb"},"source":["# Deblocare straturi si modificare learning rate"]},{"cell_type":"markdown","metadata":{"id":"JjsHHx5WYNEc"},"source":["Se va schimba modelul EmotionVGG creat mai sus cu modelul ResNet50 pentru a testa pe un model preantrenat.\n","\n","In plus, se va face fine-tuning cu un strat de 512 de neuroni. Spre deosebire de 3.4, se va modifica modelul cu cel ResNet50.\n","\n","Se vor debloca straturile de la 143 si se va modifica learning rate-ul la 10^-3.\n","\n","Rezultatele se salveaza in outputs/output35."]},{"cell_type":"markdown","metadata":{"id":"ypR5l_WMYNEc"},"source":["\n","\n","---\n","\n","ANTRENARE"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2973,"status":"ok","timestamp":1653847388555,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"a64G7tYbYNEc","outputId":"86ce36ea-d919-4c3b-c5a3-fc34ae34aa06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4246 images belonging to 6 classes.\n","Found 529 images belonging to 6 classes.\n"]}],"source":["# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","\n","# import the necessary packages\n","import tensorflow\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from keras.models import load_model\n","import keras.backend as K\n","import argparse\n","import os\n","import tensorflow\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import ResNet50\n","\n","output = '/content/drive/MyDrive/GitHub/licenta/outputs/output35'\n","checkpoint = '/content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint1'\n","model = None\n","start_epoch = 0\n","\n","train_datagen = ImageDataGenerator( rotation_range = 10, rescale = 1 / 255.0, zoom_range = 0.1, horizontal_flip = True, fill_mode = \"nearest\")\n","val_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/GitHub/licenta/dataset_fer/train', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')\n","val_generator = val_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/val', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')\n","\n","\n","# FOLOSIRE VGG16\n","\n","## Loading VGG16 model\n","\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n","base_model.trainable = False ## Not trainable weights\n","\n","## Add last layers\n","\n","flatten_layer = layers.Flatten()\n","dense_layer_1 = layers.Dense(512, activation='relu')\n","dropout_layer = layers.Dropout(0.5)\n","prediction_layer = layers.Dense(6, activation='softmax')\n","\n","\n","model = models.Sequential([base_model, flatten_layer, dense_layer_1, dropout_layer, prediction_layer])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1653847394876,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"SthRdsZ6YNEd","outputId":"2557ca53-dfb8-48a3-d3bc-b9c3223d6c50"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] base model status... \n","\n","0 input_1 False\n","1 conv1_pad False\n","2 conv1_conv False\n","3 conv1_bn False\n","4 conv1_relu False\n","5 pool1_pad False\n","6 pool1_pool False\n","7 conv2_block1_1_conv False\n","8 conv2_block1_1_bn False\n","9 conv2_block1_1_relu False\n","10 conv2_block1_2_conv False\n","11 conv2_block1_2_bn False\n","12 conv2_block1_2_relu False\n","13 conv2_block1_0_conv False\n","14 conv2_block1_3_conv False\n","15 conv2_block1_0_bn False\n","16 conv2_block1_3_bn False\n","17 conv2_block1_add False\n","18 conv2_block1_out False\n","19 conv2_block2_1_conv False\n","20 conv2_block2_1_bn False\n","21 conv2_block2_1_relu False\n","22 conv2_block2_2_conv False\n","23 conv2_block2_2_bn False\n","24 conv2_block2_2_relu False\n","25 conv2_block2_3_conv False\n","26 conv2_block2_3_bn False\n","27 conv2_block2_add False\n","28 conv2_block2_out False\n","29 conv2_block3_1_conv False\n","30 conv2_block3_1_bn False\n","31 conv2_block3_1_relu False\n","32 conv2_block3_2_conv False\n","33 conv2_block3_2_bn False\n","34 conv2_block3_2_relu False\n","35 conv2_block3_3_conv False\n","36 conv2_block3_3_bn False\n","37 conv2_block3_add False\n","38 conv2_block3_out False\n","39 conv3_block1_1_conv False\n","40 conv3_block1_1_bn False\n","41 conv3_block1_1_relu False\n","42 conv3_block1_2_conv False\n","43 conv3_block1_2_bn False\n","44 conv3_block1_2_relu False\n","45 conv3_block1_0_conv False\n","46 conv3_block1_3_conv False\n","47 conv3_block1_0_bn False\n","48 conv3_block1_3_bn False\n","49 conv3_block1_add False\n","50 conv3_block1_out False\n","51 conv3_block2_1_conv False\n","52 conv3_block2_1_bn False\n","53 conv3_block2_1_relu False\n","54 conv3_block2_2_conv False\n","55 conv3_block2_2_bn False\n","56 conv3_block2_2_relu False\n","57 conv3_block2_3_conv False\n","58 conv3_block2_3_bn False\n","59 conv3_block2_add False\n","60 conv3_block2_out False\n","61 conv3_block3_1_conv False\n","62 conv3_block3_1_bn False\n","63 conv3_block3_1_relu False\n","64 conv3_block3_2_conv False\n","65 conv3_block3_2_bn False\n","66 conv3_block3_2_relu False\n","67 conv3_block3_3_conv False\n","68 conv3_block3_3_bn False\n","69 conv3_block3_add False\n","70 conv3_block3_out False\n","71 conv3_block4_1_conv False\n","72 conv3_block4_1_bn False\n","73 conv3_block4_1_relu False\n","74 conv3_block4_2_conv False\n","75 conv3_block4_2_bn False\n","76 conv3_block4_2_relu False\n","77 conv3_block4_3_conv False\n","78 conv3_block4_3_bn False\n","79 conv3_block4_add False\n","80 conv3_block4_out False\n","81 conv4_block1_1_conv False\n","82 conv4_block1_1_bn False\n","83 conv4_block1_1_relu False\n","84 conv4_block1_2_conv False\n","85 conv4_block1_2_bn False\n","86 conv4_block1_2_relu False\n","87 conv4_block1_0_conv False\n","88 conv4_block1_3_conv False\n","89 conv4_block1_0_bn False\n","90 conv4_block1_3_bn False\n","91 conv4_block1_add False\n","92 conv4_block1_out False\n","93 conv4_block2_1_conv False\n","94 conv4_block2_1_bn False\n","95 conv4_block2_1_relu False\n","96 conv4_block2_2_conv False\n","97 conv4_block2_2_bn False\n","98 conv4_block2_2_relu False\n","99 conv4_block2_3_conv False\n","100 conv4_block2_3_bn False\n","101 conv4_block2_add False\n","102 conv4_block2_out False\n","103 conv4_block3_1_conv False\n","104 conv4_block3_1_bn False\n","105 conv4_block3_1_relu False\n","106 conv4_block3_2_conv False\n","107 conv4_block3_2_bn False\n","108 conv4_block3_2_relu False\n","109 conv4_block3_3_conv False\n","110 conv4_block3_3_bn False\n","111 conv4_block3_add False\n","112 conv4_block3_out False\n","113 conv4_block4_1_conv False\n","114 conv4_block4_1_bn False\n","115 conv4_block4_1_relu False\n","116 conv4_block4_2_conv False\n","117 conv4_block4_2_bn False\n","118 conv4_block4_2_relu False\n","119 conv4_block4_3_conv False\n","120 conv4_block4_3_bn False\n","121 conv4_block4_add False\n","122 conv4_block4_out False\n","123 conv4_block5_1_conv False\n","124 conv4_block5_1_bn False\n","125 conv4_block5_1_relu False\n","126 conv4_block5_2_conv False\n","127 conv4_block5_2_bn False\n","128 conv4_block5_2_relu False\n","129 conv4_block5_3_conv False\n","130 conv4_block5_3_bn False\n","131 conv4_block5_add False\n","132 conv4_block5_out False\n","133 conv4_block6_1_conv False\n","134 conv4_block6_1_bn False\n","135 conv4_block6_1_relu False\n","136 conv4_block6_2_conv False\n","137 conv4_block6_2_bn False\n","138 conv4_block6_2_relu False\n","139 conv4_block6_3_conv False\n","140 conv4_block6_3_bn False\n","141 conv4_block6_add False\n","142 conv4_block6_out False\n","143 conv5_block1_1_conv False\n","144 conv5_block1_1_bn False\n","145 conv5_block1_1_relu False\n","146 conv5_block1_2_conv False\n","147 conv5_block1_2_bn False\n","148 conv5_block1_2_relu False\n","149 conv5_block1_0_conv False\n","150 conv5_block1_3_conv False\n","151 conv5_block1_0_bn False\n","152 conv5_block1_3_bn False\n","153 conv5_block1_add False\n","154 conv5_block1_out False\n","155 conv5_block2_1_conv False\n","156 conv5_block2_1_bn False\n","157 conv5_block2_1_relu False\n","158 conv5_block2_2_conv False\n","159 conv5_block2_2_bn False\n","160 conv5_block2_2_relu False\n","161 conv5_block2_3_conv False\n","162 conv5_block2_3_bn False\n","163 conv5_block2_add False\n","164 conv5_block2_out False\n","165 conv5_block3_1_conv False\n","166 conv5_block3_1_bn False\n","167 conv5_block3_1_relu False\n","168 conv5_block3_2_conv False\n","169 conv5_block3_2_bn False\n","170 conv5_block3_2_relu False\n","171 conv5_block3_3_conv False\n","172 conv5_block3_3_bn False\n","173 conv5_block3_add False\n","174 conv5_block3_out False\n","\n","\n","[INFO] entire model status...\n","\n","0 resnet50 False\n","1 flatten True\n","2 dense True\n","3 dropout True\n","4 dense_1 True\n"]}],"source":["print(\"[INFO] base model status... \\n\")\n","for i, layer in enumerate(base_model.layers):\n","  print(i, layer.name, layer.trainable)\n","\n","print(\"\\n\\n[INFO] entire model status...\\n\")\n","for i, layer in enumerate(model.layers):\n","  print(i, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1231942,"status":"ok","timestamp":1653848630998,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"_7ap9Wy3YNEe","outputId":"c04ad50f-3edd-4e6a-a9a9-b52ec4daf964"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] compiling model...\n","Epoch 1/20\n","19/33 [================>.............] - ETA: 21s - loss: 13.2071 - accuracy: 0.1840"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 8.3465 - accuracy: 0.1826INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint1/assets\n","33/33 [==============================] - 85s 2s/step - loss: 8.3465 - accuracy: 0.1826 - val_loss: 1.7475 - val_accuracy: 0.1875\n","Epoch 2/20\n","31/33 [===========================>..] - ETA: 3s - loss: 1.7741 - accuracy: 0.1932"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.7733 - accuracy: 0.1914INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint1/assets\n","33/33 [==============================] - 79s 2s/step - loss: 1.7733 - accuracy: 0.1914 - val_loss: 1.7521 - val_accuracy: 0.3359\n","Epoch 3/20\n","27/33 [=======================>......] - ETA: 10s - loss: 1.7476 - accuracy: 0.1982"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 61s 2s/step - loss: 1.7425 - accuracy: 0.2005 - val_loss: 1.6984 - val_accuracy: 0.3066\n","Epoch 4/20\n"," 1/33 [..............................] - ETA: 1:09 - loss: 1.7289 - accuracy: 0.2031"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 60s 2s/step - loss: 1.7485 - accuracy: 0.2210 - val_loss: 1.6963 - val_accuracy: 0.1914\n","Epoch 5/20\n"," 1/33 [..............................] - ETA: 1:10 - loss: 1.7733 - accuracy: 0.1797"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 59s 2s/step - loss: 1.7377 - accuracy: 0.2297 - val_loss: 1.6617 - val_accuracy: 0.2891\n","Epoch 6/20\n","23/33 [===================>..........] - ETA: 16s - loss: 1.7643 - accuracy: 0.2287"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.7652 - accuracy: 0.2258 - val_loss: 1.6543 - val_accuracy: 0.3125\n","Epoch 7/20\n"," 7/33 [=====>........................] - ETA: 43s - loss: 1.7094 - accuracy: 0.2556"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.7328 - accuracy: 0.2251 - val_loss: 1.6522 - val_accuracy: 0.2930\n","Epoch 8/20\n","29/33 [=========================>....] - ETA: 6s - loss: 1.7199 - accuracy: 0.2316"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.7212 - accuracy: 0.2302 - val_loss: 1.6610 - val_accuracy: 0.3008\n","Epoch 9/20\n","23/33 [===================>..........] - ETA: 16s - loss: 1.7481 - accuracy: 0.2327"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.7424 - accuracy: 0.2271 - val_loss: 1.6520 - val_accuracy: 0.2969\n","Epoch 10/20\n"," 9/33 [=======>......................] - ETA: 35s - loss: 1.7092 - accuracy: 0.2342"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.7140 - accuracy: 0.2346 - val_loss: 1.6505 - val_accuracy: 0.3223\n","Epoch 11/20\n","12/33 [=========>....................] - ETA: 35s - loss: 1.7126 - accuracy: 0.2298"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.7035 - accuracy: 0.2476INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint1/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.7035 - accuracy: 0.2476 - val_loss: 1.6530 - val_accuracy: 0.3535\n","Epoch 12/20\n","16/33 [=============>................] - ETA: 27s - loss: 1.6934 - accuracy: 0.2472"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.7121 - accuracy: 0.2365 - val_loss: 1.6293 - val_accuracy: 0.3027\n","Epoch 13/20\n"," 1/33 [..............................] - ETA: 1:03 - loss: 1.7123 - accuracy: 0.2266"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7076 - accuracy: 0.2404 - val_loss: 1.6586 - val_accuracy: 0.2969\n","Epoch 14/20\n","25/33 [=====================>........] - ETA: 12s - loss: 1.7227 - accuracy: 0.2288"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7193 - accuracy: 0.2319 - val_loss: 1.6389 - val_accuracy: 0.3047\n","Epoch 15/20\n","29/33 [=========================>....] - ETA: 6s - loss: 1.6989 - accuracy: 0.2366"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7036 - accuracy: 0.2346 - val_loss: 1.6432 - val_accuracy: 0.2812\n","Epoch 16/20\n","31/33 [===========================>..] - ETA: 3s - loss: 1.6934 - accuracy: 0.2613"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6940 - accuracy: 0.2591 - val_loss: 1.6235 - val_accuracy: 0.2930\n","Epoch 17/20\n"," 1/33 [..............................] - ETA: 1:03 - loss: 1.7729 - accuracy: 0.2500"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7043 - accuracy: 0.2450 - val_loss: 1.6364 - val_accuracy: 0.2715\n","Epoch 18/20\n","28/33 [========================>.....] - ETA: 8s - loss: 1.7014 - accuracy: 0.2438"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7042 - accuracy: 0.2431 - val_loss: 1.6118 - val_accuracy: 0.3125\n","Epoch 19/20\n","15/33 [============>.................] - ETA: 28s - loss: 1.6845 - accuracy: 0.2464"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6907 - accuracy: 0.2407 - val_loss: 1.6227 - val_accuracy: 0.3105\n","Epoch 20/20\n","18/33 [===============>..............] - ETA: 24s - loss: 1.7557 - accuracy: 0.2500"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7262 - accuracy: 0.2572 - val_loss: 1.5911 - val_accuracy: 0.3164\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8b08df7190>"]},"metadata":{},"execution_count":7}],"source":["## Compile and fit model\n","\n","print(\"[INFO] compiling model...\")\n","opt = Adam(learning_rate = 1e-3)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# construct the set of callbacks\n","figPath = os.path.sep.join([output,\"facial_emotion_recognition35_1.png\"])\n","jsonPath = os.path.sep.join([output,\"facial_emotion_recognitio35_1.json\"])\n","model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n","callbacks = [model_checkpoint_callback, TrainingMonitor(figPath, jsonPath=jsonPath, startAt=start_epoch)]\n","\n","model.fit(train_generator, steps_per_epoch = 4246 // 128, epochs = 20, validation_data = val_generator, validation_steps = 529 // 128, max_queue_size = 128 * 2, callbacks = callbacks, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"_tqPPKFSYNEe"},"source":["\n","\n","---\n","\n","TESTARE"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20830,"status":"ok","timestamp":1653848651819,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"dOv_5DzUYNEe","outputId":"4326cafc-eef1-4135-8f27-4cbb86546de0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 540 images belonging to 6 classes.\n","[INFO] loading /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint1...\n","4/4 [==============================] - 4s 589ms/step - loss: 1.6804 - accuracy: 0.3301\n","              precision    recall  f1-score   support\n","\n","           0       0.16      0.49      0.24        96\n","           1       0.16      0.09      0.11        81\n","           2       0.13      0.04      0.06        99\n","           3       0.17      0.19      0.18        94\n","           4       0.21      0.15      0.17        88\n","           5       0.00      0.00      0.00        82\n","\n","    accuracy                           0.16       540\n","   macro avg       0.14      0.16      0.13       540\n","weighted avg       0.14      0.16      0.13       540\n","\n","\n","\n","[INFO] accuracy: 33.01\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["# import the necessary packages\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import load_model\n","import argparse\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelBinarizer\n","import numpy as np\n","\n","model = '/content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint1'\n","\n","test_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","test_generator = test_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/test', target_size = (224, 224), batch_size = 128, class_mode = \"categorical\")\n","\n","# load the model from disk\n","print(\"[INFO] loading {}...\".format(model))\n","model = load_model(model)\n","\n","\n","# evaluate the network\n","(loss, acc) = model.evaluate(test_generator, steps = 540 // 128, max_queue_size = 128 * 2)\n","\n","# get the ground truth of your data. \n","test_labels  =test_generator.classes \n","\n","# predict the probability distribution of the data\n","predictions = model.predict(test_generator)\n","\n","# get the class with highest probability for each sample\n","y_pred = np.argmax(predictions, axis=-1)\n","\n","# get the classification report\n","print(classification_report(test_labels, y_pred))\n","\n","print(\"\\n\\n[INFO] accuracy: {:.2f}\".format(acc * 100))"]},{"cell_type":"markdown","metadata":{"id":"AYAN6vobYNEf"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","ANTRENARE"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1653848651820,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"},"user_tz":-180},"id":"p4ISGkS4YNEf","outputId":"efe549cb-d878-401a-94f8-df067f5bc45a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] base model status... \n","\n","0 input_1 False\n","1 conv1_pad False\n","2 conv1_conv False\n","3 conv1_bn False\n","4 conv1_relu False\n","5 pool1_pad False\n","6 pool1_pool False\n","7 conv2_block1_1_conv False\n","8 conv2_block1_1_bn False\n","9 conv2_block1_1_relu False\n","10 conv2_block1_2_conv False\n","11 conv2_block1_2_bn False\n","12 conv2_block1_2_relu False\n","13 conv2_block1_0_conv False\n","14 conv2_block1_3_conv False\n","15 conv2_block1_0_bn False\n","16 conv2_block1_3_bn False\n","17 conv2_block1_add False\n","18 conv2_block1_out False\n","19 conv2_block2_1_conv False\n","20 conv2_block2_1_bn False\n","21 conv2_block2_1_relu False\n","22 conv2_block2_2_conv False\n","23 conv2_block2_2_bn False\n","24 conv2_block2_2_relu False\n","25 conv2_block2_3_conv False\n","26 conv2_block2_3_bn False\n","27 conv2_block2_add False\n","28 conv2_block2_out False\n","29 conv2_block3_1_conv False\n","30 conv2_block3_1_bn False\n","31 conv2_block3_1_relu False\n","32 conv2_block3_2_conv False\n","33 conv2_block3_2_bn False\n","34 conv2_block3_2_relu False\n","35 conv2_block3_3_conv False\n","36 conv2_block3_3_bn False\n","37 conv2_block3_add False\n","38 conv2_block3_out False\n","39 conv3_block1_1_conv False\n","40 conv3_block1_1_bn False\n","41 conv3_block1_1_relu False\n","42 conv3_block1_2_conv False\n","43 conv3_block1_2_bn False\n","44 conv3_block1_2_relu False\n","45 conv3_block1_0_conv False\n","46 conv3_block1_3_conv False\n","47 conv3_block1_0_bn False\n","48 conv3_block1_3_bn False\n","49 conv3_block1_add False\n","50 conv3_block1_out False\n","51 conv3_block2_1_conv False\n","52 conv3_block2_1_bn False\n","53 conv3_block2_1_relu False\n","54 conv3_block2_2_conv False\n","55 conv3_block2_2_bn False\n","56 conv3_block2_2_relu False\n","57 conv3_block2_3_conv False\n","58 conv3_block2_3_bn False\n","59 conv3_block2_add False\n","60 conv3_block2_out False\n","61 conv3_block3_1_conv False\n","62 conv3_block3_1_bn False\n","63 conv3_block3_1_relu False\n","64 conv3_block3_2_conv False\n","65 conv3_block3_2_bn False\n","66 conv3_block3_2_relu False\n","67 conv3_block3_3_conv False\n","68 conv3_block3_3_bn False\n","69 conv3_block3_add False\n","70 conv3_block3_out False\n","71 conv3_block4_1_conv False\n","72 conv3_block4_1_bn False\n","73 conv3_block4_1_relu False\n","74 conv3_block4_2_conv False\n","75 conv3_block4_2_bn False\n","76 conv3_block4_2_relu False\n","77 conv3_block4_3_conv False\n","78 conv3_block4_3_bn False\n","79 conv3_block4_add False\n","80 conv3_block4_out False\n","81 conv4_block1_1_conv False\n","82 conv4_block1_1_bn False\n","83 conv4_block1_1_relu False\n","84 conv4_block1_2_conv False\n","85 conv4_block1_2_bn False\n","86 conv4_block1_2_relu False\n","87 conv4_block1_0_conv False\n","88 conv4_block1_3_conv False\n","89 conv4_block1_0_bn False\n","90 conv4_block1_3_bn False\n","91 conv4_block1_add False\n","92 conv4_block1_out False\n","93 conv4_block2_1_conv False\n","94 conv4_block2_1_bn False\n","95 conv4_block2_1_relu False\n","96 conv4_block2_2_conv False\n","97 conv4_block2_2_bn False\n","98 conv4_block2_2_relu False\n","99 conv4_block2_3_conv False\n","100 conv4_block2_3_bn False\n","101 conv4_block2_add False\n","102 conv4_block2_out False\n","103 conv4_block3_1_conv False\n","104 conv4_block3_1_bn False\n","105 conv4_block3_1_relu False\n","106 conv4_block3_2_conv False\n","107 conv4_block3_2_bn False\n","108 conv4_block3_2_relu False\n","109 conv4_block3_3_conv False\n","110 conv4_block3_3_bn False\n","111 conv4_block3_add False\n","112 conv4_block3_out False\n","113 conv4_block4_1_conv False\n","114 conv4_block4_1_bn False\n","115 conv4_block4_1_relu False\n","116 conv4_block4_2_conv False\n","117 conv4_block4_2_bn False\n","118 conv4_block4_2_relu False\n","119 conv4_block4_3_conv False\n","120 conv4_block4_3_bn False\n","121 conv4_block4_add False\n","122 conv4_block4_out False\n","123 conv4_block5_1_conv False\n","124 conv4_block5_1_bn False\n","125 conv4_block5_1_relu False\n","126 conv4_block5_2_conv False\n","127 conv4_block5_2_bn False\n","128 conv4_block5_2_relu False\n","129 conv4_block5_3_conv False\n","130 conv4_block5_3_bn False\n","131 conv4_block5_add False\n","132 conv4_block5_out False\n","133 conv4_block6_1_conv False\n","134 conv4_block6_1_bn False\n","135 conv4_block6_1_relu False\n","136 conv4_block6_2_conv False\n","137 conv4_block6_2_bn False\n","138 conv4_block6_2_relu False\n","139 conv4_block6_3_conv False\n","140 conv4_block6_3_bn False\n","141 conv4_block6_add False\n","142 conv4_block6_out False\n","143 conv5_block1_1_conv True\n","144 conv5_block1_1_bn True\n","145 conv5_block1_1_relu True\n","146 conv5_block1_2_conv True\n","147 conv5_block1_2_bn True\n","148 conv5_block1_2_relu True\n","149 conv5_block1_0_conv True\n","150 conv5_block1_3_conv True\n","151 conv5_block1_0_bn True\n","152 conv5_block1_3_bn True\n","153 conv5_block1_add True\n","154 conv5_block1_out True\n","155 conv5_block2_1_conv True\n","156 conv5_block2_1_bn True\n","157 conv5_block2_1_relu True\n","158 conv5_block2_2_conv True\n","159 conv5_block2_2_bn True\n","160 conv5_block2_2_relu True\n","161 conv5_block2_3_conv True\n","162 conv5_block2_3_bn True\n","163 conv5_block2_add True\n","164 conv5_block2_out True\n","165 conv5_block3_1_conv True\n","166 conv5_block3_1_bn True\n","167 conv5_block3_1_relu True\n","168 conv5_block3_2_conv True\n","169 conv5_block3_2_bn True\n","170 conv5_block3_2_relu True\n","171 conv5_block3_3_conv True\n","172 conv5_block3_3_bn True\n","173 conv5_block3_add True\n","174 conv5_block3_out True\n","\n","\n","[INFO] entire model status...\n","\n","\n","0 resnet50 False\n","1 flatten True\n","2 dense True\n","3 dropout True\n","4 dense_1 True\n"]}],"source":["output = '/content/drive/MyDrive/GitHub/licenta/outputs/output35'\n","checkpoint = '/content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint2'\n","start_epoch = 0\n","\n","for layer in base_model.layers[143:]:\n","  layer.trainable = True\n","\n","print(\"[INFO] base model status... \\n\")\n","for i, layer in enumerate(base_model.layers):\n","  print(i, layer.name, layer.trainable)\n","\n","print(\"\\n\\n[INFO] entire model status...\\n\\n\")\n","for i, layer in enumerate(model.layers):\n","  print(i, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7u5OMbaYNEf","outputId":"9923b518-2397-4369-aabf-a012722fc54e","executionInfo":{"status":"ok","timestamp":1653854454768,"user_tz":-180,"elapsed":5802961,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] compiling model...\n","Epoch 1/100\n"," 5/33 [===>..........................] - ETA: 45s - loss: 1.8419 - accuracy: 0.1937"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.7954 - accuracy: 0.1884INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint2/assets\n","33/33 [==============================] - 84s 2s/step - loss: 1.7954 - accuracy: 0.1884 - val_loss: 1.7443 - val_accuracy: 0.2012\n","Epoch 2/100\n"," 2/33 [>.............................] - ETA: 48s - loss: 1.7618 - accuracy: 0.1875 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.7422 - accuracy: 0.2173INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint2/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.7422 - accuracy: 0.2173 - val_loss: 1.6349 - val_accuracy: 0.3008\n","Epoch 3/100\n","15/33 [============>.................] - ETA: 31s - loss: 1.7110 - accuracy: 0.2271"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.7110 - accuracy: 0.2356 - val_loss: 1.6554 - val_accuracy: 0.2871\n","Epoch 4/100\n","20/33 [=================>............] - ETA: 20s - loss: 1.7092 - accuracy: 0.2319"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7129 - accuracy: 0.2351 - val_loss: 1.6221 - val_accuracy: 0.2969\n","Epoch 5/100\n","12/33 [=========>....................] - ETA: 34s - loss: 1.7325 - accuracy: 0.2135"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7347 - accuracy: 0.2205 - val_loss: 1.6764 - val_accuracy: 0.2520\n","Epoch 6/100\n","27/33 [=======================>......] - ETA: 9s - loss: 1.7036 - accuracy: 0.2338 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.7062 - accuracy: 0.2367 - val_loss: 1.6536 - val_accuracy: 0.2871\n","Epoch 7/100\n","29/33 [=========================>....] - ETA: 6s - loss: 1.7077 - accuracy: 0.2335"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.7071 - accuracy: 0.2348INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint2/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.7071 - accuracy: 0.2348 - val_loss: 1.6276 - val_accuracy: 0.3105\n","Epoch 8/100\n","26/33 [======================>.......] - ETA: 11s - loss: 1.7221 - accuracy: 0.2427"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.7230 - accuracy: 0.2380 - val_loss: 1.6265 - val_accuracy: 0.2910\n","Epoch 9/100\n","19/33 [================>.............] - ETA: 22s - loss: 1.6899 - accuracy: 0.2511"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7169 - accuracy: 0.2402 - val_loss: 1.6507 - val_accuracy: 0.2773\n","Epoch 10/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.7036 - accuracy: 0.2367"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.7028 - accuracy: 0.2358INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint2/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.7028 - accuracy: 0.2358 - val_loss: 1.5997 - val_accuracy: 0.3145\n","Epoch 11/100\n"," 8/33 [======>.......................] - ETA: 40s - loss: 1.7016 - accuracy: 0.2124"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.6958 - accuracy: 0.2404 - val_loss: 1.6016 - val_accuracy: 0.3145\n","Epoch 12/100\n"," 9/33 [=======>......................] - ETA: 36s - loss: 1.7148 - accuracy: 0.2495"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7237 - accuracy: 0.2411 - val_loss: 1.6007 - val_accuracy: 0.2891\n","Epoch 13/100\n","28/33 [========================>.....] - ETA: 8s - loss: 1.7001 - accuracy: 0.2358"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7055 - accuracy: 0.2314 - val_loss: 1.6529 - val_accuracy: 0.2734\n","Epoch 14/100\n","16/33 [=============>................] - ETA: 26s - loss: 1.6999 - accuracy: 0.2508"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7018 - accuracy: 0.2368 - val_loss: 1.5949 - val_accuracy: 0.3066\n","Epoch 15/100\n","15/33 [============>.................] - ETA: 29s - loss: 1.6965 - accuracy: 0.2375"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7182 - accuracy: 0.2317 - val_loss: 1.6133 - val_accuracy: 0.2871\n","Epoch 16/100\n","25/33 [=====================>........] - ETA: 12s - loss: 1.7037 - accuracy: 0.2343"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7037 - accuracy: 0.2341 - val_loss: 1.5961 - val_accuracy: 0.2812\n","Epoch 17/100\n","29/33 [=========================>....] - ETA: 6s - loss: 1.7013 - accuracy: 0.2349"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6984 - accuracy: 0.2375 - val_loss: 1.6343 - val_accuracy: 0.2695\n","Epoch 18/100\n"," 6/33 [====>.........................] - ETA: 38s - loss: 1.6699 - accuracy: 0.2492"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6946 - accuracy: 0.2363 - val_loss: 1.5992 - val_accuracy: 0.3008\n","Epoch 19/100\n","12/33 [=========>....................] - ETA: 34s - loss: 1.6869 - accuracy: 0.2480"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6893 - accuracy: 0.2419 - val_loss: 1.6197 - val_accuracy: 0.2910\n","Epoch 20/100\n"," 2/33 [>.............................] - ETA: 50s - loss: 1.7076 - accuracy: 0.2266 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6916 - accuracy: 0.2419 - val_loss: 1.6004 - val_accuracy: 0.2969\n","Epoch 21/100\n","14/33 [===========>..................] - ETA: 31s - loss: 1.6779 - accuracy: 0.2600"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6841 - accuracy: 0.2499 - val_loss: 1.6004 - val_accuracy: 0.2988\n","Epoch 22/100\n","32/33 [============================>.] - ETA: 1s - loss: 1.6860 - accuracy: 0.2459"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6874 - accuracy: 0.2460 - val_loss: 1.6130 - val_accuracy: 0.2988\n","Epoch 23/100\n","11/33 [=========>....................] - ETA: 36s - loss: 1.7072 - accuracy: 0.2216"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7001 - accuracy: 0.2409 - val_loss: 1.6240 - val_accuracy: 0.2734\n","Epoch 24/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7011 - accuracy: 0.2334 - val_loss: 1.6327 - val_accuracy: 0.2773\n","Epoch 25/100\n","17/33 [==============>...............] - ETA: 25s - loss: 1.6843 - accuracy: 0.2406"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6935 - accuracy: 0.2377 - val_loss: 1.6007 - val_accuracy: 0.2969\n","Epoch 26/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7060 - accuracy: 0.2358 - val_loss: 1.6091 - val_accuracy: 0.2812\n","Epoch 27/100\n","13/33 [==========>...................] - ETA: 33s - loss: 1.7034 - accuracy: 0.2248"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7017 - accuracy: 0.2377 - val_loss: 1.5960 - val_accuracy: 0.2812\n","Epoch 28/100\n","11/33 [=========>....................] - ETA: 33s - loss: 1.6751 - accuracy: 0.2542"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6915 - accuracy: 0.2416 - val_loss: 1.5893 - val_accuracy: 0.2891\n","Epoch 29/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.6913 - accuracy: 0.2529"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 59s 2s/step - loss: 1.6997 - accuracy: 0.2396 - val_loss: 1.5847 - val_accuracy: 0.3086\n","Epoch 30/100\n"," 8/33 [======>.......................] - ETA: 41s - loss: 1.7371 - accuracy: 0.2246"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7272 - accuracy: 0.2251 - val_loss: 1.5856 - val_accuracy: 0.3086\n","Epoch 31/100\n","25/33 [=====================>........] - ETA: 12s - loss: 1.6908 - accuracy: 0.2359"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6887 - accuracy: 0.2370 - val_loss: 1.6066 - val_accuracy: 0.2832\n","Epoch 32/100\n","33/33 [==============================] - ETA: 0s - loss: 1.6915 - accuracy: 0.2419"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 58s 2s/step - loss: 1.6915 - accuracy: 0.2419 - val_loss: 1.5826 - val_accuracy: 0.3027\n","Epoch 33/100\n","18/33 [===============>..............] - ETA: 23s - loss: 1.6871 - accuracy: 0.2379"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6921 - accuracy: 0.2409 - val_loss: 1.6013 - val_accuracy: 0.2910\n","Epoch 34/100\n"," 2/33 [>.............................] - ETA: 50s - loss: 1.6828 - accuracy: 0.2461 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.6874 - accuracy: 0.2436 - val_loss: 1.5699 - val_accuracy: 0.2988\n","Epoch 35/100\n","10/33 [========>.....................] - ETA: 34s - loss: 1.6825 - accuracy: 0.2530"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6803 - accuracy: 0.2484 - val_loss: 1.6137 - val_accuracy: 0.2832\n","Epoch 36/100\n","18/33 [===============>..............] - ETA: 25s - loss: 1.6982 - accuracy: 0.2365"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6987 - accuracy: 0.2370 - val_loss: 1.5743 - val_accuracy: 0.2910\n","Epoch 37/100\n","25/33 [=====================>........] - ETA: 13s - loss: 1.6830 - accuracy: 0.2516"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.6892 - accuracy: 0.2428 - val_loss: 1.5745 - val_accuracy: 0.2910\n","Epoch 38/100\n","32/33 [============================>.] - ETA: 1s - loss: 1.7021 - accuracy: 0.2323"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7006 - accuracy: 0.2339 - val_loss: 1.5818 - val_accuracy: 0.2969\n","Epoch 39/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.6860 - accuracy: 0.2410"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6847 - accuracy: 0.2436 - val_loss: 1.6134 - val_accuracy: 0.2852\n","Epoch 40/100\n","11/33 [=========>....................] - ETA: 37s - loss: 1.7005 - accuracy: 0.2422"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6935 - accuracy: 0.2390 - val_loss: 1.5889 - val_accuracy: 0.3008\n","Epoch 41/100\n","10/33 [========>.....................] - ETA: 38s - loss: 1.6647 - accuracy: 0.2594"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6806 - accuracy: 0.2455 - val_loss: 1.5953 - val_accuracy: 0.2910\n","Epoch 42/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.6895 - accuracy: 0.2374"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6874 - accuracy: 0.2397 - val_loss: 1.6107 - val_accuracy: 0.2754\n","Epoch 43/100\n","21/33 [==================>...........] - ETA: 18s - loss: 1.6745 - accuracy: 0.2432"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6764 - accuracy: 0.2436 - val_loss: 1.5731 - val_accuracy: 0.2871\n","Epoch 44/100\n"," 9/33 [=======>......................] - ETA: 39s - loss: 1.7106 - accuracy: 0.2257"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7133 - accuracy: 0.2288 - val_loss: 1.5624 - val_accuracy: 0.3066\n","Epoch 45/100\n","16/33 [=============>................] - ETA: 27s - loss: 1.6768 - accuracy: 0.2373"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6835 - accuracy: 0.2387 - val_loss: 1.5784 - val_accuracy: 0.3047\n","Epoch 46/100\n","10/33 [========>.....................] - ETA: 35s - loss: 1.7065 - accuracy: 0.2249"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6997 - accuracy: 0.2356 - val_loss: 1.5819 - val_accuracy: 0.2949\n","Epoch 47/100\n"," 1/33 [..............................] - ETA: 1:04 - loss: 1.6706 - accuracy: 0.2109"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.6725 - accuracy: 0.2445INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint2/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.6725 - accuracy: 0.2445 - val_loss: 1.5724 - val_accuracy: 0.3203\n","Epoch 48/100\n","21/33 [==================>...........] - ETA: 20s - loss: 1.6776 - accuracy: 0.2433"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6842 - accuracy: 0.2387 - val_loss: 1.5815 - val_accuracy: 0.2871\n","Epoch 49/100\n"," 8/33 [======>.......................] - ETA: 42s - loss: 1.6911 - accuracy: 0.2432"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.6850 - accuracy: 0.2431 - val_loss: 1.6068 - val_accuracy: 0.2852\n","Epoch 50/100\n","31/33 [===========================>..] - ETA: 3s - loss: 1.6843 - accuracy: 0.2374"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6851 - accuracy: 0.2380 - val_loss: 1.5621 - val_accuracy: 0.3086\n","Epoch 51/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6905 - accuracy: 0.2385 - val_loss: 1.5699 - val_accuracy: 0.3125\n","Epoch 52/100\n","25/33 [=====================>........] - ETA: 12s - loss: 1.6772 - accuracy: 0.2411"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6829 - accuracy: 0.2402 - val_loss: 1.5828 - val_accuracy: 0.2910\n","Epoch 53/100\n"," 9/33 [=======>......................] - ETA: 39s - loss: 1.6883 - accuracy: 0.2483"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6878 - accuracy: 0.2419 - val_loss: 1.5733 - val_accuracy: 0.2930\n","Epoch 54/100\n"," 2/33 [>.............................] - ETA: 48s - loss: 1.6927 - accuracy: 0.2656 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6833 - accuracy: 0.2421 - val_loss: 1.5658 - val_accuracy: 0.3047\n","Epoch 55/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6836 - accuracy: 0.2448 - val_loss: 1.5938 - val_accuracy: 0.3008\n","Epoch 56/100\n","16/33 [=============>................] - ETA: 28s - loss: 1.6841 - accuracy: 0.2354"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6815 - accuracy: 0.2414 - val_loss: 1.5718 - val_accuracy: 0.3125\n","Epoch 57/100\n","19/33 [================>.............] - ETA: 22s - loss: 1.6962 - accuracy: 0.2304"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6921 - accuracy: 0.2363 - val_loss: 1.5739 - val_accuracy: 0.3066\n","Epoch 58/100\n","25/33 [=====================>........] - ETA: 13s - loss: 1.6928 - accuracy: 0.2346"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.6904 - accuracy: 0.2319 - val_loss: 1.5824 - val_accuracy: 0.2988\n","Epoch 59/100\n","14/33 [===========>..................] - ETA: 29s - loss: 1.6712 - accuracy: 0.2485"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.7009 - accuracy: 0.2307 - val_loss: 1.5634 - val_accuracy: 0.2930\n","Epoch 60/100\n"," 2/33 [>.............................] - ETA: 50s - loss: 1.6455 - accuracy: 0.2656 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7058 - accuracy: 0.2326 - val_loss: 1.5607 - val_accuracy: 0.3125\n","Epoch 61/100\n","32/33 [============================>.] - ETA: 1s - loss: 1.7051 - accuracy: 0.2303"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.7028 - accuracy: 0.2307 - val_loss: 1.5642 - val_accuracy: 0.3008\n","Epoch 62/100\n"," 5/33 [===>..........................] - ETA: 45s - loss: 1.6693 - accuracy: 0.2438"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6808 - accuracy: 0.2428 - val_loss: 1.6036 - val_accuracy: 0.2754\n","Epoch 63/100\n"," 9/33 [=======>......................] - ETA: 36s - loss: 1.7002 - accuracy: 0.2495"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6775 - accuracy: 0.2416 - val_loss: 1.5646 - val_accuracy: 0.3105\n","Epoch 64/100\n","19/33 [================>.............] - ETA: 22s - loss: 1.6844 - accuracy: 0.2403"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6759 - accuracy: 0.2458 - val_loss: 1.5797 - val_accuracy: 0.3086\n","Epoch 65/100\n","10/33 [========>.....................] - ETA: 37s - loss: 1.6815 - accuracy: 0.2430"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6877 - accuracy: 0.2404 - val_loss: 1.5648 - val_accuracy: 0.2988\n","Epoch 66/100\n","19/33 [================>.............] - ETA: 23s - loss: 1.6925 - accuracy: 0.2422"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6882 - accuracy: 0.2433 - val_loss: 1.5760 - val_accuracy: 0.2910\n","Epoch 67/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.6797 - accuracy: 0.2374"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6773 - accuracy: 0.2445 - val_loss: 1.5540 - val_accuracy: 0.3047\n","Epoch 68/100\n"," 5/33 [===>..........................] - ETA: 45s - loss: 1.6936 - accuracy: 0.2531"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.6837 - accuracy: 0.2402 - val_loss: 1.5727 - val_accuracy: 0.2969\n","Epoch 69/100\n","29/33 [=========================>....] - ETA: 6s - loss: 1.6780 - accuracy: 0.2471"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6772 - accuracy: 0.2455 - val_loss: 1.6008 - val_accuracy: 0.2871\n","Epoch 70/100\n","26/33 [======================>.......] - ETA: 11s - loss: 1.6676 - accuracy: 0.2521"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6711 - accuracy: 0.2460 - val_loss: 1.6027 - val_accuracy: 0.2949\n","Epoch 71/100\n"," 2/33 [>.............................] - ETA: 47s - loss: 1.6958 - accuracy: 0.2383 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.6838 - accuracy: 0.2385 - val_loss: 1.5549 - val_accuracy: 0.3086\n","Epoch 72/100\n"," 9/33 [=======>......................] - ETA: 40s - loss: 1.6819 - accuracy: 0.2352"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6713 - accuracy: 0.2375 - val_loss: 1.5748 - val_accuracy: 0.2988\n","Epoch 73/100\n","16/33 [=============>................] - ETA: 27s - loss: 1.6833 - accuracy: 0.2476"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6751 - accuracy: 0.2433 - val_loss: 1.5722 - val_accuracy: 0.3047\n","Epoch 74/100\n"," 1/33 [..............................] - ETA: 1:02 - loss: 1.6196 - accuracy: 0.2656"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6788 - accuracy: 0.2387 - val_loss: 1.5694 - val_accuracy: 0.2617\n","Epoch 75/100\n","19/33 [================>.............] - ETA: 23s - loss: 1.7124 - accuracy: 0.2278"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.7039 - accuracy: 0.2351 - val_loss: 1.5684 - val_accuracy: 0.2910\n","Epoch 76/100\n","16/33 [=============>................] - ETA: 27s - loss: 1.6948 - accuracy: 0.2295"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6993 - accuracy: 0.2271 - val_loss: 1.5620 - val_accuracy: 0.3027\n","Epoch 77/100\n"," 2/33 [>.............................] - ETA: 54s - loss: 1.6686 - accuracy: 0.2695 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6672 - accuracy: 0.2450 - val_loss: 1.5927 - val_accuracy: 0.2871\n","Epoch 78/100\n"," 2/33 [>.............................] - ETA: 52s - loss: 1.7187 - accuracy: 0.2617 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6753 - accuracy: 0.2450 - val_loss: 1.5941 - val_accuracy: 0.2773\n","Epoch 79/100\n"," 6/33 [====>.........................] - ETA: 44s - loss: 1.6873 - accuracy: 0.2253"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6702 - accuracy: 0.2426 - val_loss: 1.5582 - val_accuracy: 0.3008\n","Epoch 80/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6664 - accuracy: 0.2477 - val_loss: 1.5641 - val_accuracy: 0.2891\n","Epoch 81/100\n","18/33 [===============>..............] - ETA: 24s - loss: 1.6696 - accuracy: 0.2400"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6747 - accuracy: 0.2450 - val_loss: 1.6105 - val_accuracy: 0.2793\n","Epoch 82/100\n"," 4/33 [==>...........................] - ETA: 47s - loss: 1.6500 - accuracy: 0.2441"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6862 - accuracy: 0.2377 - val_loss: 1.5583 - val_accuracy: 0.3008\n","Epoch 83/100\n","21/33 [==================>...........] - ETA: 19s - loss: 1.7005 - accuracy: 0.2219"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6898 - accuracy: 0.2380 - val_loss: 1.5748 - val_accuracy: 0.3047\n","Epoch 84/100\n","27/33 [=======================>......] - ETA: 9s - loss: 1.6756 - accuracy: 0.2421 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6750 - accuracy: 0.2419 - val_loss: 1.5829 - val_accuracy: 0.2871\n","Epoch 85/100\n"," 4/33 [==>...........................] - ETA: 47s - loss: 1.7064 - accuracy: 0.2383"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6809 - accuracy: 0.2365 - val_loss: 1.5581 - val_accuracy: 0.2949\n","Epoch 86/100\n","11/33 [=========>....................] - ETA: 33s - loss: 1.6683 - accuracy: 0.2343"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6814 - accuracy: 0.2385 - val_loss: 1.5756 - val_accuracy: 0.2988\n","Epoch 87/100\n"," 3/33 [=>............................] - ETA: 50s - loss: 1.7028 - accuracy: 0.1901"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6717 - accuracy: 0.2431 - val_loss: 1.5714 - val_accuracy: 0.3047\n","Epoch 88/100\n"," 8/33 [======>.......................] - ETA: 41s - loss: 1.6928 - accuracy: 0.2373"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6741 - accuracy: 0.2484 - val_loss: 1.5579 - val_accuracy: 0.3008\n","Epoch 89/100\n"," 7/33 [=====>........................] - ETA: 36s - loss: 1.7055 - accuracy: 0.2430"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.7014 - accuracy: 0.2309 - val_loss: 1.5530 - val_accuracy: 0.2949\n","Epoch 90/100\n","32/33 [============================>.] - ETA: 1s - loss: 1.6925 - accuracy: 0.2343"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6909 - accuracy: 0.2351 - val_loss: 1.5965 - val_accuracy: 0.2832\n","Epoch 91/100\n"," 6/33 [====>.........................] - ETA: 43s - loss: 1.6924 - accuracy: 0.2279"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6940 - accuracy: 0.2348 - val_loss: 1.5759 - val_accuracy: 0.2949\n","Epoch 92/100\n"," 7/33 [=====>........................] - ETA: 42s - loss: 1.6648 - accuracy: 0.2589"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6747 - accuracy: 0.2431 - val_loss: 1.5578 - val_accuracy: 0.3203\n","Epoch 93/100\n","28/33 [========================>.....] - ETA: 8s - loss: 1.6765 - accuracy: 0.2421"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6758 - accuracy: 0.2426 - val_loss: 1.5723 - val_accuracy: 0.3027\n","Epoch 94/100\n"," 4/33 [==>...........................] - ETA: 46s - loss: 1.6705 - accuracy: 0.2559"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6680 - accuracy: 0.2377 - val_loss: 1.5953 - val_accuracy: 0.2793\n","Epoch 95/100\n","13/33 [==========>...................] - ETA: 30s - loss: 1.6900 - accuracy: 0.2471"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6861 - accuracy: 0.2414 - val_loss: 1.5966 - val_accuracy: 0.2832\n","Epoch 96/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6723 - accuracy: 0.2411 - val_loss: 1.5662 - val_accuracy: 0.3086\n","Epoch 97/100\n"," 6/33 [====>.........................] - ETA: 43s - loss: 1.6765 - accuracy: 0.2539"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6882 - accuracy: 0.2385 - val_loss: 1.5792 - val_accuracy: 0.2988\n","Epoch 98/100\n","27/33 [=======================>......] - ETA: 9s - loss: 1.6868 - accuracy: 0.2496 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6840 - accuracy: 0.2487 - val_loss: 1.5714 - val_accuracy: 0.3145\n","Epoch 99/100\n","29/33 [=========================>....] - ETA: 6s - loss: 1.6658 - accuracy: 0.2449"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6673 - accuracy: 0.2470 - val_loss: 1.5756 - val_accuracy: 0.3145\n","Epoch 100/100\n","26/33 [======================>.......] - ETA: 11s - loss: 1.6748 - accuracy: 0.2418"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6729 - accuracy: 0.2414 - val_loss: 1.5581 - val_accuracy: 0.2969\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8ac27f2c90>"]},"metadata":{},"execution_count":10}],"source":["## Compile and fit model\n","\n","print(\"[INFO] compiling model...\")\n","opt = Adam(learning_rate = 1e-3)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# construct the set of callbacks\n","figPath = os.path.sep.join([output,\"facial_emotion_recognition35_2.png\"])\n","jsonPath = os.path.sep.join([output,\"facial_emotion_recognition35_2.json\"])\n","model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n","callbacks = [model_checkpoint_callback, TrainingMonitor(figPath, jsonPath=jsonPath, startAt=start_epoch)]\n","\n","model.fit(train_generator, steps_per_epoch = 4246 // 128, epochs = 100, validation_data = val_generator, validation_steps = 529 // 128, max_queue_size = 128 * 2, callbacks = callbacks, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"_VAbB9nsYNEg"},"source":["\n","\n","---\n","\n","TESTARE"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"utujhtn4YNEg","outputId":"8c9adcac-3396-43c0-ab25-88443d6958d5","executionInfo":{"status":"ok","timestamp":1653854472324,"user_tz":-180,"elapsed":17586,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 540 images belonging to 6 classes.\n","[INFO] loading /content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint2...\n","4/4 [==============================] - 4s 541ms/step - loss: 1.6082 - accuracy: 0.2852\n","              precision    recall  f1-score   support\n","\n","           0       0.17      0.72      0.27        96\n","           1       0.00      0.00      0.00        81\n","           2       0.12      0.07      0.09        99\n","           3       0.22      0.17      0.19        94\n","           4       0.00      0.00      0.00        88\n","           5       0.00      0.00      0.00        82\n","\n","    accuracy                           0.17       540\n","   macro avg       0.08      0.16      0.09       540\n","weighted avg       0.09      0.17      0.10       540\n","\n","\n","\n","[INFO] accuracy: 28.52\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["model = '/content/drive/MyDrive/GitHub/licenta/outputs/output35/checkpoint2'\n","\n","test_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","test_generator = test_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/test', target_size = (224, 224), batch_size = 128, class_mode = \"categorical\")\n","\n","# load the model from disk\n","print(\"[INFO] loading {}...\".format(model))\n","model = load_model(model)\n","\n","\n","# evaluate the network\n","(loss, acc) = model.evaluate(test_generator, steps = 540 // 128, max_queue_size = 128 * 2)\n","\n","# get the ground truth of your data. \n","test_labels  =test_generator.classes \n","\n","# predict the probability distribution of the data\n","predictions = model.predict(test_generator)\n","\n","# get the class with highest probability for each sample\n","y_pred = np.argmax(predictions, axis=-1)\n","\n","# get the classification report\n","print(classification_report(test_labels, y_pred))\n","\n","print(\"\\n\\n[INFO] accuracy: {:.2f}\".format(acc * 100))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"m5jScpwQYNEg","outputId":"43e1c9d5-cf3b-406b-8e7a-35b31c41c105","executionInfo":{"status":"ok","timestamp":1653854473009,"user_tz":-180,"elapsed":690,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","%matplotlib inline\n","plt.close('all')\n","\n","# Get the confusion matrix\n","cf_matrix = confusion_matrix(test_labels, y_pred)\n","\n","ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')\n","\n","ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n","ax.set_xlabel('\\nPredicted Category')\n","ax.set_ylabel('Actual Category ')\n","\n","## Ticket labels - List must be in alphabetical order\n","ax.xaxis.set_ticklabels(['angry','fear', 'happy', 'neutral', 'sad', 'surprise'])\n","ax.yaxis.set_ticklabels(['angry','fear', 'happy', 'neutral', 'sad', 'surprise'])\n","\n","## Display the visualization of the Confusion Matrix.\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Zp-XjW2fZ_9f"},"source":["# Deblocare straturi si modificare learning rate 2"]},{"cell_type":"markdown","metadata":{"id":"Ur6d6ya8Z_9i"},"source":["Se va schimba modelul EmotionVGG creat mai sus cu modelul ResNet50 pentru a testa pe un model preantrenat.\n","\n","In plus, se va face fine-tuning cu un strat de 512 de neuroni. Spre deosebire de 3.4, se va modifica modelul cu cel ResNet50.\n","\n","Se vor debloca straturile de la 143 si modificare learning la 10^-5.\n","\n","Rezultatele se salveaza in outputs/output36."]},{"cell_type":"markdown","metadata":{"id":"Wp-aidxAZ_9j"},"source":["\n","\n","---\n","\n","ANTRENARE"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FmvAa_DZ_9j","executionInfo":{"status":"ok","timestamp":1653854493049,"user_tz":-180,"elapsed":2287,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}},"outputId":"22dea032-8b3e-4c81-a97a-e12972baf8bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4246 images belonging to 6 classes.\n","Found 529 images belonging to 6 classes.\n"]}],"source":["# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","\n","# import the necessary packages\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from keras.models import load_model\n","import keras.backend as K\n","import argparse\n","import os\n","import tensorflow\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import ResNet50\n","\n","output = '/content/drive/MyDrive/GitHub/licenta/outputs/output36'\n","checkpoint = '/content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1'\n","model = None\n","start_epoch = 0\n","\n","train_datagen = ImageDataGenerator( rotation_range = 10, rescale = 1 / 255.0, zoom_range = 0.1, horizontal_flip = True, fill_mode = \"nearest\")\n","val_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/GitHub/licenta/dataset_fer/train', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')\n","val_generator = val_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/val', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')\n","\n","\n","# FOLOSIRE VGG16\n","\n","## Loading VGG16 model\n","\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n","base_model.trainable = False ## Not trainable weights\n","\n","## Add last layers\n","\n","flatten_layer = layers.Flatten()\n","dense_layer_1 = layers.Dense(512, activation='relu')\n","dropout_layer = layers.Dropout(0.5)\n","prediction_layer = layers.Dense(6, activation='softmax')\n","\n","\n","model = models.Sequential([base_model, flatten_layer, dense_layer_1, dropout_layer, prediction_layer])"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZ2BLNTeZ_9k","executionInfo":{"status":"ok","timestamp":1653854496724,"user_tz":-180,"elapsed":255,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}},"outputId":"a0957601-18fe-4335-b942-f1028af7e07f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] base model status... \n","\n","0 input_2 False\n","1 conv1_pad False\n","2 conv1_conv False\n","3 conv1_bn False\n","4 conv1_relu False\n","5 pool1_pad False\n","6 pool1_pool False\n","7 conv2_block1_1_conv False\n","8 conv2_block1_1_bn False\n","9 conv2_block1_1_relu False\n","10 conv2_block1_2_conv False\n","11 conv2_block1_2_bn False\n","12 conv2_block1_2_relu False\n","13 conv2_block1_0_conv False\n","14 conv2_block1_3_conv False\n","15 conv2_block1_0_bn False\n","16 conv2_block1_3_bn False\n","17 conv2_block1_add False\n","18 conv2_block1_out False\n","19 conv2_block2_1_conv False\n","20 conv2_block2_1_bn False\n","21 conv2_block2_1_relu False\n","22 conv2_block2_2_conv False\n","23 conv2_block2_2_bn False\n","24 conv2_block2_2_relu False\n","25 conv2_block2_3_conv False\n","26 conv2_block2_3_bn False\n","27 conv2_block2_add False\n","28 conv2_block2_out False\n","29 conv2_block3_1_conv False\n","30 conv2_block3_1_bn False\n","31 conv2_block3_1_relu False\n","32 conv2_block3_2_conv False\n","33 conv2_block3_2_bn False\n","34 conv2_block3_2_relu False\n","35 conv2_block3_3_conv False\n","36 conv2_block3_3_bn False\n","37 conv2_block3_add False\n","38 conv2_block3_out False\n","39 conv3_block1_1_conv False\n","40 conv3_block1_1_bn False\n","41 conv3_block1_1_relu False\n","42 conv3_block1_2_conv False\n","43 conv3_block1_2_bn False\n","44 conv3_block1_2_relu False\n","45 conv3_block1_0_conv False\n","46 conv3_block1_3_conv False\n","47 conv3_block1_0_bn False\n","48 conv3_block1_3_bn False\n","49 conv3_block1_add False\n","50 conv3_block1_out False\n","51 conv3_block2_1_conv False\n","52 conv3_block2_1_bn False\n","53 conv3_block2_1_relu False\n","54 conv3_block2_2_conv False\n","55 conv3_block2_2_bn False\n","56 conv3_block2_2_relu False\n","57 conv3_block2_3_conv False\n","58 conv3_block2_3_bn False\n","59 conv3_block2_add False\n","60 conv3_block2_out False\n","61 conv3_block3_1_conv False\n","62 conv3_block3_1_bn False\n","63 conv3_block3_1_relu False\n","64 conv3_block3_2_conv False\n","65 conv3_block3_2_bn False\n","66 conv3_block3_2_relu False\n","67 conv3_block3_3_conv False\n","68 conv3_block3_3_bn False\n","69 conv3_block3_add False\n","70 conv3_block3_out False\n","71 conv3_block4_1_conv False\n","72 conv3_block4_1_bn False\n","73 conv3_block4_1_relu False\n","74 conv3_block4_2_conv False\n","75 conv3_block4_2_bn False\n","76 conv3_block4_2_relu False\n","77 conv3_block4_3_conv False\n","78 conv3_block4_3_bn False\n","79 conv3_block4_add False\n","80 conv3_block4_out False\n","81 conv4_block1_1_conv False\n","82 conv4_block1_1_bn False\n","83 conv4_block1_1_relu False\n","84 conv4_block1_2_conv False\n","85 conv4_block1_2_bn False\n","86 conv4_block1_2_relu False\n","87 conv4_block1_0_conv False\n","88 conv4_block1_3_conv False\n","89 conv4_block1_0_bn False\n","90 conv4_block1_3_bn False\n","91 conv4_block1_add False\n","92 conv4_block1_out False\n","93 conv4_block2_1_conv False\n","94 conv4_block2_1_bn False\n","95 conv4_block2_1_relu False\n","96 conv4_block2_2_conv False\n","97 conv4_block2_2_bn False\n","98 conv4_block2_2_relu False\n","99 conv4_block2_3_conv False\n","100 conv4_block2_3_bn False\n","101 conv4_block2_add False\n","102 conv4_block2_out False\n","103 conv4_block3_1_conv False\n","104 conv4_block3_1_bn False\n","105 conv4_block3_1_relu False\n","106 conv4_block3_2_conv False\n","107 conv4_block3_2_bn False\n","108 conv4_block3_2_relu False\n","109 conv4_block3_3_conv False\n","110 conv4_block3_3_bn False\n","111 conv4_block3_add False\n","112 conv4_block3_out False\n","113 conv4_block4_1_conv False\n","114 conv4_block4_1_bn False\n","115 conv4_block4_1_relu False\n","116 conv4_block4_2_conv False\n","117 conv4_block4_2_bn False\n","118 conv4_block4_2_relu False\n","119 conv4_block4_3_conv False\n","120 conv4_block4_3_bn False\n","121 conv4_block4_add False\n","122 conv4_block4_out False\n","123 conv4_block5_1_conv False\n","124 conv4_block5_1_bn False\n","125 conv4_block5_1_relu False\n","126 conv4_block5_2_conv False\n","127 conv4_block5_2_bn False\n","128 conv4_block5_2_relu False\n","129 conv4_block5_3_conv False\n","130 conv4_block5_3_bn False\n","131 conv4_block5_add False\n","132 conv4_block5_out False\n","133 conv4_block6_1_conv False\n","134 conv4_block6_1_bn False\n","135 conv4_block6_1_relu False\n","136 conv4_block6_2_conv False\n","137 conv4_block6_2_bn False\n","138 conv4_block6_2_relu False\n","139 conv4_block6_3_conv False\n","140 conv4_block6_3_bn False\n","141 conv4_block6_add False\n","142 conv4_block6_out False\n","143 conv5_block1_1_conv False\n","144 conv5_block1_1_bn False\n","145 conv5_block1_1_relu False\n","146 conv5_block1_2_conv False\n","147 conv5_block1_2_bn False\n","148 conv5_block1_2_relu False\n","149 conv5_block1_0_conv False\n","150 conv5_block1_3_conv False\n","151 conv5_block1_0_bn False\n","152 conv5_block1_3_bn False\n","153 conv5_block1_add False\n","154 conv5_block1_out False\n","155 conv5_block2_1_conv False\n","156 conv5_block2_1_bn False\n","157 conv5_block2_1_relu False\n","158 conv5_block2_2_conv False\n","159 conv5_block2_2_bn False\n","160 conv5_block2_2_relu False\n","161 conv5_block2_3_conv False\n","162 conv5_block2_3_bn False\n","163 conv5_block2_add False\n","164 conv5_block2_out False\n","165 conv5_block3_1_conv False\n","166 conv5_block3_1_bn False\n","167 conv5_block3_1_relu False\n","168 conv5_block3_2_conv False\n","169 conv5_block3_2_bn False\n","170 conv5_block3_2_relu False\n","171 conv5_block3_3_conv False\n","172 conv5_block3_3_bn False\n","173 conv5_block3_add False\n","174 conv5_block3_out False\n","\n","\n","[INFO] entire model status...\n","\n","0 resnet50 False\n","1 flatten_1 True\n","2 dense_2 True\n","3 dropout_1 True\n","4 dense_3 True\n"]}],"source":["print(\"[INFO] base model status... \\n\")\n","for i, layer in enumerate(base_model.layers):\n","  print(i, layer.name, layer.trainable)\n","\n","print(\"\\n\\n[INFO] entire model status...\\n\")\n","for i, layer in enumerate(model.layers):\n","  print(i, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"NKBSGnGpZ_9k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653855834123,"user_tz":-180,"elapsed":1332936,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}},"outputId":"88035772-1f0d-435a-a7b2-2c07137ab583"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] compiling model...\n","Epoch 1/20\n","31/33 [===========================>..] - ETA: 3s - loss: 2.1243 - accuracy: 0.1813"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 2.1085 - accuracy: 0.1829INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1/assets\n","33/33 [==============================] - 82s 2s/step - loss: 2.1085 - accuracy: 0.1829 - val_loss: 1.7342 - val_accuracy: 0.2168\n","Epoch 2/20\n","15/33 [============>.................] - ETA: 28s - loss: 1.8359 - accuracy: 0.2106"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.7924 - accuracy: 0.2390INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.7924 - accuracy: 0.2390 - val_loss: 1.6879 - val_accuracy: 0.3359\n","Epoch 3/20\n","23/33 [===================>..........] - ETA: 16s - loss: 1.7079 - accuracy: 0.2903"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.7037 - accuracy: 0.2977INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1/assets\n","33/33 [==============================] - 79s 2s/step - loss: 1.7037 - accuracy: 0.2977 - val_loss: 1.6476 - val_accuracy: 0.3496\n","Epoch 4/20\n","20/33 [=================>............] - ETA: 21s - loss: 1.6842 - accuracy: 0.3097"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.6814 - accuracy: 0.3091INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.6814 - accuracy: 0.3091 - val_loss: 1.6358 - val_accuracy: 0.3770\n","Epoch 5/20\n","18/33 [===============>..............] - ETA: 24s - loss: 1.6584 - accuracy: 0.3325"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.6613 - accuracy: 0.3281INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.6613 - accuracy: 0.3281 - val_loss: 1.6211 - val_accuracy: 0.3867\n","Epoch 6/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.6424 - accuracy: 0.3407 - val_loss: 1.6057 - val_accuracy: 0.3691\n","Epoch 7/20\n","26/33 [======================>.......] - ETA: 11s - loss: 1.6172 - accuracy: 0.3532"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6257 - accuracy: 0.3424 - val_loss: 1.5963 - val_accuracy: 0.3652\n","Epoch 8/20\n"," 2/33 [>.............................] - ETA: 53s - loss: 1.6281 - accuracy: 0.3320 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6106 - accuracy: 0.3528 - val_loss: 1.5796 - val_accuracy: 0.3652\n","Epoch 9/20\n","17/33 [==============>...............] - ETA: 26s - loss: 1.5946 - accuracy: 0.3722"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.5997 - accuracy: 0.3623 - val_loss: 1.5740 - val_accuracy: 0.3633\n","Epoch 10/20\n","21/33 [==================>...........] - ETA: 19s - loss: 1.5994 - accuracy: 0.3624"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.6027 - accuracy: 0.3550 - val_loss: 1.5598 - val_accuracy: 0.3730\n","Epoch 11/20\n","19/33 [================>.............] - ETA: 23s - loss: 1.5785 - accuracy: 0.3869"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 59s 2s/step - loss: 1.5823 - accuracy: 0.3694 - val_loss: 1.5397 - val_accuracy: 0.3867\n","Epoch 12/20\n","32/33 [============================>.] - ETA: 1s - loss: 1.5797 - accuracy: 0.3647"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.5818 - accuracy: 0.3635INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.5818 - accuracy: 0.3635 - val_loss: 1.5488 - val_accuracy: 0.3984\n","Epoch 13/20\n","17/33 [==============>...............] - ETA: 27s - loss: 1.5662 - accuracy: 0.3739"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 60s 2s/step - loss: 1.5815 - accuracy: 0.3715 - val_loss: 1.5390 - val_accuracy: 0.3828\n","Epoch 14/20\n","28/33 [========================>.....] - ETA: 8s - loss: 1.5718 - accuracy: 0.3753 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 61s 2s/step - loss: 1.5691 - accuracy: 0.3757 - val_loss: 1.5412 - val_accuracy: 0.3887\n","Epoch 15/20\n"," 6/33 [====>.........................] - ETA: 46s - loss: 1.5473 - accuracy: 0.3841"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.5690 - accuracy: 0.3771 - val_loss: 1.5511 - val_accuracy: 0.3672\n","Epoch 16/20\n","21/33 [==================>...........] - ETA: 20s - loss: 1.5667 - accuracy: 0.3735"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.5623 - accuracy: 0.3740INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.5623 - accuracy: 0.3740 - val_loss: 1.5197 - val_accuracy: 0.4082\n","Epoch 17/20\n","28/33 [========================>.....] - ETA: 8s - loss: 1.5455 - accuracy: 0.3853 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 61s 2s/step - loss: 1.5494 - accuracy: 0.3776 - val_loss: 1.5148 - val_accuracy: 0.4062\n","Epoch 18/20\n"," 8/33 [======>.......................] - ETA: 36s - loss: 1.5540 - accuracy: 0.3780"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5413 - accuracy: 0.3890 - val_loss: 1.5173 - val_accuracy: 0.3633\n","Epoch 19/20\n","16/33 [=============>................] - ETA: 28s - loss: 1.5478 - accuracy: 0.3608"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5398 - accuracy: 0.3735 - val_loss: 1.5122 - val_accuracy: 0.3867\n","Epoch 20/20\n","20/33 [=================>............] - ETA: 20s - loss: 1.5476 - accuracy: 0.3871"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5396 - accuracy: 0.3953 - val_loss: 1.5055 - val_accuracy: 0.3887\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8ac3023590>"]},"metadata":{},"execution_count":15}],"source":["## Compile and fit model\n","\n","print(\"[INFO] compiling model...\")\n","opt = Adam(learning_rate = 1e-5)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# construct the set of callbacks\n","figPath = os.path.sep.join([output,\"facial_emotion_recognition36_1.png\"])\n","jsonPath = os.path.sep.join([output,\"facial_emotion_recognitio36_1.json\"])\n","model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n","callbacks = [model_checkpoint_callback, TrainingMonitor(figPath, jsonPath=jsonPath, startAt=start_epoch)]\n","\n","model.fit(train_generator, steps_per_epoch = 4246 // 128, epochs = 20, validation_data = val_generator, validation_steps = 529 // 128, max_queue_size = 128 * 2, callbacks = callbacks, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"Bmba-mR2Z_9l"},"source":["\n","\n","---\n","\n","TESTARE"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvLFBrfSZ_9l","executionInfo":{"status":"ok","timestamp":1653855852008,"user_tz":-180,"elapsed":17898,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}},"outputId":"d27af4bf-4dbb-4bb5-91ad-1804fe9aafef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 540 images belonging to 6 classes.\n","[INFO] loading /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1...\n","4/4 [==============================] - 4s 584ms/step - loss: 1.5712 - accuracy: 0.3477\n","              precision    recall  f1-score   support\n","\n","           0       0.16      0.47      0.24        96\n","           1       0.23      0.14      0.17        81\n","           2       0.16      0.11      0.13        99\n","           3       0.17      0.15      0.16        94\n","           4       0.14      0.03      0.05        88\n","           5       0.12      0.06      0.08        82\n","\n","    accuracy                           0.16       540\n","   macro avg       0.16      0.16      0.14       540\n","weighted avg       0.16      0.16      0.14       540\n","\n","\n","\n","[INFO] accuracy: 34.77\n"]}],"source":["# import the necessary packages\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import load_model\n","import argparse\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelBinarizer\n","import numpy as np\n","\n","model = '/content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint1'\n","\n","test_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","test_generator = test_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/test', target_size = (224, 224), batch_size = 128, class_mode = \"categorical\")\n","\n","# load the model from disk\n","print(\"[INFO] loading {}...\".format(model))\n","model = load_model(model)\n","\n","\n","# evaluate the network\n","(loss, acc) = model.evaluate(test_generator, steps = 540 // 128, max_queue_size = 128 * 2)\n","\n","# get the ground truth of your data. \n","test_labels  =test_generator.classes \n","\n","# predict the probability distribution of the data\n","predictions = model.predict(test_generator)\n","\n","# get the class with highest probability for each sample\n","y_pred = np.argmax(predictions, axis=-1)\n","\n","# get the classification report\n","print(classification_report(test_labels, y_pred))\n","\n","print(\"\\n\\n[INFO] accuracy: {:.2f}\".format(acc * 100))"]},{"cell_type":"markdown","metadata":{"id":"vWeFGs4sZ_9m"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","ANTRENARE"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBq2v9tqZ_9m","executionInfo":{"status":"ok","timestamp":1653855852009,"user_tz":-180,"elapsed":23,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}},"outputId":"3e76de50-7d61-4910-c92d-89552cef5171"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] base model status... \n","\n","0 input_2 False\n","1 conv1_pad False\n","2 conv1_conv False\n","3 conv1_bn False\n","4 conv1_relu False\n","5 pool1_pad False\n","6 pool1_pool False\n","7 conv2_block1_1_conv False\n","8 conv2_block1_1_bn False\n","9 conv2_block1_1_relu False\n","10 conv2_block1_2_conv False\n","11 conv2_block1_2_bn False\n","12 conv2_block1_2_relu False\n","13 conv2_block1_0_conv False\n","14 conv2_block1_3_conv False\n","15 conv2_block1_0_bn False\n","16 conv2_block1_3_bn False\n","17 conv2_block1_add False\n","18 conv2_block1_out False\n","19 conv2_block2_1_conv False\n","20 conv2_block2_1_bn False\n","21 conv2_block2_1_relu False\n","22 conv2_block2_2_conv False\n","23 conv2_block2_2_bn False\n","24 conv2_block2_2_relu False\n","25 conv2_block2_3_conv False\n","26 conv2_block2_3_bn False\n","27 conv2_block2_add False\n","28 conv2_block2_out False\n","29 conv2_block3_1_conv False\n","30 conv2_block3_1_bn False\n","31 conv2_block3_1_relu False\n","32 conv2_block3_2_conv False\n","33 conv2_block3_2_bn False\n","34 conv2_block3_2_relu False\n","35 conv2_block3_3_conv False\n","36 conv2_block3_3_bn False\n","37 conv2_block3_add False\n","38 conv2_block3_out False\n","39 conv3_block1_1_conv False\n","40 conv3_block1_1_bn False\n","41 conv3_block1_1_relu False\n","42 conv3_block1_2_conv False\n","43 conv3_block1_2_bn False\n","44 conv3_block1_2_relu False\n","45 conv3_block1_0_conv False\n","46 conv3_block1_3_conv False\n","47 conv3_block1_0_bn False\n","48 conv3_block1_3_bn False\n","49 conv3_block1_add False\n","50 conv3_block1_out False\n","51 conv3_block2_1_conv False\n","52 conv3_block2_1_bn False\n","53 conv3_block2_1_relu False\n","54 conv3_block2_2_conv False\n","55 conv3_block2_2_bn False\n","56 conv3_block2_2_relu False\n","57 conv3_block2_3_conv False\n","58 conv3_block2_3_bn False\n","59 conv3_block2_add False\n","60 conv3_block2_out False\n","61 conv3_block3_1_conv False\n","62 conv3_block3_1_bn False\n","63 conv3_block3_1_relu False\n","64 conv3_block3_2_conv False\n","65 conv3_block3_2_bn False\n","66 conv3_block3_2_relu False\n","67 conv3_block3_3_conv False\n","68 conv3_block3_3_bn False\n","69 conv3_block3_add False\n","70 conv3_block3_out False\n","71 conv3_block4_1_conv False\n","72 conv3_block4_1_bn False\n","73 conv3_block4_1_relu False\n","74 conv3_block4_2_conv False\n","75 conv3_block4_2_bn False\n","76 conv3_block4_2_relu False\n","77 conv3_block4_3_conv False\n","78 conv3_block4_3_bn False\n","79 conv3_block4_add False\n","80 conv3_block4_out False\n","81 conv4_block1_1_conv False\n","82 conv4_block1_1_bn False\n","83 conv4_block1_1_relu False\n","84 conv4_block1_2_conv False\n","85 conv4_block1_2_bn False\n","86 conv4_block1_2_relu False\n","87 conv4_block1_0_conv False\n","88 conv4_block1_3_conv False\n","89 conv4_block1_0_bn False\n","90 conv4_block1_3_bn False\n","91 conv4_block1_add False\n","92 conv4_block1_out False\n","93 conv4_block2_1_conv False\n","94 conv4_block2_1_bn False\n","95 conv4_block2_1_relu False\n","96 conv4_block2_2_conv False\n","97 conv4_block2_2_bn False\n","98 conv4_block2_2_relu False\n","99 conv4_block2_3_conv False\n","100 conv4_block2_3_bn False\n","101 conv4_block2_add False\n","102 conv4_block2_out False\n","103 conv4_block3_1_conv False\n","104 conv4_block3_1_bn False\n","105 conv4_block3_1_relu False\n","106 conv4_block3_2_conv False\n","107 conv4_block3_2_bn False\n","108 conv4_block3_2_relu False\n","109 conv4_block3_3_conv False\n","110 conv4_block3_3_bn False\n","111 conv4_block3_add False\n","112 conv4_block3_out False\n","113 conv4_block4_1_conv False\n","114 conv4_block4_1_bn False\n","115 conv4_block4_1_relu False\n","116 conv4_block4_2_conv False\n","117 conv4_block4_2_bn False\n","118 conv4_block4_2_relu False\n","119 conv4_block4_3_conv False\n","120 conv4_block4_3_bn False\n","121 conv4_block4_add False\n","122 conv4_block4_out False\n","123 conv4_block5_1_conv False\n","124 conv4_block5_1_bn False\n","125 conv4_block5_1_relu False\n","126 conv4_block5_2_conv False\n","127 conv4_block5_2_bn False\n","128 conv4_block5_2_relu False\n","129 conv4_block5_3_conv False\n","130 conv4_block5_3_bn False\n","131 conv4_block5_add False\n","132 conv4_block5_out False\n","133 conv4_block6_1_conv False\n","134 conv4_block6_1_bn False\n","135 conv4_block6_1_relu False\n","136 conv4_block6_2_conv False\n","137 conv4_block6_2_bn False\n","138 conv4_block6_2_relu False\n","139 conv4_block6_3_conv False\n","140 conv4_block6_3_bn False\n","141 conv4_block6_add False\n","142 conv4_block6_out False\n","143 conv5_block1_1_conv True\n","144 conv5_block1_1_bn True\n","145 conv5_block1_1_relu True\n","146 conv5_block1_2_conv True\n","147 conv5_block1_2_bn True\n","148 conv5_block1_2_relu True\n","149 conv5_block1_0_conv True\n","150 conv5_block1_3_conv True\n","151 conv5_block1_0_bn True\n","152 conv5_block1_3_bn True\n","153 conv5_block1_add True\n","154 conv5_block1_out True\n","155 conv5_block2_1_conv True\n","156 conv5_block2_1_bn True\n","157 conv5_block2_1_relu True\n","158 conv5_block2_2_conv True\n","159 conv5_block2_2_bn True\n","160 conv5_block2_2_relu True\n","161 conv5_block2_3_conv True\n","162 conv5_block2_3_bn True\n","163 conv5_block2_add True\n","164 conv5_block2_out True\n","165 conv5_block3_1_conv True\n","166 conv5_block3_1_bn True\n","167 conv5_block3_1_relu True\n","168 conv5_block3_2_conv True\n","169 conv5_block3_2_bn True\n","170 conv5_block3_2_relu True\n","171 conv5_block3_3_conv True\n","172 conv5_block3_3_bn True\n","173 conv5_block3_add True\n","174 conv5_block3_out True\n","\n","\n","[INFO] entire model status...\n","\n","\n","0 resnet50 False\n","1 flatten_1 True\n","2 dense_2 True\n","3 dropout_1 True\n","4 dense_3 True\n"]}],"source":["output = '/content/drive/MyDrive/GitHub/licenta/outputs/output36'\n","checkpoint = '/content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2'\n","start_epoch = 0\n","\n","for layer in base_model.layers[143:]:\n","  layer.trainable = True\n","\n","print(\"[INFO] base model status... \\n\")\n","for i, layer in enumerate(base_model.layers):\n","  print(i, layer.name, layer.trainable)\n","\n","print(\"\\n\\n[INFO] entire model status...\\n\\n\")\n","for i, layer in enumerate(model.layers):\n","  print(i, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQFnNop2Z_9o","executionInfo":{"status":"ok","timestamp":1653861710739,"user_tz":-180,"elapsed":5858747,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}},"outputId":"77dc4f73-31b9-4fbc-deee-cf121e0039da"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] compiling model...\n","Epoch 1/100\n","21/33 [==================>...........] - ETA: 19s - loss: 1.5733 - accuracy: 0.3652"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.5583 - accuracy: 0.3723INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2/assets\n","33/33 [==============================] - 84s 2s/step - loss: 1.5583 - accuracy: 0.3723 - val_loss: 1.5159 - val_accuracy: 0.3926\n","Epoch 2/100\n"," 2/33 [>.............................] - ETA: 53s - loss: 1.5515 - accuracy: 0.4258 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.5538 - accuracy: 0.3856INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.5538 - accuracy: 0.3856 - val_loss: 1.5012 - val_accuracy: 0.4082\n","Epoch 3/100\n","15/33 [============>.................] - ETA: 29s - loss: 1.5352 - accuracy: 0.3920"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 59s 2s/step - loss: 1.5361 - accuracy: 0.3893 - val_loss: 1.5261 - val_accuracy: 0.3711\n","Epoch 4/100\n"," 1/33 [..............................] - ETA: 1:03 - loss: 1.5150 - accuracy: 0.3750"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.5370 - accuracy: 0.3815 - val_loss: 1.5059 - val_accuracy: 0.3965\n","Epoch 5/100\n","31/33 [===========================>..] - ETA: 3s - loss: 1.5403 - accuracy: 0.3809"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.5404 - accuracy: 0.3813 - val_loss: 1.5107 - val_accuracy: 0.3750\n","Epoch 6/100\n","21/33 [==================>...........] - ETA: 20s - loss: 1.5316 - accuracy: 0.3888"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.5275 - accuracy: 0.3968 - val_loss: 1.5003 - val_accuracy: 0.3984\n","Epoch 7/100\n","22/33 [===================>..........] - ETA: 17s - loss: 1.5316 - accuracy: 0.3926"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 0.3970INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.5236 - accuracy: 0.3970 - val_loss: 1.4869 - val_accuracy: 0.4160\n","Epoch 8/100\n","33/33 [==============================] - ETA: 0s - loss: 1.5165 - accuracy: 0.3973"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 59s 2s/step - loss: 1.5165 - accuracy: 0.3973 - val_loss: 1.4996 - val_accuracy: 0.3750\n","Epoch 9/100\n","31/33 [===========================>..] - ETA: 3s - loss: 1.5197 - accuracy: 0.3909"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.5191 - accuracy: 0.3907 - val_loss: 1.4897 - val_accuracy: 0.4023\n","Epoch 10/100\n","23/33 [===================>..........] - ETA: 16s - loss: 1.5210 - accuracy: 0.3808"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5126 - accuracy: 0.3868 - val_loss: 1.4941 - val_accuracy: 0.4102\n","Epoch 11/100\n"," 1/33 [..............................] - ETA: 1:09 - loss: 1.5687 - accuracy: 0.3672"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.5081 - accuracy: 0.4092 - val_loss: 1.4832 - val_accuracy: 0.4004\n","Epoch 12/100\n","27/33 [=======================>......] - ETA: 9s - loss: 1.4979 - accuracy: 0.3991 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5011 - accuracy: 0.4007 - val_loss: 1.4736 - val_accuracy: 0.4062\n","Epoch 13/100\n","11/33 [=========>....................] - ETA: 33s - loss: 1.5009 - accuracy: 0.4117"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.5032 - accuracy: 0.4017 - val_loss: 1.4863 - val_accuracy: 0.3848\n","Epoch 14/100\n","22/33 [===================>..........] - ETA: 17s - loss: 1.4782 - accuracy: 0.4063"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4872 - accuracy: 0.4031 - val_loss: 1.4708 - val_accuracy: 0.4062\n","Epoch 15/100\n","20/33 [=================>............] - ETA: 21s - loss: 1.4991 - accuracy: 0.3941"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4994 - accuracy: 0.3946 - val_loss: 1.4737 - val_accuracy: 0.4004\n","Epoch 16/100\n","26/33 [======================>.......] - ETA: 11s - loss: 1.4897 - accuracy: 0.4041"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.4910 - accuracy: 0.4021 - val_loss: 1.4690 - val_accuracy: 0.3887\n","Epoch 17/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.4918 - accuracy: 0.4005"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4938 - accuracy: 0.4017 - val_loss: 1.4679 - val_accuracy: 0.4062\n","Epoch 18/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.4904 - accuracy: 0.3992INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.4904 - accuracy: 0.3992 - val_loss: 1.4669 - val_accuracy: 0.4199\n","Epoch 19/100\n","31/33 [===========================>..] - ETA: 3s - loss: 1.4870 - accuracy: 0.4099"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.4906 - accuracy: 0.4085 - val_loss: 1.4680 - val_accuracy: 0.4082\n","Epoch 20/100\n","16/33 [=============>................] - ETA: 28s - loss: 1.4724 - accuracy: 0.4160"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4801 - accuracy: 0.4094 - val_loss: 1.4725 - val_accuracy: 0.3965\n","Epoch 21/100\n"," 9/33 [=======>......................] - ETA: 34s - loss: 1.4793 - accuracy: 0.4245"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4768 - accuracy: 0.4201 - val_loss: 1.4503 - val_accuracy: 0.4141\n","Epoch 22/100\n","26/33 [======================>.......] - ETA: 11s - loss: 1.4654 - accuracy: 0.4153"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4701 - accuracy: 0.4114 - val_loss: 1.4727 - val_accuracy: 0.3750\n","Epoch 23/100\n","27/33 [=======================>......] - ETA: 9s - loss: 1.4719 - accuracy: 0.4131 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4735 - accuracy: 0.4116 - val_loss: 1.4554 - val_accuracy: 0.4043\n","Epoch 24/100\n"," 7/33 [=====>........................] - ETA: 44s - loss: 1.4566 - accuracy: 0.4330"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4620 - accuracy: 0.4203 - val_loss: 1.4460 - val_accuracy: 0.4141\n","Epoch 25/100\n","16/33 [=============>................] - ETA: 28s - loss: 1.4550 - accuracy: 0.4243"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4627 - accuracy: 0.4240 - val_loss: 1.4362 - val_accuracy: 0.4199\n","Epoch 26/100\n","17/33 [==============>...............] - ETA: 26s - loss: 1.4521 - accuracy: 0.4393"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4656 - accuracy: 0.4281 - val_loss: 1.4479 - val_accuracy: 0.4043\n","Epoch 27/100\n","33/33 [==============================] - ETA: 0s - loss: 1.4611 - accuracy: 0.4121"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 57s 2s/step - loss: 1.4611 - accuracy: 0.4121 - val_loss: 1.4415 - val_accuracy: 0.4141\n","Epoch 28/100\n"," 4/33 [==>...........................] - ETA: 49s - loss: 1.4565 - accuracy: 0.4492"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.4610 - accuracy: 0.4259INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2/assets\n","33/33 [==============================] - 80s 2s/step - loss: 1.4610 - accuracy: 0.4259 - val_loss: 1.4326 - val_accuracy: 0.4238\n","Epoch 29/100\n","33/33 [==============================] - ETA: 0s - loss: 1.4464 - accuracy: 0.4305"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 58s 2s/step - loss: 1.4464 - accuracy: 0.4305 - val_loss: 1.4359 - val_accuracy: 0.4160\n","Epoch 30/100\n","33/33 [==============================] - ETA: 0s - loss: 1.4522 - accuracy: 0.4223"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 57s 2s/step - loss: 1.4522 - accuracy: 0.4223 - val_loss: 1.4434 - val_accuracy: 0.4160\n","Epoch 31/100\n","22/33 [===================>..........] - ETA: 17s - loss: 1.4461 - accuracy: 0.4269"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4484 - accuracy: 0.4218 - val_loss: 1.4440 - val_accuracy: 0.4043\n","Epoch 32/100\n"," 8/33 [======>.......................] - ETA: 42s - loss: 1.4569 - accuracy: 0.4238"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4450 - accuracy: 0.4237 - val_loss: 1.4347 - val_accuracy: 0.4062\n","Epoch 33/100\n","16/33 [=============>................] - ETA: 26s - loss: 1.4382 - accuracy: 0.4289"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4477 - accuracy: 0.4247 - val_loss: 1.4292 - val_accuracy: 0.4238\n","Epoch 34/100\n","13/33 [==========>...................] - ETA: 32s - loss: 1.4327 - accuracy: 0.4339"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4496 - accuracy: 0.4194 - val_loss: 1.4210 - val_accuracy: 0.4238\n","Epoch 35/100\n"," 5/33 [===>..........................] - ETA: 46s - loss: 1.4206 - accuracy: 0.4422"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4458 - accuracy: 0.4274 - val_loss: 1.4407 - val_accuracy: 0.4082\n","Epoch 36/100\n","17/33 [==============>...............] - ETA: 25s - loss: 1.4397 - accuracy: 0.4300"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4407 - accuracy: 0.4310 - val_loss: 1.4362 - val_accuracy: 0.4062\n","Epoch 37/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.4399 - accuracy: 0.4284"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4398 - accuracy: 0.4271 - val_loss: 1.4382 - val_accuracy: 0.4043\n","Epoch 38/100\n"," 1/33 [..............................] - ETA: 1:01 - loss: 1.5308 - accuracy: 0.3281"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4427 - accuracy: 0.4211 - val_loss: 1.4344 - val_accuracy: 0.3965\n","Epoch 39/100\n","15/33 [============>.................] - ETA: 27s - loss: 1.4422 - accuracy: 0.4151"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4392 - accuracy: 0.4213 - val_loss: 1.4320 - val_accuracy: 0.4121\n","Epoch 40/100\n","28/33 [========================>.....] - ETA: 8s - loss: 1.4291 - accuracy: 0.4330"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4287 - accuracy: 0.4325 - val_loss: 1.4222 - val_accuracy: 0.4180\n","Epoch 41/100\n"," 7/33 [=====>........................] - ETA: 42s - loss: 1.4298 - accuracy: 0.4375"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4375 - accuracy: 0.4327 - val_loss: 1.4178 - val_accuracy: 0.4219\n","Epoch 42/100\n","20/33 [=================>............] - ETA: 20s - loss: 1.4336 - accuracy: 0.4336"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4369 - accuracy: 0.4354 - val_loss: 1.4200 - val_accuracy: 0.4141\n","Epoch 43/100\n"," 7/33 [=====>........................] - ETA: 42s - loss: 1.4019 - accuracy: 0.4576"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.4428 - accuracy: 0.4318INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2/assets\n","33/33 [==============================] - 78s 2s/step - loss: 1.4428 - accuracy: 0.4318 - val_loss: 1.4133 - val_accuracy: 0.4414\n","Epoch 44/100\n","12/33 [=========>....................] - ETA: 34s - loss: 1.4330 - accuracy: 0.4308"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4253 - accuracy: 0.4286 - val_loss: 1.4338 - val_accuracy: 0.4004\n","Epoch 45/100\n","23/33 [===================>..........] - ETA: 15s - loss: 1.4405 - accuracy: 0.4235"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4206 - accuracy: 0.4356 - val_loss: 1.4098 - val_accuracy: 0.4336\n","Epoch 46/100\n","23/33 [===================>..........] - ETA: 15s - loss: 1.4165 - accuracy: 0.4408"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4126 - accuracy: 0.4444 - val_loss: 1.4120 - val_accuracy: 0.4199\n","Epoch 47/100\n"," 3/33 [=>............................] - ETA: 47s - loss: 1.3940 - accuracy: 0.4505"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4235 - accuracy: 0.4361 - val_loss: 1.4071 - val_accuracy: 0.4316\n","Epoch 48/100\n"," 1/33 [..............................] - ETA: 1:06 - loss: 1.4115 - accuracy: 0.4844"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4118 - accuracy: 0.4441 - val_loss: 1.3916 - val_accuracy: 0.4336\n","Epoch 49/100\n"," 3/33 [=>............................] - ETA: 26s - loss: 1.3037 - accuracy: 0.5252"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4269 - accuracy: 0.4313 - val_loss: 1.4145 - val_accuracy: 0.4102\n","Epoch 50/100\n"," 2/33 [>.............................] - ETA: 50s - loss: 1.3820 - accuracy: 0.4648 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4136 - accuracy: 0.4393 - val_loss: 1.4059 - val_accuracy: 0.4297\n","Epoch 51/100\n"," 4/33 [==>...........................] - ETA: 48s - loss: 1.4074 - accuracy: 0.4531"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4114 - accuracy: 0.4432 - val_loss: 1.4146 - val_accuracy: 0.4160\n","Epoch 52/100\n","21/33 [==================>...........] - ETA: 19s - loss: 1.3988 - accuracy: 0.4487"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.4112 - accuracy: 0.4415 - val_loss: 1.4036 - val_accuracy: 0.4238\n","Epoch 53/100\n"," 8/33 [======>.......................] - ETA: 36s - loss: 1.4111 - accuracy: 0.4532"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4130 - accuracy: 0.4444 - val_loss: 1.4080 - val_accuracy: 0.4219\n","Epoch 54/100\n","27/33 [=======================>......] - ETA: 9s - loss: 1.4100 - accuracy: 0.4412 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4071 - accuracy: 0.4458 - val_loss: 1.4034 - val_accuracy: 0.4160\n","Epoch 55/100\n","13/33 [==========>...................] - ETA: 30s - loss: 1.3759 - accuracy: 0.4596"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4073 - accuracy: 0.4458 - val_loss: 1.3999 - val_accuracy: 0.4121\n","Epoch 56/100\n","25/33 [=====================>........] - ETA: 12s - loss: 1.4064 - accuracy: 0.4373"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4019 - accuracy: 0.4439 - val_loss: 1.3978 - val_accuracy: 0.4375\n","Epoch 57/100\n","28/33 [========================>.....] - ETA: 8s - loss: 1.3915 - accuracy: 0.4554"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3948 - accuracy: 0.4517 - val_loss: 1.4043 - val_accuracy: 0.4258\n","Epoch 58/100\n","28/33 [========================>.....] - ETA: 7s - loss: 1.4081 - accuracy: 0.4494"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4129 - accuracy: 0.4424 - val_loss: 1.4077 - val_accuracy: 0.4297\n","Epoch 59/100\n","11/33 [=========>....................] - ETA: 36s - loss: 1.4191 - accuracy: 0.4332"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4010 - accuracy: 0.4444 - val_loss: 1.3908 - val_accuracy: 0.4375\n","Epoch 60/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.4048 - accuracy: 0.4555"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4039 - accuracy: 0.4497 - val_loss: 1.4006 - val_accuracy: 0.4219\n","Epoch 61/100\n","17/33 [==============>...............] - ETA: 24s - loss: 1.4188 - accuracy: 0.4304"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.4042 - accuracy: 0.4437 - val_loss: 1.3803 - val_accuracy: 0.4258\n","Epoch 62/100\n","20/33 [=================>............] - ETA: 20s - loss: 1.3996 - accuracy: 0.4348"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3956 - accuracy: 0.4415 - val_loss: 1.3860 - val_accuracy: 0.4336\n","Epoch 63/100\n"," 9/33 [=======>......................] - ETA: 38s - loss: 1.3737 - accuracy: 0.4688"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3950 - accuracy: 0.4500 - val_loss: 1.3940 - val_accuracy: 0.4316\n","Epoch 64/100\n","20/33 [=================>............] - ETA: 20s - loss: 1.3768 - accuracy: 0.4650"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3860 - accuracy: 0.4621 - val_loss: 1.3913 - val_accuracy: 0.4160\n","Epoch 65/100\n","17/33 [==============>...............] - ETA: 26s - loss: 1.3831 - accuracy: 0.4536"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3932 - accuracy: 0.4427 - val_loss: 1.4006 - val_accuracy: 0.4277\n","Epoch 66/100\n","18/33 [===============>..............] - ETA: 23s - loss: 1.3971 - accuracy: 0.4481"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3884 - accuracy: 0.4505 - val_loss: 1.4015 - val_accuracy: 0.4121\n","Epoch 67/100\n","16/33 [=============>................] - ETA: 27s - loss: 1.3816 - accuracy: 0.4443"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3958 - accuracy: 0.4364 - val_loss: 1.3946 - val_accuracy: 0.4238\n","Epoch 68/100\n","12/33 [=========>....................] - ETA: 33s - loss: 1.3645 - accuracy: 0.4524"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3914 - accuracy: 0.4507 - val_loss: 1.3817 - val_accuracy: 0.4316\n","Epoch 69/100\n","30/33 [==========================>...] - ETA: 5s - loss: 1.3781 - accuracy: 0.4523"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.3829 - accuracy: 0.4512 - val_loss: 1.3852 - val_accuracy: 0.4258\n","Epoch 70/100\n","29/33 [=========================>....] - ETA: 6s - loss: 1.3802 - accuracy: 0.4584"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3889 - accuracy: 0.4514 - val_loss: 1.3892 - val_accuracy: 0.4316\n","Epoch 71/100\n","18/33 [===============>..............] - ETA: 24s - loss: 1.4036 - accuracy: 0.4401"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3914 - accuracy: 0.4449 - val_loss: 1.3857 - val_accuracy: 0.4258\n","Epoch 72/100\n","22/33 [===================>..........] - ETA: 17s - loss: 1.3679 - accuracy: 0.4587"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3833 - accuracy: 0.4488 - val_loss: 1.3720 - val_accuracy: 0.4277\n","Epoch 73/100\n"," 1/33 [..............................] - ETA: 1:05 - loss: 1.3202 - accuracy: 0.5391"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3890 - accuracy: 0.4522 - val_loss: 1.3834 - val_accuracy: 0.4238\n","Epoch 74/100\n","15/33 [============>.................] - ETA: 29s - loss: 1.3635 - accuracy: 0.4740"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3763 - accuracy: 0.4611 - val_loss: 1.3800 - val_accuracy: 0.4297\n","Epoch 75/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.3782 - accuracy: 0.4513"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3794 - accuracy: 0.4519 - val_loss: 1.3764 - val_accuracy: 0.4297\n","Epoch 76/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.3727 - accuracy: 0.4568"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3788 - accuracy: 0.4529 - val_loss: 1.3752 - val_accuracy: 0.4375\n","Epoch 77/100\n"," 6/33 [====>.........................] - ETA: 45s - loss: 1.3449 - accuracy: 0.4635"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.3760 - accuracy: 0.4519 - val_loss: 1.3810 - val_accuracy: 0.4258\n","Epoch 78/100\n"," 4/33 [==>...........................] - ETA: 48s - loss: 1.4367 - accuracy: 0.4355"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3757 - accuracy: 0.4599 - val_loss: 1.3817 - val_accuracy: 0.4316\n","Epoch 79/100\n","17/33 [==============>...............] - ETA: 26s - loss: 1.3763 - accuracy: 0.4531"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.3758 - accuracy: 0.4529 - val_loss: 1.3846 - val_accuracy: 0.4297\n","Epoch 80/100\n"," 5/33 [===>..........................] - ETA: 46s - loss: 1.3978 - accuracy: 0.4484"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3723 - accuracy: 0.4580 - val_loss: 1.3712 - val_accuracy: 0.4375\n","Epoch 81/100\n","18/33 [===============>..............] - ETA: 24s - loss: 1.3750 - accuracy: 0.4500"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3695 - accuracy: 0.4570 - val_loss: 1.3665 - val_accuracy: 0.4297\n","Epoch 82/100\n","11/33 [=========>....................] - ETA: 36s - loss: 1.3760 - accuracy: 0.4702"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3630 - accuracy: 0.4638 - val_loss: 1.3701 - val_accuracy: 0.4238\n","Epoch 83/100\n","32/33 [============================>.] - ETA: 1s - loss: 1.3725 - accuracy: 0.4571"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 58s 2s/step - loss: 1.3745 - accuracy: 0.4560 - val_loss: 1.3669 - val_accuracy: 0.4375\n","Epoch 84/100\n","21/33 [==================>...........] - ETA: 18s - loss: 1.3726 - accuracy: 0.4527"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3736 - accuracy: 0.4512 - val_loss: 1.3602 - val_accuracy: 0.4375\n","Epoch 85/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.3621 - accuracy: 0.4557"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3640 - accuracy: 0.4553 - val_loss: 1.3698 - val_accuracy: 0.4238\n","Epoch 86/100\n","30/33 [==========================>...] - ETA: 4s - loss: 1.3673 - accuracy: 0.4555"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3719 - accuracy: 0.4553 - val_loss: 1.3646 - val_accuracy: 0.4355\n","Epoch 87/100\n","21/33 [==================>...........] - ETA: 19s - loss: 1.3595 - accuracy: 0.4628"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3587 - accuracy: 0.4616 - val_loss: 1.3643 - val_accuracy: 0.4141\n","Epoch 88/100\n"," 5/33 [===>..........................] - ETA: 45s - loss: 1.4076 - accuracy: 0.4453"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3680 - accuracy: 0.4582 - val_loss: 1.3877 - val_accuracy: 0.4141\n","Epoch 89/100\n","28/33 [========================>.....] - ETA: 7s - loss: 1.3692 - accuracy: 0.4629"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.3704 - accuracy: 0.4624INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2/assets\n","33/33 [==============================] - 77s 2s/step - loss: 1.3704 - accuracy: 0.4624 - val_loss: 1.3614 - val_accuracy: 0.4434\n","Epoch 90/100\n","20/33 [=================>............] - ETA: 20s - loss: 1.3814 - accuracy: 0.4580"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3671 - accuracy: 0.4626 - val_loss: 1.3563 - val_accuracy: 0.4414\n","Epoch 91/100\n","10/33 [========>.....................] - ETA: 37s - loss: 1.3456 - accuracy: 0.4672"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3529 - accuracy: 0.4704 - val_loss: 1.3588 - val_accuracy: 0.4375\n","Epoch 92/100\n","21/33 [==================>...........] - ETA: 18s - loss: 1.3538 - accuracy: 0.4613"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3566 - accuracy: 0.4585 - val_loss: 1.3662 - val_accuracy: 0.4375\n","Epoch 93/100\n","28/33 [========================>.....] - ETA: 7s - loss: 1.3565 - accuracy: 0.4730"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3540 - accuracy: 0.4711 - val_loss: 1.3583 - val_accuracy: 0.4414\n","Epoch 94/100\n","21/33 [==================>...........] - ETA: 18s - loss: 1.3492 - accuracy: 0.4741"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3580 - accuracy: 0.4716 - val_loss: 1.3489 - val_accuracy: 0.4395\n","Epoch 95/100\n"," 8/33 [======>.......................] - ETA: 41s - loss: 1.3381 - accuracy: 0.4893"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - ETA: 0s - loss: 1.3570 - accuracy: 0.4675INFO:tensorflow:Assets written to: /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2/assets\n","33/33 [==============================] - 77s 2s/step - loss: 1.3570 - accuracy: 0.4675 - val_loss: 1.3550 - val_accuracy: 0.4512\n","Epoch 96/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3569 - accuracy: 0.4609 - val_loss: 1.3615 - val_accuracy: 0.4453\n","Epoch 97/100\n"," 1/33 [..............................] - ETA: 1:06 - loss: 1.4027 - accuracy: 0.4062"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3530 - accuracy: 0.4645 - val_loss: 1.3619 - val_accuracy: 0.4434\n","Epoch 98/100\n","26/33 [======================>.......] - ETA: 11s - loss: 1.3524 - accuracy: 0.4606"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 57s 2s/step - loss: 1.3503 - accuracy: 0.4645 - val_loss: 1.3541 - val_accuracy: 0.4395\n","Epoch 99/100\n","24/33 [====================>.........] - ETA: 14s - loss: 1.3519 - accuracy: 0.4633"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3433 - accuracy: 0.4706 - val_loss: 1.3451 - val_accuracy: 0.4434\n","Epoch 100/100\n","21/33 [==================>...........] - ETA: 19s - loss: 1.3575 - accuracy: 0.4675"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 56s 2s/step - loss: 1.3516 - accuracy: 0.4672 - val_loss: 1.3566 - val_accuracy: 0.4375\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f886f2e4710>"]},"metadata":{},"execution_count":18}],"source":["## Compile and fit model\n","\n","print(\"[INFO] compiling model...\")\n","opt = Adam(learning_rate = 1e-5)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# construct the set of callbacks\n","figPath = os.path.sep.join([output,\"facial_emotion_recognition36_2.png\"])\n","jsonPath = os.path.sep.join([output,\"facial_emotion_recognition36_2.json\"])\n","model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n","callbacks = [model_checkpoint_callback, TrainingMonitor(figPath, jsonPath=jsonPath, startAt=start_epoch)]\n","\n","model.fit(train_generator, steps_per_epoch = 4246 // 128, epochs = 100, validation_data = val_generator, validation_steps = 529 // 128, max_queue_size = 128 * 2, callbacks = callbacks, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"J5fzB2G5Z_9o"},"source":["\n","\n","---\n","\n","TESTARE"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6vdCSajZ_9o","executionInfo":{"status":"ok","timestamp":1653861728167,"user_tz":-180,"elapsed":17460,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}},"outputId":"40d37c6a-b5cf-4cc7-dd1a-ed4bbe73e5c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 540 images belonging to 6 classes.\n","[INFO] loading /content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2...\n","4/4 [==============================] - 3s 552ms/step - loss: 1.4060 - accuracy: 0.4238\n","              precision    recall  f1-score   support\n","\n","           0       0.22      0.58      0.32        96\n","           1       0.17      0.05      0.08        81\n","           2       0.23      0.21      0.22        99\n","           3       0.22      0.09      0.12        94\n","           4       0.16      0.10      0.13        88\n","           5       0.21      0.18      0.19        82\n","\n","    accuracy                           0.21       540\n","   macro avg       0.20      0.20      0.18       540\n","weighted avg       0.20      0.21      0.18       540\n","\n","\n","\n","[INFO] accuracy: 42.38\n"]}],"source":["model = '/content/drive/MyDrive/GitHub/licenta/outputs/output36/checkpoint2'\n","\n","test_datagen = ImageDataGenerator(rescale = 1 / 255.0)\n","test_generator = test_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/test', target_size = (224, 224), batch_size = 128, class_mode = \"categorical\")\n","\n","# load the model from disk\n","print(\"[INFO] loading {}...\".format(model))\n","model = load_model(model)\n","\n","\n","# evaluate the network\n","(loss, acc) = model.evaluate(test_generator, steps = 540 // 128, max_queue_size = 128 * 2)\n","\n","# get the ground truth of your data. \n","test_labels  =test_generator.classes \n","\n","# predict the probability distribution of the data\n","predictions = model.predict(test_generator)\n","\n","# get the class with highest probability for each sample\n","y_pred = np.argmax(predictions, axis=-1)\n","\n","# get the classification report\n","print(classification_report(test_labels, y_pred))\n","\n","print(\"\\n\\n[INFO] accuracy: {:.2f}\".format(acc * 100))"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"aaDFldUCZ_9p","colab":{"base_uri":"https://localhost:8080/","height":348},"executionInfo":{"status":"ok","timestamp":1653861728838,"user_tz":-180,"elapsed":678,"user":{"displayName":"Cristina Iacob","userId":"18040797693002347035"}},"outputId":"e7d74fee-cd18-45f6-9ab3-d603472307cf"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","%matplotlib inline\n","plt.close('all')\n","\n","# Get the confusion matrix\n","cf_matrix = confusion_matrix(test_labels, y_pred)\n","\n","ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')\n","\n","ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n","ax.set_xlabel('\\nPredicted Category')\n","ax.set_ylabel('Actual Category ')\n","\n","## Ticket labels - List must be in alphabetical order\n","ax.xaxis.set_ticklabels(['angry','fear', 'happy', 'neutral', 'sad', 'surprise'])\n","ax.yaxis.set_ticklabels(['angry','fear', 'happy', 'neutral', 'sad', 'surprise'])\n","\n","## Display the visualization of the Confusion Matrix.\n","plt.show()"]}]}