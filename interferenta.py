# -*- coding: utf-8 -*-
"""Interferenta.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1idRH_6sgWM4YLlQ2tJnMPeiq4oIWSNOy

# Setup
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

"""'ghp_z(HayhkIaeF11Invg1KGWKjWYvfi150358zH'

ghp_z(HayhkIaeF11Invg1KGWKjWYvfi150358zH
"""

from google.colab import drive
drive.mount('/content/drive')

# set the matplotlib backend so figures can be saved in the background
import matplotlib
matplotlib.use("Agg")

# import the necessary packages
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from keras.models import load_model
import keras.backend as K
import argparse
import os
import tensorflow
from tensorflow.keras import layers, models
from tensorflow.keras.applications.vgg16 import VGG16

output = '/content/drive/MyDrive/GitHub/licenta/outputs/output22'
checkpoint = '/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint1'
model = None
start_epoch = 0

train_datagen = ImageDataGenerator( rotation_range = 10, rescale = 1 / 255.0, zoom_range = 0.1, horizontal_flip = True, fill_mode = "nearest")
val_datagen = ImageDataGenerator(rescale = 1 / 255.0)
train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/GitHub/licenta/dataset_fer/train', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')
val_generator = val_datagen.flow_from_directory( '/content/drive/MyDrive/GitHub/licenta/dataset_fer/val', target_size = (224, 224), batch_size = 128, class_mode = 'categorical')


# FOLOSIRE VGG16

## Loading VGG16 model

base_model = VGG16(weights="imagenet", include_top=False, input_shape=(224,224,3))
base_model.trainable = False ## Not trainable weights

## Add last layers

flatten_layer = layers.Flatten()
dense_layer_1 = layers.Dense(512, activation='relu')
dropout_layer = layers.Dropout(0.5)
prediction_layer = layers.Dense(6, activation='softmax')


model = models.Sequential([base_model, flatten_layer, dense_layer_1, dropout_layer, prediction_layer])

"""# Interferenta

Se va testa modelul pe cateva poze din fiecare clasa cu mine
"""

class_labels = val_generator.class_indices
class_labels = {v: k for k, v in class_labels.items()}
print(class_labels)

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/happy.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/sup.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/cata.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza1.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza2.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza3.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza4.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza5.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza6.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza7.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza8.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza9.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza10.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza11.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza12.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza13.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza14.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza15.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza16.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza17.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza18.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza19.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza20.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza21.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza22.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza23.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza24.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/poze_test_separat/poza25.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

"""# Inferenta 2"""

class_labels = val_generator.class_indices
class_labels = {v: k for k, v in class_labels.items()}
print(class_labels)

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (1).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image.png")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (2).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (3).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (4).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (5).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (6).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (7).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (8).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (9).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (10).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (11).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (12).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (14).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/inferenta_2/image (15).jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

"""# Inferenta 3"""

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/dataset_fer/train/angry/10-106421_angry-person-png-image-hd-will-kill-you.png.jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/dataset_fer/train/angry/Angry_woman.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/dataset_fer/train/angry/iStock_000010998923XSmall.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/dataset_fer/train/angry/images-15.jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/dataset_fer/train/angry/istockphoto-546195938-170667a.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/dataset_fer/train/angry/young-handsome-man-beard-wearing-260nw-1661274163.jpg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from keras.preprocessing.image import img_to_array
from google.colab.patches import cv2_imshow

# adaugare load model

classifier = load_model("/content/drive/MyDrive/GitHub/licenta/outputs/output22/checkpoint3")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def face_detector(img):
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    if faces is ():
        return (0,0,0,0), np.zeros((224,224), np.uint8), img
    allfaces = []   
    rects = []
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (224, 224), interpolation = cv2.INTER_AREA)
        allfaces.append(roi)
        rects.append((x,w,y,h))
    return rects, allfaces, img

img = cv2.imread("/content/drive/MyDrive/GitHub/licenta/dataset_fer/train/angry/pexels-photo-1447424.jpeg")
rects, faces, image = face_detector(img)

i = 0
for face in faces:
    roi = face.astype("float") / 255.0
    roi = img_to_array(roi)
    roi = np.expand_dims(roi, axis=0)


    # make a prediction on the ROI, then lookup the class
    preds = classifier.predict(roi)[0]
    label = class_labels[preds.argmax()]   

    #Overlay our detected emotion on our pic
    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))
    i =+ 1
    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)
    
cv2_imshow(image)
cv2.waitKey(0)

cv2.destroyAllWindows()